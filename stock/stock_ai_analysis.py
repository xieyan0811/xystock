"""
è‚¡ç¥¨AIåˆ†æå·¥å…·
æä¾›åŸºäºLLMçš„è‚¡ç¥¨å¸‚åœºåˆ†æåŠŸèƒ½ã€ç­¹ç åˆ†æåŠŸèƒ½ã€æ–°é—»åˆ†æåŠŸèƒ½å’ŒåŸºæœ¬é¢åˆ†æåŠŸèƒ½
"""

from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass
from llm.openai_client import OpenAIClient
import datetime
import sys
import os
import traceback

project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_dir not in sys.path:
    sys.path.append(project_dir)

from utils.string_utils import remove_markdown_format
from utils.data_formatters import get_stock_formatter


@dataclass
class AnalysisResult:
    """AIåˆ†æç»“æœçš„ç»Ÿä¸€æ ¼å¼"""
    success: bool
    report: str
    timestamp: str
    error_message: Optional[str] = None
    analysis_type: str = ""
    stock_code: str = ""
    data_sources: Optional[List[Dict]] = None


class AnalysisConfig:
    """AIåˆ†æé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        try:
            from config_manager import config
            self.config = config
        except Exception as e:
            print(f"åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            self.config = None
    
    def get_analysis_config(self, analysis_type: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šåˆ†æç±»å‹çš„é…ç½®"""
        if not self.config:
            return self._get_default_config(analysis_type)
        
        try:
            config_key = f"AI_ANALYSIS.{analysis_type.upper()}"
            return {
                'temperature': self.config.get(f'{config_key}.TEMPERATURE', 0.5),
                'model_type': self.config.get(f'{config_key}.MODEL_TYPE', 'default'),
                'cache_filename': self.config.get(f'{config_key}.CACHE_FILENAME', f'req_{analysis_type}.txt')
            }
        except Exception as e:
            print(f"è·å–{analysis_type}é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return self._get_default_config(analysis_type)
    
    def _get_default_config(self, analysis_type: str) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        defaults = {
            'technical': {'temperature': 0.5, 'model_type': 'inference', 'cache_filename': 'req_tech.txt'},
            'news': {'temperature': 0.7, 'model_type': 'default', 'cache_filename': 'req_news.txt'},
            'chip': {'temperature': 0.5, 'model_type': 'default', 'cache_filename': 'req_chip.txt'},
            'fundamental': {'temperature': 0.6, 'model_type': 'default', 'cache_filename': 'req_basic_info.txt'},
            'comprehensive': {'temperature': 0.4, 'model_type': 'default', 'cache_filename': 'req.txt'}
        }
        return defaults.get(analysis_type, defaults['comprehensive'])


class DataCollector:
    """æ•°æ®æ”¶é›†å™¨ - è´Ÿè´£æ”¶é›†å„ç§åˆ†ææ‰€éœ€çš„æ•°æ®"""
    
    def __init__(self):
        self.formatter = get_stock_formatter()
    
    def collect_stock_basic_info(self, stock_identity: Dict[str, Any]) -> Tuple[str, Optional[Dict]]:
        """æ”¶é›†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            from stock.stock_data_tools import get_stock_tools
            stock_tools = get_stock_tools()
            basic_info = stock_tools.get_basic_info(stock_identity, use_cache=True)
            
            if basic_info and 'error' not in basic_info:
                formatted_info = self.formatter.format_basic_info(basic_info, stock_identity)
                data_source = {
                    'type': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯',
                    'description': 'åŒ…å«å½“å‰ä»·æ ¼ã€æ¶¨è·Œé¢ã€æ¶¨è·Œå¹…ç­‰å®æ—¶æ•°æ®',
                    'timestamp': basic_info.get('update_time', 'æœªçŸ¥æ—¶é—´')
                }
                return formatted_info, data_source
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        
        return "", None
    
    def collect_historical_analyses(self, stock_code: str, stock_tools=None) -> Tuple[Dict[str, str], List[Dict]]:
        """æ”¶é›†å†å²åˆ†ææ•°æ®"""
        historical_analyses = {}
        data_sources = []
        
        if not stock_tools:
            return historical_analyses, data_sources
        
        analysis_types = {
            'technical': 'æŠ€æœ¯åˆ†æ',
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'news': 'æ–°é—»åˆ†æ',
            'chip': 'ç­¹ç åˆ†æ'
        }
        
        for analysis_type, description in analysis_types.items():
            try:
                cached_analysis = stock_tools.get_cached_ai_analysis(stock_code, analysis_type, use_cache=True)
                if cached_analysis and 'report' in cached_analysis:
                    historical_analyses[analysis_type] = cached_analysis['report']
                    data_sources.append({
                        'type': description,
                        'description': f'ç¼“å­˜çš„{description}æŠ¥å‘Š',
                        'timestamp': cached_analysis.get('timestamp', 'æœªçŸ¥æ—¶é—´')
                    })
            except Exception as e:
                print(f"è·å–{description}å¤±è´¥: {e}")
        
        return historical_analyses, data_sources
    
    def collect_market_data(self, market_tools=None) -> Tuple[str, str, List[Dict]]:
        """æ”¶é›†å¸‚åœºæ•°æ®"""
        market_report_text = ""
        market_ai_analysis = ""
        data_sources = []
        
        if not market_tools:
            try:
                from market.market_data_tools import get_market_tools
                market_tools = get_market_tools()
            except Exception as e:
                print(f"å¯¼å…¥market_toolså¤±è´¥: {e}")
                return market_report_text, market_ai_analysis, data_sources
        
        # æ”¶é›†å¸‚åœºç»¼åˆæŠ¥å‘Š
        try:
            market_report = market_tools.get_comprehensive_market_report(use_cache=True)
            if market_report:
                data_sources.append({
                    'type': 'å¸‚åœºç»¼åˆæŠ¥å‘Š',
                    'description': 'åŒ…å«æŠ€æœ¯æŒ‡æ ‡ã€æƒ…ç»ªã€ä¼°å€¼ã€èµ„é‡‘æµå‘ç­‰å¸‚åœºæ•°æ®',
                    'timestamp': market_report.get('report_time', 'æœªçŸ¥æ—¶é—´')
                })
                market_report_text = market_tools.generate_market_report(market_report, format_type='summary')
        except Exception as e:
            print(f"è·å–å¸‚åœºç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")
        
        # æ”¶é›†AIå¤§ç›˜åˆ†æ
        try:
            market_ai_data = market_tools.get_ai_analysis(use_cache=True, index_name='ä¸Šè¯æŒ‡æ•°')
            if market_ai_data:
                if isinstance(market_ai_data, dict) and 'report' in market_ai_data:
                    market_ai_analysis = market_ai_data['report']
                data_sources.append({
                    'type': 'AIå¤§ç›˜åˆ†æ',
                    'description': 'åŸºäºAIæ¨¡å‹çš„å¸‚åœºåˆ†ææŠ¥å‘Š',
                    'timestamp': market_ai_data.get('analysis_time', 'æœªçŸ¥æ—¶é—´')
                })
        except Exception as e:
            print(f"è·å–å¤§ç›˜åˆ†æå¤±è´¥: {e}")
        
        return market_report_text, market_ai_analysis, data_sources
    
    def collect_user_profile(self) -> Tuple[str, str, List[Dict]]:
        """æ”¶é›†ç”¨æˆ·ç”»åƒæ•°æ®"""
        user_profile_section = ""
        user_mistakes_section = ""
        data_sources = []
        
        try:
            from config_manager import config
            
            # ç”¨æˆ·ç”»åƒ
            user_profile_raw = config.get('USER_PROFILE.RAW', '').strip()
            if user_profile_raw:
                user_profile_section = f"\n# ç”¨æˆ·ç”»åƒ\n{user_profile_raw}\n"
                data_sources.append({
                    'type': 'ç”¨æˆ·ç”»åƒ',
                    'description': 'ç”¨æˆ·çš„æŠ•èµ„åå¥½ã€é£é™©æ‰¿å—èƒ½åŠ›ç­‰ä¿¡æ¯',
                    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
            
            # ç”¨æˆ·å¸¸çŠ¯é”™è¯¯
            user_mistakes = config.get('USER_PROFILE.MISTAKES', '')
            if user_mistakes:
                user_mistakes_section = f"\n# ç”¨æˆ·å¸¸çŠ¯é”™è¯¯\n{user_mistakes}\n"
                data_sources.append({
                    'type': 'ç”¨æˆ·å¸¸çŠ¯é”™è¯¯',
                    'description': 'ç”¨æˆ·åœ¨æŠ•èµ„è¿‡ç¨‹ä¸­å¸¸çŠ¯çš„é”™è¯¯å’Œè¯¯åŒº',
                    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
        except Exception as e:
            print(f"è·å–ç”¨æˆ·é…ç½®å¤±è´¥: {e}")
        
        return user_profile_section, user_mistakes_section, data_sources


class ReportFormatter:
    """æŠ¥å‘Šæ ¼å¼åŒ–å™¨ - è´Ÿè´£æ ¼å¼åŒ–å„ç§æ•°æ®ä¸ºæŠ¥å‘Šæ ¼å¼"""
    
    @staticmethod
    def format_historical_summary(historical_analyses: Dict[str, str], truncate_data: bool = False) -> str:
        """æ ¼å¼åŒ–å†å²åˆ†ææ‘˜è¦"""
        if not historical_analyses:
            return "\n\n## ğŸ“Š å†å²åˆ†ææ‘˜è¦\næœªæ‰¾åˆ°ç›¸å…³å†å²åˆ†ææ•°æ®ï¼Œå°†åŸºäºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n"
        
        analysis_types = {
            'technical': 'æŠ€æœ¯åˆ†æ',
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'news': 'æ–°é—»åˆ†æ',
            'chip': 'ç­¹ç åˆ†æ'
        }
        
        historical_summary = "\n\n# ğŸ“Š å†å²åˆ†ææ‘˜è¦\n"
        for analysis_type, report in historical_analyses.items():
            if truncate_data:
                summary = report[:300] + "..." if len(report) > 300 else report
            else:
                summary = report
            summary = remove_markdown_format(summary)
            historical_summary += f"\n## {analysis_types.get(analysis_type, analysis_type)}:\n\n{summary}\n"
        
        return historical_summary
    
    @staticmethod
    def format_market_summary(market_report_text: str, market_ai_analysis: str, truncate_data: bool = False) -> str:
        """æ ¼å¼åŒ–å¸‚åœºç¯å¢ƒåˆ†æ"""
        if not market_report_text and not market_ai_analysis:
            return "\n\n## ğŸŒ å¸‚åœºç¯å¢ƒåˆ†æ\næš‚æ— å¸‚åœºç¯å¢ƒæ•°æ®ã€‚\n\n"
        
        market_summary = "\n\n# ğŸŒ å¸‚åœºç¯å¢ƒåˆ†æ\n"
        
        if market_report_text:
            market_text_summary = market_report_text[:500] + "..." if truncate_data and len(market_report_text) > 500 else market_report_text
            market_summary += f"\n## å¸‚åœºç»¼åˆæŠ¥å‘Š:\n\n{market_text_summary}\n\n"
        
        if market_ai_analysis:
            ai_summary = market_ai_analysis[:300] + "..." if truncate_data and len(market_ai_analysis) > 300 else market_ai_analysis
            market_summary += f"\n### AIå¤§ç›˜åˆ†æ:\n\n{ai_summary}\n\n"
        
        return market_summary
    
    @staticmethod
    def format_user_opinion_section(user_opinion: str, user_position: str) -> Tuple[str, List[Dict]]:
        """æ ¼å¼åŒ–ç”¨æˆ·è§‚ç‚¹éƒ¨åˆ†"""
        user_opinion_section = ""
        data_sources = []
        
        if user_opinion.strip():
            user_opinion_section = f"\n# ç”¨æˆ·è§‚ç‚¹\n{user_opinion.strip()}\n"
            data_sources.append({
                'type': 'ç”¨æˆ·è§‚ç‚¹',
                'description': 'ç”¨æˆ·æä¾›çš„æŠ•èµ„è§‚ç‚¹å’Œçœ‹æ³•',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        if user_position and user_position.strip() and user_position.strip() != "ä¸ç¡®å®š":
            user_opinion_section += f"\n# ç”¨æˆ·å½“å‰æŒä»“çŠ¶æ€\n{user_position.strip()}\n"
            data_sources.append({
                'type': 'ç”¨æˆ·æŒä»“',
                'description': f'ç”¨æˆ·å½“å‰æŒä»“çŠ¶æ€ï¼š{user_position.strip()}',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        return user_opinion_section, data_sources


def _save_request_to_cache(content: str, filename: str):
    """ä¿å­˜è¯·æ±‚å†…å®¹åˆ°ç¼“å­˜æ–‡ä»¶"""
    try:
        cache_path = os.path.join(project_dir, "data", "cache", filename)
        with open(cache_path, "w", encoding="utf-8") as f:
            f.write(content)
    except Exception as e:
        print(f"ä¿å­˜è¯·æ±‚æ–‡ä»¶{filename}å¤±è´¥: {e}")


class BaseAnalysisGenerator:
    """åŸºç¡€åˆ†æç”Ÿæˆå™¨ - æä¾›é€šç”¨çš„åˆ†æç”ŸæˆåŠŸèƒ½"""
    
    def __init__(self):
        self.client = OpenAIClient()
        self.config_manager = AnalysisConfig()
    
    def generate_analysis(self, analysis_type: str, messages: List[Dict], stock_code: str = "") -> AnalysisResult:
        """é€šç”¨çš„åˆ†æç”Ÿæˆæ–¹æ³•"""
        config = self.config_manager.get_analysis_config(analysis_type)
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        if len(messages) > 1:
            _save_request_to_cache(messages[1]['content'], config['cache_filename'])
        
        try:
            response = self.client.chat(
                messages=messages,
                temperature=config['temperature'],
                model_type=config['model_type']
            )
            
            return AnalysisResult(
                success=True,
                report=response,
                timestamp=timestamp,
                analysis_type=analysis_type,
                stock_code=stock_code
            )
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆ{analysis_type}åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}"
            print(error_msg)
            traceback.print_exc()
            
            return AnalysisResult(
                success=False,
                report=error_msg,
                timestamp=timestamp,
                error_message=str(e),
                analysis_type=analysis_type,
                stock_code=stock_code
            )

def get_stock_info(stock_identity):
    from stock.stock_data_tools import get_stock_tools
    stock_tools = get_stock_tools()
    return stock_tools.get_basic_info(stock_identity, use_cache=True)

def generate_stock_analysis_report(
    stock_identity: Dict[str, Any],
    kline_info: Dict[str, Any] = None,
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨æŠ€æœ¯åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    kline_text = formatter.format_kline_data(kline_info)

    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨æŠ€æœ¯åˆ†æå¸ˆï¼Œä¸“ç²¾äºåŸºäºæŠ€æœ¯æŒ‡æ ‡è¿›è¡Œè‚¡ç¥¨åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®æŠ€æœ¯æ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„æŠ€æœ¯é¢åˆ†æï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æŠ€æœ¯é¢ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- åˆ†æç§»åŠ¨å¹³å‡çº¿ã€MACDã€RSIã€å¸ƒæ—å¸¦ç­‰å…³é”®æŠ€æœ¯æŒ‡æ ‡
- è¯†åˆ«æ”¯æ’‘é˜»åŠ›ä½å’Œä»·æ ¼è¶‹åŠ¿
- è¯„ä¼°å½“å‰è‚¡ä»·å˜åŠ¨å¯¹æŠ€æœ¯é¢çš„å½±å“
- æä¾›å…·ä½“æ•°å€¼å’Œä¸“ä¸šæŠ€æœ¯åˆ¤æ–­

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ
## ğŸ“‰ ä»·æ ¼è¶‹åŠ¿åˆ†æ
## ğŸ¯ å…³é”®æŠ€æœ¯ä½

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- å…³æ³¨å½“å‰è‚¡ä»·è¡¨ç°å¯¹æŠ€æœ¯é¢çš„å½±å“
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ•°æ®ï¼Œä¸å¾—ç¼–é€ """

    user_message = f"""è¯·åŸºäºä»¥ä¸‹æ•°æ®å¯¹{stock_name}({stock_code})è¿›è¡ŒæŠ€æœ¯åˆ†æï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}
- è´§å¸ï¼š{stock_identity.get('currency_name', 'äººæ°‘å¸')}({stock_identity.get('currency_symbol', 'Â¥')})

**æŠ€æœ¯æ•°æ®ï¼š**
{basic_info_section}

{kline_text}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]

    return generator.generate_analysis("technical", messages, stock_code)


def generate_news_analysis_report(
    stock_identity: Dict[str, Any],
    news_data: List[Dict]
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨æ–°é—»åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    news_text = formatter.format_news_data(news_data, has_content=True)
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œä¸“ç²¾äºè¯„ä¼°æ–°é—»äº‹ä»¶å¯¹è‚¡ç¥¨ä»·æ ¼çš„æ½œåœ¨å½±å“ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®æ–°é—»æ•°æ®ï¼Œè¯†åˆ«å…³é”®ä¿¡æ¯å¹¶è¯„ä¼°å¸‚åœºå½±å“ï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ¶ˆæ¯é¢ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- è¯†åˆ«å½±å“è¯¥è‚¡çš„å…³é”®æ–°é—»äº‹ä»¶ï¼ˆè´¢æŠ¥ã€åˆä½œã€æ”¿ç­–ã€çªå‘äº‹ä»¶ç­‰ï¼‰
- è¯„ä¼°æ–°é—»æ—¶æ•ˆæ€§ã€å¯ä¿¡åº¦å’Œå¸‚åœºå½±å“ç¨‹åº¦
- åˆ†ææŠ•èµ„è€…æƒ…ç»ªå˜åŒ–å’ŒçŸ­æœŸä»·æ ¼å½±å“
- å…³æ³¨æ–°é—»å¯¹å…¬å¸åŸºæœ¬é¢çš„å®è´¨æ€§å½±å“

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“° æ–°é—»æ¦‚è¿°
## ğŸ“Š å…³é”®ä¿¡æ¯åˆ†æ
## ğŸ’¹ å¸‚åœºå½±å“è¯„ä¼°
## âš ï¸ é£é™©å› ç´ è¯†åˆ«

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- é‡ç‚¹å…³æ³¨å¯¹æŠ•èµ„å†³ç­–æœ‰å®è´¨å½±å“çš„æ–°é—»å†…å®¹
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ–°é—»æ•°æ®ï¼Œä¸å¾—ç¼–é€ 
- å¦‚æ–°é—»æ•°æ®ä¸è¶³ï¼Œæ˜ç¡®æŒ‡å‡ºåˆ†æå±€é™æ€§"""

    user_message = f"""è¯·åˆ†æä»¥ä¸‹å…³äº{stock_name}({stock_code})çš„æœ€æ–°æ–°é—»ï¼Œè¯„ä¼°å…¶å¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“ï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- æ‰€å±å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

{basic_info_section}

=== æœ€æ–°æ–°é—»æ•°æ® ===

{news_text}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    
    return generator.generate_analysis("news", messages, stock_code)
        
        
def generate_chip_analysis_report(
    stock_identity: Dict[str, Any],
    chip_data: Dict[str, Any]
) -> AnalysisResult:
    """ç”Ÿæˆç­¹ç åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    chip_text = formatter.format_chip_data(chip_data)
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç­¹ç åˆ†æå¸ˆï¼Œä¸“ç²¾äºAè‚¡å¸‚åœºçš„ç­¹ç åˆ†å¸ƒæŠ€æœ¯åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®ç­¹ç æ•°æ®ï¼Œè¡¥å……å›¾è¡¨æ— æ³•ä½“ç°çš„æ•´ä½“è¶‹åŠ¿ã€ä¸»åŠ›è¡Œä¸ºå’Œå¸‚åœºåšå¼ˆæ´å¯Ÿï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›ç®€æ˜ã€ä¸“ä¸šçš„åˆ†æã€‚

**åˆ†æé‡ç‚¹ï¼š**
- è§£è¯»ç­¹ç åˆ†å¸ƒå½¢æ€ä¸é›†ä¸­åº¦ï¼Œåˆ¤æ–­ä¸»åŠ›æˆæœ¬åŒºé—´å’Œæ§ç›˜ç¨‹åº¦
- ç»“åˆç­¹ç å³°å€¼è¯†åˆ«å…³é”®æ”¯æ’‘ä¸å‹åŠ›ä½
- å…³æ³¨ç­¹ç è¿ç§»ã€å¼‚åŠ¨è½¬ç§»ç‡ç­‰å˜åŒ–ï¼Œè¯†åˆ«å¸‚åœºä¿¡å·
- å¯ç”¨ä¸»åŠ›æˆæœ¬ä¹–ç¦»ç‡ã€ç­¹ç ç¨³å®šæŒ‡æ•°ç­‰æŒ‡æ ‡è¾…åŠ©åˆ†æ

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“Š ç­¹ç åˆ†å¸ƒæ¦‚å†µ
## ğŸ¯ ä¸»åŠ›è¡Œä¸ºç”»åƒ
## âš¡ å‹åŠ›æ”¯æ’‘åˆ†æ
## ğŸ’¡ ç­¹ç å˜åŒ–ä¿¡å·

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- ä¸é‡å¤å›¾è¡¨å·²å±•ç¤ºçš„ç»†èŠ‚ï¼Œåªè¡¥å……æ•´ä½“è¶‹åŠ¿å’Œä¸»åŠ›æ„å›¾ç­‰å…³é”®å†…å®¹
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®ç­¹ç æ•°æ®ï¼Œä¸å¾—ç¼–é€ 
"""
    user_message = f"""è¯·å¯¹{stock_name}({stock_code})è¿›è¡Œç­¹ç åˆ†æï¼ŒåŸºäºä»¥ä¸‹æ•°æ®ï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

**åŸºæœ¬ä¿¡æ¯ï¼š**
{basic_info_section}

**ç­¹ç æ•°æ®ï¼š**
{chip_text}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    
    return generator.generate_analysis("chip", messages, stock_code)


def generate_fundamental_analysis_report(
    stock_identity: Dict[str, Any],
    fundamental_data: Dict[str, Any]
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨åŸºæœ¬é¢åˆ†ææŠ¥å‘Š"""
    
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_basic_info(fundamental_data, stock_identity)
    currency_name = stock_identity.get('currency_name', 'äººæ°‘å¸')
    currency_symbol = stock_identity.get('currency_symbol', 'Â¥')
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå¸ˆï¼Œä¸“ç²¾äºæ·±å…¥çš„è´¢åŠ¡å’ŒåŸºæœ¬é¢åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®è´¢åŠ¡æ•°æ®ï¼Œæä¾›ä¸“ä¸šã€å®¢è§‚çš„åŸºæœ¬é¢åˆ†æï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›åŸºæœ¬é¢ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- è´¢åŠ¡å¥åº·è¯„ä¼°ï¼šåˆ†æèµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµå’Œç›ˆåˆ©èƒ½åŠ›
- ä¼°å€¼åˆ†æï¼šè®¡ç®—å¹¶è§£é‡ŠPEã€PBã€PEGç­‰å…³é”®ä¼°å€¼æŒ‡æ ‡
- å¢é•¿æ½œåŠ›è¯„ä¼°ï¼šåˆ†æè¥æ”¶å’Œåˆ©æ¶¦å¢é•¿è¶‹åŠ¿
- é£é™©è¯„ä¼°ï¼šè¯†åˆ«è´¢åŠ¡ã€ç»è¥ã€è¡Œä¸šå’Œå¸‚åœºé£é™©å› ç´ 

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“Š åŸºæœ¬é¢æ¦‚å†µ
## ğŸ’° è´¢åŠ¡æŒ‡æ ‡åˆ†æ
## ğŸ“ˆ ä¼°å€¼ä¸å¢é•¿åˆ†æ
## âš–ï¸ ä¼˜åŠ¿ä¸é£é™©åˆ†æ

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€ï¼Œä¸åŒ…å«å…·ä½“æŠ•èµ„å»ºè®®
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ•°æ®ï¼Œä¸¥ç¦ç¼–é€ æ•°æ®æˆ–ä¸»è§‚è‡†æµ‹"""

    user_message = f"""è¯·åŸºäºä»¥ä¸‹çœŸå®æ•°æ®ï¼Œå¯¹{stock_name}({stock_code})è¿›è¡Œå…¨é¢çš„åŸºæœ¬é¢åˆ†æï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}
- è´§å¸ï¼š{currency_name}({currency_symbol})

**åŸºæœ¬é¢æ•°æ®ï¼š**
{basic_info_section}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]

    return generator.generate_analysis("fundamental", messages, stock_code)


def generate_comprehensive_analysis_report(
    stock_identity: Dict[str, Any],
    user_opinion: str = "",
    user_position: str = "ä¸ç¡®å®š",
    stock_tools=None,
    market_tools=None,
    truncate_data: bool = False
) -> AnalysisResult:
    """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')
    
    collector = DataCollector()
    formatter = ReportFormatter()
    all_data_sources = []
    
    try:
        # 1. æ”¶é›†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        basic_info_section, basic_info_source = collector.collect_stock_basic_info(stock_identity)
        if basic_info_source:
            all_data_sources.append(basic_info_source)
        
        # 2. æ”¶é›†å†å²åˆ†ææ•°æ®
        historical_analyses, historical_sources = collector.collect_historical_analyses(stock_code, stock_tools)
        all_data_sources.extend(historical_sources)
        
        # å¦‚æœæ²¡æœ‰å†å²åˆ†ææ•°æ®ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
        if not historical_analyses:
            all_data_sources.append({
                'type': 'æç¤ºä¿¡æ¯',
                'description': 'æœªæ‰¾åˆ°å†å²åˆ†ææ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬ä¿¡æ¯è¿›è¡Œåˆ†æ',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        # 3. æ”¶é›†å¤§ç›˜æ•°æ®
        market_report_text, market_ai_analysis, market_sources = collector.collect_market_data(market_tools)
        all_data_sources.extend(market_sources)
        
        # 4. æ”¶é›†ç”¨æˆ·ç”»åƒæ•°æ®
        user_profile_section, user_mistakes_section, user_sources = collector.collect_user_profile()
        all_data_sources.extend(user_sources)
        
        # 5. æ ¼å¼åŒ–ç”¨æˆ·è§‚ç‚¹å’ŒæŒä»“ä¿¡æ¯
        user_opinion_section, user_opinion_sources = formatter.format_user_opinion_section(user_opinion, user_position)
        all_data_sources.extend(user_opinion_sources)
        
        # 6. æ ¼å¼åŒ–å„éƒ¨åˆ†å†…å®¹
        historical_summary = formatter.format_historical_summary(historical_analyses, truncate_data)
        market_summary = formatter.format_market_summary(market_report_text, market_ai_analysis, truncate_data)
        
        system_message = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„é¡¾é—®å’Œè‚¡ç¥¨åˆ†æå¸ˆï¼Œä¸“ç²¾äºæ•´åˆå¤šç»´åº¦æ•°æ®è¿›è¡Œç»¼åˆæŠ•èµ„åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºAIå·²ç”Ÿæˆçš„å„ç±»åˆ†æå’Œå®æ—¶æ•°æ®ï¼Œå¯¹è‚¡ç¥¨å½“å‰çš„æŠ•èµ„ä»·å€¼è¿›è¡Œé«˜åº¦å‡ç»ƒçš„ç»¼åˆåˆ¤æ–­ï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ˜ç¡®æŒ‡å¯¼ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- æ•´åˆæŠ€æœ¯é¢ã€åŸºæœ¬é¢ã€æ¶ˆæ¯é¢ã€ç­¹ç é¢åˆ†æï¼Œè¯†åˆ«æ ¸å¿ƒé©±åŠ¨å› ç´ å’Œä¸»è¦çŸ›ç›¾
- é¢„æµ‹å…·ä½“æ¶¨è·Œå¹…åº¦ï¼šè¶…çŸ­æœŸ(1-3å¤©)ã€çŸ­æœŸ(1-3ä¸ªæœˆ)ã€ä¸­æœŸ(3-6ä¸ªæœˆ)çš„æ¶¨è·Œæ¦‚ç‡å’Œå¹…åº¦åŒºé—´
- ç»™å‡ºæ˜ç¡®çš„æ“ä½œä½ç½®ï¼šä¹°å…¥åŒºé—´ã€åŠ ä»“ç‚¹ä½ã€å‡ä»“ç‚¹ä½ã€æ­¢æŸä½ç½®
- è¯„ä¼°ç”¨æˆ·è§‚ç‚¹çš„åˆç†æ€§ï¼Œæ•´åˆç”¨æˆ·è¡¥å……ä¿¡æ¯ä¼˜åŒ–é¢„æµ‹åˆ¤æ–­
- ç»“åˆç”¨æˆ·æŒä»“çŠ¶æ€ã€æŠ•èµ„ç‰¹ç‚¹å’Œæ˜“é”™å€¾å‘ï¼Œæä¾›ä¸ªæ€§åŒ–æ“ä½œå»ºè®®
- è¯†åˆ«å½“å‰æœ€éœ€è­¦æƒ•çš„é£é™©ç‚¹å’Œæœ€å€¼å¾—å…³æ³¨çš„æœºä¼šç‚¹

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“„ ç»¼åˆåˆ†ææŠ¥å‘Š
### ğŸ“Š ä¸ªè‚¡å½“å‰çŠ¶å†µ
### ğŸŒ å¤§ç›˜ä¸è¡Œä¸šç¯å¢ƒ  
### ğŸ‘¤ ç”¨æˆ·è§‚ç‚¹åˆ†æ
### ğŸ“ˆ æ¶¨è·Œé¢„æµ‹ä¸æ¦‚ç‡
### ğŸ¯ å…·ä½“æ“ä½œå»ºè®®
### âš ï¸ é£é™©æç¤º

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡800å­—
- é¿å…é‡å¤å„ä¸“é¡¹åˆ†æçš„å…·ä½“å†…å®¹ï¼Œé‡ç‚¹çªå‡ºç»¼åˆåˆ¤æ–­å’Œæ“ä½œæŒ‡å¯¼
- é¢„æµ‹å’Œå»ºè®®å¿…é¡»å…·ä½“é‡åŒ–ï¼Œé¿å…æ¨¡ç³Šè¡¨è¿°
- æ‰€æœ‰åˆ¤æ–­åŸºäºæ•°æ®åˆ†æï¼Œç»“è®ºè¦æœ‰æ˜ç¡®çš„å¯æ“ä½œæ€§
- é’ˆå¯¹ç”¨æˆ·ç‰¹ç‚¹ç»™å‡ºå·®å¼‚åŒ–çš„é£é™©æé†’å’Œæ“ä½œå»ºè®®"""
        
        user_message = f"""è¯·å¯¹{stock_name}ï¼ˆ{stock_code}ï¼‰è¿›è¡Œç»¼åˆåˆ†æï¼š

**è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

**å½“å‰è¡Œæƒ…æ•°æ®ï¼š**
{basic_info_section}

**å†å²åˆ†ææ•°æ®ï¼š**
{historical_summary}

**å¸‚åœºç¯å¢ƒæ•°æ®ï¼š**
{market_summary}

**ç”¨æˆ·é…ç½®ä¿¡æ¯ï¼š**
{user_profile_section}
{user_mistakes_section}
{user_opinion_section}"""
        
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        print(f'req length {len(user_message)}')
        
        # ä½¿ç”¨ç»Ÿä¸€çš„åˆ†æç”Ÿæˆå™¨
        generator = BaseAnalysisGenerator()
        result = generator.generate_analysis("comprehensive", messages, stock_code)
        result.data_sources = all_data_sources
        
        return result
        
    except Exception as e:
        # ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
        error_report = f"""# âŒ ç»¼åˆåˆ†æç”Ÿæˆå¤±è´¥

**é”™è¯¯ä¿¡æ¯:** {str(e)}

**æ—¶é—´:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ç¡®è®¤AIæœåŠ¡é…ç½®æ­£ç¡®
3. ç¨åé‡è¯•

## æ•°æ®æ¥æºï¼š
{len(all_data_sources)}ä¸ªæ•°æ®æºå·²æ”¶é›†ï¼Œä½†AIåˆ†æå¤±è´¥ã€‚"""
        
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
        print(f"ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        traceback.print_exc()
        
        return AnalysisResult(
            success=False,
            report=error_report,
            timestamp=datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            error_message=str(e),
            analysis_type="comprehensive",
            stock_code=stock_code,
            data_sources=all_data_sources
        )
