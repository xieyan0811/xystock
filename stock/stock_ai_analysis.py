"""
è‚¡ç¥¨AIåˆ†æå·¥å…·
æä¾›åŸºäºLLMçš„è‚¡ç¥¨å¸‚åœºåˆ†æåŠŸèƒ½ã€ç­¹ç åˆ†æåŠŸèƒ½ã€æ–°é—»åˆ†æåŠŸèƒ½å’ŒåŸºæœ¬é¢åˆ†æåŠŸèƒ½
"""

from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass
from llm.openai_client import OpenAIClient
import datetime
import sys
import os
import traceback

project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_dir not in sys.path:
    sys.path.append(project_dir)

from utils.string_utils import remove_markdown_format
from utils.data_formatters import get_stock_formatter


@dataclass
class AnalysisResult:
    """AIåˆ†æç»“æœçš„ç»Ÿä¸€æ ¼å¼"""
    success: bool
    report: str
    timestamp: str
    error_message: Optional[str] = None
    analysis_type: str = ""
    stock_code: str = ""
    data_sources: Optional[List[Dict]] = None


class AnalysisConfig:
    """AIåˆ†æé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        try:
            from config_manager import config
            self.config = config
        except Exception as e:
            print(f"åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            self.config = None
    
    def get_analysis_config(self, analysis_type: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šåˆ†æç±»å‹çš„é…ç½®"""
        if not self.config:
            return self._get_default_config(analysis_type)
        
        try:
            config_key = f"AI_ANALYSIS.{analysis_type.upper()}"
            return {
                'temperature': self.config.get(f'{config_key}.TEMPERATURE', 0.5),
                'model_type': self.config.get(f'{config_key}.MODEL_TYPE', 'default'),
                'cache_filename': self.config.get(f'{config_key}.CACHE_FILENAME', f'req_{analysis_type}.txt')
            }
        except Exception as e:
            print(f"è·å–{analysis_type}é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return self._get_default_config(analysis_type)
    
    def _get_default_config(self, analysis_type: str) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        defaults = {
            'technical': {'temperature': 0.5, 'model_type': 'inference', 'cache_filename': 'req_tech.txt'},
            'news': {'temperature': 0.7, 'model_type': 'default', 'cache_filename': 'req_news.txt'},
            'chip': {'temperature': 0.5, 'model_type': 'default', 'cache_filename': 'req_chip.txt'},
            'fundamental': {'temperature': 0.6, 'model_type': 'default', 'cache_filename': 'req_basic_info.txt'},
            'company': {'temperature': 0.5, 'model_type': 'default', 'cache_filename': 'req_company.txt'},
            'comprehensive': {'temperature': 0.4, 'model_type': 'default', 'cache_filename': 'req.txt'}
        }
        return defaults.get(analysis_type, defaults['comprehensive'])


class DataCollector:
    """æ•°æ®æ”¶é›†å™¨ - è´Ÿè´£æ”¶é›†å„ç§åˆ†ææ‰€éœ€çš„æ•°æ®"""
    
    def __init__(self):
        self.formatter = get_stock_formatter()
    
    def collect_stock_basic_info(self, stock_identity: Dict[str, Any]) -> Tuple[str, Optional[Dict]]:
        """æ”¶é›†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            from stock.stock_data_tools import get_stock_tools
            stock_tools = get_stock_tools()
            basic_info = stock_tools.get_basic_info(stock_identity, use_cache=True)
            
            if basic_info and 'error' not in basic_info:
                formatted_info = self.formatter.format_basic_info(basic_info, stock_identity)
                data_source = {
                    'type': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯',
                    'description': 'åŒ…å«å½“å‰ä»·æ ¼ã€æ¶¨è·Œé¢ã€æ¶¨è·Œå¹…ç­‰å®æ—¶æ•°æ®',
                    'timestamp': basic_info.get('update_time', 'æœªçŸ¥æ—¶é—´')
                }
                return formatted_info, data_source
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        
        return "", None
    
    def collect_historical_analyses(self, stock_code: str, stock_tools=None) -> Tuple[Dict[str, str], List[Dict]]:
        """æ”¶é›†å†å²åˆ†ææ•°æ®"""
        historical_analyses = {}
        data_sources = []
        
        if not stock_tools:
            return historical_analyses, data_sources
        
        analysis_types = {
            'technical': 'æŠ€æœ¯åˆ†æ',
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'news': 'æ–°é—»åˆ†æ',
            'chip': 'ç­¹ç åˆ†æ'
        }
        
        for analysis_type, description in analysis_types.items():
            try:
                cached_analysis = stock_tools.get_cached_ai_analysis(stock_code, analysis_type, use_cache=True)
                if cached_analysis and 'report' in cached_analysis:
                    historical_analyses[analysis_type] = cached_analysis['report']
                    data_sources.append({
                        'type': description,
                        'description': f'ç¼“å­˜çš„{description}æŠ¥å‘Š',
                        'timestamp': cached_analysis.get('timestamp', 'æœªçŸ¥æ—¶é—´')
                    })
            except Exception as e:
                print(f"è·å–{description}å¤±è´¥: {e}")
        
        return historical_analyses, data_sources
    
    def collect_market_data(self, market_tools=None, stock_identity: Dict[str, Any] = None) -> Tuple[str, str, List[Dict]]:
        """æ”¶é›†å¸‚åœºæ•°æ®"""
        market_report_text = ""
        market_ai_analysis = ""
        data_sources = []
        
        if not market_tools:
            try:
                from market.market_data_tools import get_market_tools
                market_tools = get_market_tools()
            except Exception as e:
                print(f"å¯¼å…¥market_toolså¤±è´¥: {e}")
                return market_report_text, market_ai_analysis, data_sources
        
        # æ ¹æ®è‚¡ç¥¨èº«ä»½ä¿¡æ¯ç¡®å®šå¯¹åº”çš„å¸‚åœºæŒ‡æ•°
        target_index = 'ä¸Šè¯æŒ‡æ•°'  # é»˜è®¤å€¼
        board_type = 'æœªçŸ¥æ¿å—'
        
        if stock_identity:
            # å¦‚æœstock_identityä¸­åŒ…å«æ¿å—ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨
            if 'board_type' in stock_identity and 'corresponding_index' in stock_identity:
                board_type = stock_identity['board_type']
                target_index = stock_identity['corresponding_index']
                stock_code = stock_identity.get('code', 'æœªçŸ¥')
                print(f"è‚¡ç¥¨{stock_code}å±äº{board_type}ï¼Œä½¿ç”¨{target_index}ä½œä¸ºå‚è€ƒæŒ‡æ•°")
            # å¦åˆ™ä½¿ç”¨é»˜è®¤çš„ä¸Šè¯æŒ‡æ•°
            else:
                print(f"è‚¡ç¥¨{stock_identity.get('code', 'æœªçŸ¥')}æœªåŒ…å«æ¿å—ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤çš„{target_index}ä½œä¸ºå‚è€ƒæŒ‡æ•°")
        
        # æ”¶é›†å¸‚åœºç»¼åˆæŠ¥å‘Š
        try:
            market_report = market_tools.get_comprehensive_market_report(use_cache=True)
            if market_report:
                from market.market_formatters import MarketTextFormatter
                data_sources.append({
                    'type': 'å¸‚åœºç»¼åˆæŠ¥å‘Š',
                    'description': 'åŒ…å«æŠ€æœ¯æŒ‡æ ‡ã€æƒ…ç»ªã€ä¼°å€¼ã€èµ„é‡‘æµå‘ç­‰å¸‚åœºæ•°æ®',
                    'timestamp': market_report.get('report_time', 'æœªçŸ¥æ—¶é—´')
                })
                market_report_text = MarketTextFormatter.format_summary_report(market_report)
        except Exception as e:
            print(f"è·å–å¸‚åœºç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")
        
        # æ”¶é›†AIå¤§ç›˜åˆ†æ
        try:
            market_ai_data = market_tools.get_ai_analysis(use_cache=True, index_name=target_index)
            if market_ai_data:
                if isinstance(market_ai_data, dict) and 'report' in market_ai_data:
                    market_ai_analysis = market_ai_data['report']
                data_sources.append({
                    'type': f'AI{target_index}åˆ†æ',
                    'description': f'åŸºäºAIæ¨¡å‹çš„{target_index}åˆ†ææŠ¥å‘Š',
                    'timestamp': market_ai_data.get('analysis_time', 'æœªçŸ¥æ—¶é—´')
                })
        except Exception as e:
            print(f"è·å–{target_index}åˆ†æå¤±è´¥: {e}")
        
        return market_report_text, market_ai_analysis, data_sources
    
    def collect_user_profile(self) -> Tuple[str, str, List[Dict]]:
        """æ”¶é›†ç”¨æˆ·ç”»åƒæ•°æ®"""
        user_profile_section = ""
        user_mistakes_section = ""
        data_sources = []
        
        try:
            from config_manager import config
            
            # ç”¨æˆ·ç”»åƒ
            user_profile_raw = config.get('USER_PROFILE.RAW', '').strip()
            if user_profile_raw:
                user_profile_section = f"## ç”¨æˆ·ç”»åƒ\n{user_profile_raw}\n"
                data_sources.append({
                    'type': 'ç”¨æˆ·ç”»åƒ',
                    'description': 'ç”¨æˆ·çš„æŠ•èµ„åå¥½ã€é£é™©æ‰¿å—èƒ½åŠ›ç­‰ä¿¡æ¯',
                    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
            
            # ç”¨æˆ·å¸¸çŠ¯é”™è¯¯
            user_mistakes = config.get('USER_PROFILE.MISTAKES', '')
            if user_mistakes:
                user_mistakes_section = f"## ç”¨æˆ·å¸¸çŠ¯é”™è¯¯\n{user_mistakes}\n"
                data_sources.append({
                    'type': 'ç”¨æˆ·å¸¸çŠ¯é”™è¯¯',
                    'description': 'ç”¨æˆ·åœ¨æŠ•èµ„è¿‡ç¨‹ä¸­å¸¸çŠ¯çš„é”™è¯¯å’Œè¯¯åŒº',
                    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
        except Exception as e:
            print(f"è·å–ç”¨æˆ·é…ç½®å¤±è´¥: {e}")
        
        return user_profile_section, user_mistakes_section, data_sources


class ReportFormatter:
    """æŠ¥å‘Šæ ¼å¼åŒ–å™¨ - è´Ÿè´£æ ¼å¼åŒ–å„ç§æ•°æ®ä¸ºæŠ¥å‘Šæ ¼å¼"""
    
    @staticmethod
    def format_historical_summary(historical_analyses: Dict[str, str], truncate_data: bool = False) -> str:
        """æ ¼å¼åŒ–å†å²åˆ†ææ‘˜è¦"""
        if not historical_analyses:
            return "\n\n## ğŸ“Š å†å²åˆ†ææ‘˜è¦\næœªæ‰¾åˆ°ç›¸å…³å†å²åˆ†ææ•°æ®ï¼Œå°†åŸºäºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n"
        
        analysis_types = {
            'technical': 'æŠ€æœ¯åˆ†æ',
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'news': 'æ–°é—»åˆ†æ',
            'chip': 'ç­¹ç åˆ†æ'
        }
        
        historical_summary = ""
        for analysis_type, report in historical_analyses.items():
            if truncate_data:
                summary = report[:300] + "..." if len(report) > 300 else report
            else:
                summary = report
            summary = remove_markdown_format(summary)
            historical_summary += f"\n## {analysis_types.get(analysis_type, analysis_type)}:\n\n{summary}\n"
        
        return historical_summary
    
    @staticmethod
    def format_market_summary(market_report_text: str, market_ai_analysis: str, truncate_data: bool = False) -> str:
        """æ ¼å¼åŒ–å¸‚åœºç¯å¢ƒåˆ†æ"""
        if not market_report_text and not market_ai_analysis:
            return "\n\n## ğŸŒ å¸‚åœºç¯å¢ƒåˆ†æ\næš‚æ— å¸‚åœºç¯å¢ƒæ•°æ®ã€‚\n\n"
        
        market_summary = ""
        
        if market_report_text:
            market_text_summary = market_report_text[:500] + "..." if truncate_data and len(market_report_text) > 500 else market_report_text
            market_summary += f"\n## å¸‚åœºç»¼åˆæŠ¥å‘Š:\n\n{market_text_summary}\n\n"
        
        if market_ai_analysis:
            ai_summary = market_ai_analysis[:300] + "..." if truncate_data and len(market_ai_analysis) > 300 else market_ai_analysis
            market_summary += f"\n{ai_summary}\n\n"
        
        return market_summary
    
    @staticmethod
    def format_user_opinion_section(user_opinion: str, user_position: str) -> Tuple[str, List[Dict]]:
        """æ ¼å¼åŒ–ç”¨æˆ·è§‚ç‚¹éƒ¨åˆ†"""
        user_opinion_section = ""
        data_sources = []
        
        if user_opinion.strip():
            user_opinion_section = f"## ç”¨æˆ·è§‚ç‚¹\n{user_opinion.strip()}\n\n"
            data_sources.append({
                'type': 'ç”¨æˆ·è§‚ç‚¹',
                'description': 'ç”¨æˆ·æä¾›çš„æŠ•èµ„è§‚ç‚¹å’Œçœ‹æ³•',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        if user_position and user_position.strip() and user_position.strip() != "ä¸ç¡®å®š":
            user_opinion_section += f"## ç”¨æˆ·å½“å‰æŒä»“çŠ¶æ€\n{user_position.strip()}\n\n"
            data_sources.append({
                'type': 'ç”¨æˆ·æŒä»“',
                'description': f'ç”¨æˆ·å½“å‰æŒä»“çŠ¶æ€ï¼š{user_position.strip()}',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        return user_opinion_section, data_sources


def _save_request_to_cache(content: str, filename: str):
    """ä¿å­˜è¯·æ±‚å†…å®¹åˆ°ç¼“å­˜æ–‡ä»¶"""
    try:
        cache_path = os.path.join(project_dir, "data", "cache", filename)
        with open(cache_path, "w", encoding="utf-8") as f:
            f.write(content)
    except Exception as e:
        print(f"ä¿å­˜è¯·æ±‚æ–‡ä»¶{filename}å¤±è´¥: {e}")


class BaseAnalysisGenerator:
    """åŸºç¡€åˆ†æç”Ÿæˆå™¨ - æä¾›é€šç”¨çš„åˆ†æç”ŸæˆåŠŸèƒ½"""
    
    def __init__(self):
        self.client = OpenAIClient()
        self.config_manager = AnalysisConfig()
    
    def generate_analysis(self, analysis_type: str, messages: List[Dict], stock_code: str = "") -> AnalysisResult:
        """é€šç”¨çš„åˆ†æç”Ÿæˆæ–¹æ³•"""
        config = self.config_manager.get_analysis_config(analysis_type)
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        if len(messages) > 1:
            _save_request_to_cache(messages[0]['content'] + "\n\n" + "@@@@@@@@" + "\n\n"  + messages[1]['content'], config['cache_filename'])

        try:
            response = self.client.chat(
                messages=messages,
                temperature=config['temperature'],
                model_type=config['model_type']
            )
            
            return AnalysisResult(
                success=True,
                report=response,
                timestamp=timestamp,
                analysis_type=analysis_type,
                stock_code=stock_code
            )
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆ{analysis_type}åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}"
            print(error_msg)
            traceback.print_exc()
            
            return AnalysisResult(
                success=False,
                report=error_msg,
                timestamp=timestamp,
                error_message=str(e),
                analysis_type=analysis_type,
                stock_code=stock_code
            )

def get_stock_info(stock_identity):
    from stock.stock_data_tools import get_stock_tools
    stock_tools = get_stock_tools()
    return stock_tools.get_basic_info(stock_identity, use_cache=True)

def generate_tech_analysis_report(
    stock_identity: Dict[str, Any],
    kline_info: Dict[str, Any] = None,
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨æŠ€æœ¯åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    kline_text = formatter.format_kline_data(kline_info)

    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨æŠ€æœ¯åˆ†æå¸ˆï¼Œä¸“ç²¾äºåŸºäºæŠ€æœ¯æŒ‡æ ‡è¿›è¡Œè‚¡ç¥¨åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®æŠ€æœ¯æ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„æŠ€æœ¯é¢åˆ†æï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æŠ€æœ¯é¢ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- åˆ†æç§»åŠ¨å¹³å‡çº¿ã€MACDã€RSIã€å¸ƒæ—å¸¦ç­‰å…³é”®æŠ€æœ¯æŒ‡æ ‡
- è¯†åˆ«æ”¯æ’‘é˜»åŠ›ä½å’Œä»·æ ¼è¶‹åŠ¿
- è¯„ä¼°å½“å‰è‚¡ä»·å˜åŠ¨å¯¹æŠ€æœ¯é¢çš„å½±å“
- æä¾›å…·ä½“æ•°å€¼å’Œä¸“ä¸šæŠ€æœ¯åˆ¤æ–­

**è¾“å‡ºæ ¼å¼ï¼š**
### ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ
### ğŸ“‰ ä»·æ ¼è¶‹åŠ¿åˆ†æ
### ğŸ¯ å…³é”®æŠ€æœ¯ä½

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- å…³æ³¨å½“å‰è‚¡ä»·è¡¨ç°å¯¹æŠ€æœ¯é¢çš„å½±å“
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ•°æ®ï¼Œä¸å¾—ç¼–é€ """

    user_message = f"""è¯·åŸºäºä»¥ä¸‹æ•°æ®å¯¹{stock_name}({stock_code})è¿›è¡ŒæŠ€æœ¯åˆ†æï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}
- è´§å¸ï¼š{stock_identity.get('currency_name', 'äººæ°‘å¸')}({stock_identity.get('currency_symbol', 'Â¥')})

**æŠ€æœ¯æ•°æ®ï¼š**
{basic_info_section}

{kline_text}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]

    return generator.generate_analysis("technical", messages, stock_code)


def generate_company_analysis_report(
    stock_identity: Dict[str, Any],
    fundamental_data: Dict[str, Any] = None
) -> AnalysisResult:
    """ç”Ÿæˆå…¬å¸åˆ†ææŠ¥å‘Š
    
    Args:
        stock_identity: è‚¡ç¥¨èº«ä»½ä¿¡æ¯
        fundamental_data: åŸºæœ¬é¢æ•°æ®ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        AnalysisResult: åˆ†æç»“æœ
    """
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')
    market_name = stock_identity.get('market_name', 'Aè‚¡')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    
    # è·å–åŸºæœ¬ä¿¡æ¯
    basic_info_section = ""
    if fundamental_data:
        basic_info_section = formatter.format_basic_info(fundamental_data, stock_identity)
    else:
        # å¦‚æœæ²¡æœ‰æä¾›åŸºæœ¬é¢æ•°æ®ï¼Œå°è¯•è·å–
        try:
            basic_info = get_stock_info(stock_identity)
            if basic_info and 'error' not in basic_info:
                basic_info_section = formatter.format_basic_info(basic_info, stock_identity)
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºETF
    is_etf = (market_name == 'ETF' or 
              stock_code.startswith('51') or stock_code.startswith('15') or stock_code.startswith('50') or
              'åŸºé‡‘' in stock_name or 'ETF' in stock_name)
    
    # ETFä½¿ç”¨ä¸åŒçš„åˆ†ææ¨¡æ¿
    if is_etf:
        system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ETFäº§å“åˆ†æå¸ˆï¼Œä¸“ç²¾äºETFåŸºé‡‘çš„ç»“æ„å’Œç­–ç•¥åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºETFçš„åŸºæœ¬ä¿¡æ¯ï¼ŒæŒ‰ç…§æŒ‡å®šè¦ç‚¹ç®€è¦åˆ†æè¯¥ETFäº§å“ã€‚

**åˆ†æè¦ç‚¹ï¼š**
äº§å“åŠŸèƒ½ â€”â€” ETFè·Ÿè¸ªä»€ä¹ˆæŒ‡æ•°ï¼ŸæŠ•èµ„ç­–ç•¥å’Œäº§å“å®šä½æ˜¯ä»€ä¹ˆï¼Ÿ
æŠ•èµ„ä»·å€¼ â€”â€” å®ƒæ»¡è¶³äº†ä»€ä¹ˆæŠ•èµ„éœ€æ±‚ï¼Œè§£å†³äº†å“ªäº›é…ç½®é—®é¢˜ï¼Ÿ
äº§å“ä¼˜åŠ¿ â€”â€” æŒ‡æ•°ç¼–åˆ¶æ–¹æ³•ã€ç®¡ç†èƒ½åŠ›ã€æµåŠ¨æ€§ç­‰ä¼˜åŠ¿åœ¨å“ªï¼Ÿ
å¸‚åœºåœ°ä½ â€”â€” åœ¨ETFå¸‚åœºæˆ–ç›¸å…³æ¿å—ä¸­çš„ç«äº‰åœ°ä½å¦‚ä½•ï¼Ÿ
æ›¿ä»£äº§å“ â€”â€” ä¸»è¦çš„åŒç±»ETFäº§å“æˆ–æ›¿ä»£æŠ•èµ„æ–¹å¼æœ‰å“ªäº›ï¼Ÿ
è´¹ç”¨æ”¶ç›Š â€”â€” ç®¡ç†è´¹ç‡å¦‚ä½•ï¼Ÿè§„æ¨¡æ•ˆåº”å’Œæˆæœ¬ä¼˜åŠ¿ä½“ç°åœ¨å“ªï¼Ÿ
æŠ•èµ„é£é™© â€”â€” è·Ÿè¸ªè¯¯å·®ã€æµåŠ¨æ€§é£é™©ã€å¸‚åœºé£é™©ç­‰ä¸»è¦é£é™©æ˜¯ä»€ä¹ˆï¼Ÿ

**è¾“å‡ºè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼Œå†…å®¹æ§åˆ¶åœ¨300å­—å·¦å³
- æ¯ä¸ªè¦ç‚¹ç®€æ˜æ‰¼è¦ï¼Œçªå‡ºæ ¸å¿ƒä¿¡æ¯
- åŸºäºçœŸå®ä¿¡æ¯åˆ†æï¼Œä¸å¾—ç¼–é€ 
- ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€"""
    else:
        system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å…¬å¸ç ”ç©¶åˆ†æå¸ˆï¼Œä¸“ç²¾äºä¸Šå¸‚å…¬å¸çš„å•†ä¸šæ¨¡å¼å’Œç«äº‰åŠ›åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºå…¬å¸åŸºæœ¬ä¿¡æ¯ï¼ŒæŒ‰ç…§æŒ‡å®šè¦ç‚¹ç®€è¦åˆ†æè¯¥å…¬å¸ã€‚

**åˆ†æè¦ç‚¹ï¼š**
ä¸»è¥ä¸šåŠ¡ â€”â€” å…¬å¸ä¸»è¦åšä»€ä¹ˆï¼Ÿæ ¸å¿ƒäº§å“/æœåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ
å¸‚åœºéœ€æ±‚ â€”â€” å®ƒæ»¡è¶³äº†ä»€ä¹ˆéœ€æ±‚ï¼Œè§£å†³äº†å“ªäº›é—®é¢˜ï¼Ÿ
æ ¸å¿ƒä¼˜åŠ¿ â€”â€” æŠ€æœ¯ã€èµ„æºæˆ–æ¨¡å¼ä¸Šçš„ç«äº‰åŠ›ä½“ç°åœ¨å“ªï¼Ÿ
äº§ä¸šåœ°ä½ â€”â€” åœ¨è¡Œä¸šæˆ–äº§ä¸šé“¾ä¸­çš„ä½ç½®æ˜¯ä»€ä¹ˆï¼Ÿ
ç«äº‰æ ¼å±€ â€”â€” ä¸»è¦ç«äº‰å¯¹æ‰‹æˆ–æ›¿ä»£æ–¹æ¡ˆæœ‰å“ªäº›ï¼Ÿ
ç›ˆåˆ©æ¨¡å¼ â€”â€” å…¬å¸å¦‚ä½•èµšé’±ï¼Ÿè´¢åŠ¡çŠ¶å†µå¦‚ä½•ï¼Ÿ
é£é™©æŒ‘æˆ˜ â€”â€” å¯èƒ½é¢ä¸´çš„ä¸»è¦é£é™©å’Œä¸ç¡®å®šæ€§æ˜¯ä»€ä¹ˆï¼Ÿ

**è¾“å‡ºè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼Œå†…å®¹æ§åˆ¶åœ¨300å­—å·¦å³
- æ¯ä¸ªè¦ç‚¹ç®€æ˜æ‰¼è¦ï¼Œçªå‡ºæ ¸å¿ƒä¿¡æ¯
- åŸºäºçœŸå®ä¿¡æ¯åˆ†æï¼Œé¿å…è¿‡åº¦æ¨æµ‹
- ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€"""

    # æ„å»ºç”¨æˆ·æ¶ˆæ¯
    product_type = "ETF" if is_etf else "å…¬å¸"
    user_message = f"""è¯·æŒ‰ç…§æŒ‡å®šè¦ç‚¹ï¼Œç®€è¦åˆ†æ{stock_name}ï¼ˆ{stock_code}ï¼‰è¿™ä¸ª{product_type}ï¼š

**{product_type}ä¿¡æ¯ï¼š**
- åç§°ï¼š{stock_name}
- ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{market_name}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦ç‚¹è¿›è¡Œåˆ†æï¼š
ä¸»è¥ä¸šåŠ¡ã€å¸‚åœºéœ€æ±‚ã€æ ¸å¿ƒä¼˜åŠ¿ã€äº§ä¸šåœ°ä½ã€ç«äº‰æ ¼å±€ã€ç›ˆåˆ©æ¨¡å¼ã€é£é™©æŒ‘æˆ˜"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]

    return generator.generate_analysis("company", messages, stock_code)


def generate_news_analysis_report(
    stock_identity: Dict[str, Any],
    news_data: List[Dict]
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨æ–°é—»åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    news_text = formatter.format_stock_news_data(news_data, has_content=True)
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œä¸“ç²¾äºè¯„ä¼°æ–°é—»äº‹ä»¶å¯¹è‚¡ç¥¨ä»·æ ¼çš„æ½œåœ¨å½±å“ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®æ–°é—»æ•°æ®ï¼Œè¯†åˆ«å…³é”®ä¿¡æ¯å¹¶è¯„ä¼°å¸‚åœºå½±å“ï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ¶ˆæ¯é¢ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- è¯†åˆ«å½±å“è¯¥è‚¡çš„å…³é”®æ–°é—»äº‹ä»¶ï¼ˆè´¢æŠ¥ã€åˆä½œã€æ”¿ç­–ã€çªå‘äº‹ä»¶ç­‰ï¼‰
- è¯„ä¼°æ–°é—»æ—¶æ•ˆæ€§ã€å¯ä¿¡åº¦å’Œå¸‚åœºå½±å“ç¨‹åº¦
- åˆ†ææŠ•èµ„è€…æƒ…ç»ªå˜åŒ–å’ŒçŸ­æœŸä»·æ ¼å½±å“
- å…³æ³¨æ–°é—»å¯¹å…¬å¸åŸºæœ¬é¢çš„å®è´¨æ€§å½±å“

**è¾“å‡ºæ ¼å¼ï¼š**
### ğŸ“° æ–°é—»æ¦‚è¿°
### ğŸ“Š å…³é”®ä¿¡æ¯åˆ†æ
### ğŸ’¹ å¸‚åœºå½±å“è¯„ä¼°
### âš ï¸ é£é™©å› ç´ è¯†åˆ«

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- é‡ç‚¹å…³æ³¨å¯¹æŠ•èµ„å†³ç­–æœ‰å®è´¨å½±å“çš„æ–°é—»å†…å®¹
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ–°é—»æ•°æ®ï¼Œä¸å¾—ç¼–é€ 
- å¦‚æ–°é—»æ•°æ®ä¸è¶³ï¼Œæ˜ç¡®æŒ‡å‡ºåˆ†æå±€é™æ€§"""

    user_message = f"""è¯·åˆ†æä»¥ä¸‹å…³äº{stock_name}({stock_code})çš„æœ€æ–°æ–°é—»ï¼Œè¯„ä¼°å…¶å¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“ï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- æ‰€å±å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

{basic_info_section}

=== æœ€æ–°æ–°é—»æ•°æ® ===

{news_text}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    
    return generator.generate_analysis("news", messages, stock_code)
        
        
def generate_chip_analysis_report(
    stock_identity: Dict[str, Any],
    chip_data: Dict[str, Any]
) -> AnalysisResult:
    """ç”Ÿæˆç­¹ç åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    chip_text = formatter.format_chip_data(chip_data)
    
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç­¹ç åˆ†æå¸ˆï¼Œä¸“ç²¾äºAè‚¡å¸‚åœºçš„ç­¹ç åˆ†å¸ƒæŠ€æœ¯åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®ç­¹ç æ•°æ®ï¼Œè¡¥å……å›¾è¡¨æ— æ³•ä½“ç°çš„æ•´ä½“è¶‹åŠ¿ã€ä¸»åŠ›è¡Œä¸ºå’Œå¸‚åœºåšå¼ˆæ´å¯Ÿï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›ç®€æ˜ã€ä¸“ä¸šçš„åˆ†æã€‚

**åˆ†æé‡ç‚¹ï¼š**
- è§£è¯»ç­¹ç åˆ†å¸ƒå½¢æ€ä¸é›†ä¸­åº¦ï¼Œåˆ¤æ–­ä¸»åŠ›æˆæœ¬åŒºé—´å’Œæ§ç›˜ç¨‹åº¦
- ç»“åˆç­¹ç å³°å€¼è¯†åˆ«å…³é”®æ”¯æ’‘ä¸å‹åŠ›ä½
- å…³æ³¨ç­¹ç è¿ç§»ã€å¼‚åŠ¨è½¬ç§»ç‡ç­‰å˜åŒ–ï¼Œè¯†åˆ«å¸‚åœºä¿¡å·
- å¯ç”¨ä¸»åŠ›æˆæœ¬ä¹–ç¦»ç‡ã€ç­¹ç ç¨³å®šæŒ‡æ•°ç­‰æŒ‡æ ‡è¾…åŠ©åˆ†æ

**è¾“å‡ºæ ¼å¼ï¼š**
### ğŸ“Š ç­¹ç åˆ†å¸ƒæ¦‚å†µ
### ğŸ¯ ä¸»åŠ›è¡Œä¸ºç”»åƒ
### âš¡ å‹åŠ›æ”¯æ’‘åˆ†æ
### ğŸ’¡ ç­¹ç å˜åŒ–ä¿¡å·

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- ä¸é‡å¤å›¾è¡¨å·²å±•ç¤ºçš„ç»†èŠ‚ï¼Œåªè¡¥å……æ•´ä½“è¶‹åŠ¿å’Œä¸»åŠ›æ„å›¾ç­‰å…³é”®å†…å®¹
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®ç­¹ç æ•°æ®ï¼Œä¸å¾—ç¼–é€ 
"""
    user_message = f"""è¯·å¯¹{stock_name}({stock_code})è¿›è¡Œç­¹ç åˆ†æï¼ŒåŸºäºä»¥ä¸‹æ•°æ®ï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

**åŸºæœ¬ä¿¡æ¯ï¼š**
{basic_info_section}

**ç­¹ç æ•°æ®ï¼š**
{chip_text}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    
    return generator.generate_analysis("chip", messages, stock_code)


def generate_fundamental_analysis_report(
    stock_identity: Dict[str, Any],
    fundamental_data: Dict[str, Any]
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨åŸºæœ¬é¢åˆ†ææŠ¥å‘Š"""
    
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')
    market_name = stock_identity.get('market_name', 'Aè‚¡')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_basic_info(fundamental_data, stock_identity)
    currency_name = stock_identity.get('currency_name', 'äººæ°‘å¸')
    currency_symbol = stock_identity.get('currency_symbol', 'Â¥')
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºETFï¼Œå¦‚æœæ˜¯åˆ™è·å–æŒä»“ä¿¡æ¯
    is_etf = (market_name == 'ETF' or 
              stock_code.startswith('51') or stock_code.startswith('15') or stock_code.startswith('50') or
              'åŸºé‡‘' in stock_name or 'ETF' in stock_name)
    
    etf_holdings_section = ""
    if is_etf:
        try:
            from stock.etf_holdings_fetcher import etf_holdings_fetcher
            holdings_data = etf_holdings_fetcher.get_etf_holdings(stock_code, top_n=10)
            
            if 'error' not in holdings_data:
                etf_holdings_section = formatter.format_etf_holdings_for_ai(holdings_data, max_stocks=10)
                latest_quarter = holdings_data.get('latest_quarter', 'æœªçŸ¥å­£åº¦')
                print(f"âœ… æˆåŠŸè·å–ETF {stock_code} æŒä»“ä¿¡æ¯ç”¨äºAIåˆ†æï¼ˆ{latest_quarter}ï¼‰")
            else:
                print(f"âš ï¸ è·å–ETF {stock_code} æŒä»“ä¿¡æ¯å¤±è´¥: {holdings_data['error']}")
        except Exception as e:
            print(f"âŒ è·å–ETFæŒä»“ä¿¡æ¯æ—¶å‡ºé”™: {e}")
    
    # ETFå’Œè‚¡ç¥¨ä½¿ç”¨ä¸åŒçš„åˆ†ææ¨¡æ¿
    if is_etf:
        system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ETFåŸºé‡‘åˆ†æå¸ˆï¼Œä¸“ç²¾äºETFäº§å“çš„ç»“æ„åˆ†æå’ŒæŠ•èµ„ä»·å€¼è¯„ä¼°ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºETFçš„çœŸå®æŒä»“æ•°æ®å’ŒåŸºæœ¬ä¿¡æ¯ï¼Œæä¾›ä¸“ä¸šã€å®¢è§‚çš„ETFåˆ†æï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- ETFè·Ÿè¸ªæŒ‡æ•°åˆ†æï¼šåˆ†æè·Ÿè¸ªè¯¯å·®ã€ç®¡ç†è´¹ç”¨ã€æµåŠ¨æ€§ç­‰å…³é”®æŒ‡æ ‡
- æŒä»“ç»“æ„åˆ†æï¼šåˆ†ææŒä»“é›†ä¸­åº¦ã€è¡Œä¸šåˆ†å¸ƒã€æƒé‡è‚¡ç‰¹å¾
- æŠ•èµ„ä»·å€¼è¯„ä¼°ï¼šè¯„ä¼°ETFçš„æŠ•èµ„é€‚ç”¨æ€§å’Œé£é™©æ”¶ç›Šç‰¹å¾
- å¸‚åœºè¡¨ç°åˆ†æï¼šåˆ†æETFç›¸å¯¹åŸºå‡†æŒ‡æ•°çš„è¡¨ç°å’ŒæŠ˜æº¢ä»·æƒ…å†µ

**è¾“å‡ºæ ¼å¼ï¼š**
### ğŸ“Š ETFäº§å“æ¦‚å†µ
### ğŸ¢ æŒä»“ç»“æ„åˆ†æ
### âš–ï¸ æŠ•èµ„ä»·å€¼è¯„ä¼°
### ğŸ“ˆ å¸‚åœºè¡¨ç°ä¸é£é™©

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡600å­—
- é‡ç‚¹åˆ†ææŒä»“è‚¡ç¥¨çš„è´¨é‡å’Œé£é™©åˆ†æ•£æ•ˆæœ
- ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€ï¼Œä¸åŒ…å«å…·ä½“æŠ•èµ„å»ºè®®
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ•°æ®ï¼Œä¸¥ç¦ç¼–é€ æ•°æ®æˆ–ä¸»è§‚è‡†æµ‹"""
    else:
        system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå¸ˆï¼Œä¸“ç²¾äºæ·±å…¥çš„è´¢åŠ¡å’ŒåŸºæœ¬é¢åˆ†æã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºçœŸå®è´¢åŠ¡æ•°æ®ï¼Œæä¾›ä¸“ä¸šã€å®¢è§‚çš„åŸºæœ¬é¢åˆ†æï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›åŸºæœ¬é¢ä¾æ®ã€‚

**åˆ†æé‡ç‚¹ï¼š**
- è´¢åŠ¡å¥åº·è¯„ä¼°ï¼šåˆ†æèµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµå’Œç›ˆåˆ©èƒ½åŠ›
- ä¼°å€¼åˆ†æï¼šè®¡ç®—å¹¶è§£é‡ŠPEã€PBã€PEGç­‰å…³é”®ä¼°å€¼æŒ‡æ ‡
- å¢é•¿æ½œåŠ›è¯„ä¼°ï¼šåˆ†æè¥æ”¶å’Œåˆ©æ¶¦å¢é•¿è¶‹åŠ¿
- é£é™©è¯„ä¼°ï¼šè¯†åˆ«è´¢åŠ¡ã€ç»è¥ã€è¡Œä¸šå’Œå¸‚åœºé£é™©å› ç´ 

**è¾“å‡ºæ ¼å¼ï¼š**
### ğŸ“Š åŸºæœ¬é¢æ¦‚å†µ
### ğŸ’° è´¢åŠ¡æŒ‡æ ‡åˆ†æ
### ğŸ“ˆ ä¼°å€¼ä¸å¢é•¿åˆ†æ
### âš–ï¸ ä¼˜åŠ¿ä¸é£é™©åˆ†æ

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—
- ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€ï¼Œä¸åŒ…å«å…·ä½“æŠ•èµ„å»ºè®®
- æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ•°æ®ï¼Œä¸¥ç¦ç¼–é€ æ•°æ®æˆ–ä¸»è§‚è‡†æµ‹"""

    # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ŒETFåŒ…å«æŒä»“ä¿¡æ¯
    if is_etf and etf_holdings_section:
        user_message = f"""è¯·åŸºäºä»¥ä¸‹çœŸå®æ•°æ®ï¼Œå¯¹{stock_name}({stock_code})è¿›è¡Œå…¨é¢çš„ETFåŸºæœ¬é¢åˆ†æï¼š

**ETFä¿¡æ¯ï¼š**
- äº§å“åç§°ï¼š{stock_name}
- ETFä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{market_name}
- è´§å¸ï¼š{currency_name}({currency_symbol})

**åŸºæœ¬é¢æ•°æ®ï¼š**
{basic_info_section}

**æŒä»“ç»“æ„æ•°æ®ï¼š**
{etf_holdings_section}"""
    else:
        user_message = f"""è¯·åŸºäºä»¥ä¸‹çœŸå®æ•°æ®ï¼Œå¯¹{stock_name}({stock_code})è¿›è¡Œå…¨é¢çš„åŸºæœ¬é¢åˆ†æï¼š

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{market_name}
- è´§å¸ï¼š{currency_name}({currency_symbol})

**åŸºæœ¬é¢æ•°æ®ï¼š**
{basic_info_section}"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]

    return generator.generate_analysis("fundamental", messages, stock_code)


def generate_comprehensive_analysis_report(
    stock_identity: Dict[str, Any],
    user_opinion: str = "",
    user_position: str = "ä¸ç¡®å®š",
    stock_tools=None,
    market_tools=None,
    truncate_data: bool = False
) -> AnalysisResult:
    """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')
    
    # å¯¼å…¥é…ç½®ç®¡ç†å™¨å’Œæç¤ºè¯
    import sys
    import os
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.append(project_root)
    from config_manager import config
    from stock.analysis_prompts import get_core_principles
    
    # æ ¹æ®é…ç½®è·å–æ ¸å¿ƒåŸåˆ™
    risk_preference = config.get('ANALYSIS.RISK_PREFERENCE', 'neutral')
    custom_principles = config.get('ANALYSIS.CUSTOM_PRINCIPLES', '')
    core_principles = get_core_principles(risk_preference, custom_principles)
    
    collector = DataCollector()
    formatter = ReportFormatter()
    all_data_sources = []
    
    try:
        # 1. æ”¶é›†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        basic_info_section, basic_info_source = collector.collect_stock_basic_info(stock_identity)
        if basic_info_source:
            all_data_sources.append(basic_info_source)
        
        # 2. æ”¶é›†å†å²åˆ†ææ•°æ®
        historical_analyses, historical_sources = collector.collect_historical_analyses(stock_code, stock_tools)
        all_data_sources.extend(historical_sources)
        
        # å¦‚æœæ²¡æœ‰å†å²åˆ†ææ•°æ®ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
        if not historical_analyses:
            all_data_sources.append({
                'type': 'æç¤ºä¿¡æ¯',
                'description': 'æœªæ‰¾åˆ°å†å²åˆ†ææ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬ä¿¡æ¯è¿›è¡Œåˆ†æ',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        # 3. æ”¶é›†å¤§ç›˜æ•°æ®
        market_report_text, market_ai_analysis, market_sources = collector.collect_market_data(market_tools, stock_identity)
        all_data_sources.extend(market_sources)
        
        # 4. æ”¶é›†ç”¨æˆ·ç”»åƒæ•°æ®
        user_profile_section, user_mistakes_section, user_sources = collector.collect_user_profile()
        all_data_sources.extend(user_sources)
        
        # 5. æ ¼å¼åŒ–ç”¨æˆ·è§‚ç‚¹å’ŒæŒä»“ä¿¡æ¯
        user_opinion_section, user_opinion_sources = formatter.format_user_opinion_section(user_opinion, user_position)
        all_data_sources.extend(user_opinion_sources)
        
        # 6. æ ¼å¼åŒ–å„éƒ¨åˆ†å†…å®¹
        historical_summary = formatter.format_historical_summary(historical_analyses, truncate_data)
        market_summary = formatter.format_market_summary(market_report_text, market_ai_analysis, truncate_data)
        
        system_message = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„é¡¾é—®å’Œè‚¡ç¥¨åˆ†æå¸ˆï¼Œä»¥è¯šå®ã€ç›´æ¥çš„åˆ†æé£æ ¼è‘—ç§°ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºAIå·²ç”Ÿæˆçš„å„ç±»åˆ†æå’Œå®æ—¶æ•°æ®ï¼Œå¯¹è‚¡ç¥¨å½“å‰çš„æŠ•èµ„ä»·å€¼è¿›è¡Œé«˜åº¦å‡ç»ƒçš„ç»¼åˆåˆ¤æ–­ï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ˜ç¡®æŒ‡å¯¼ã€‚

{core_principles}

**åˆ†æé‡ç‚¹ï¼š**
- æ•´åˆæŠ€æœ¯é¢ã€åŸºæœ¬é¢ã€æ¶ˆæ¯é¢ã€ç­¹ç é¢åˆ†æï¼Œè¯†åˆ«æ ¸å¿ƒé©±åŠ¨å› ç´ å’Œä¸»è¦çŸ›ç›¾
- é¢„æµ‹å…·ä½“æ¶¨è·Œå¹…åº¦ï¼šè¶…çŸ­æœŸ(1-3å¤©)ã€çŸ­æœŸ(1-3ä¸ªæœˆ)ã€ä¸­æœŸ(3-6ä¸ªæœˆ)çš„æ¶¨è·Œæ¦‚ç‡å’Œå¹…åº¦åŒºé—´
- ç»™å‡ºæ˜ç¡®çš„æ“ä½œä½ç½®ï¼šä¹°å…¥åŒºé—´ã€åŠ ä»“ç‚¹ä½ã€å‡ä»“ç‚¹ä½ã€æ­¢æŸä½ç½®
- æç¤ºè´Ÿé¢ä¿¡å·ï¼šä¸šç»©å¤§å¹…ä¸‹æ»‘ã€è´¢åŠ¡é€ å‡é£é™©ã€è¡Œä¸šè¡°é€€ã€æŠ€æœ¯ç ´ä½ç­‰
- è¯„ä¼°ç”¨æˆ·è§‚ç‚¹çš„åˆç†æ€§ï¼Œå¦‚æœç”¨æˆ·çœ‹å¥½ä½†æ•°æ®æ˜¾ç¤ºé£é™©å¾ˆå¤§ï¼Œè¦æ˜ç¡®æé†’
- ç»“åˆç”¨æˆ·æŒä»“çŠ¶æ€ã€æŠ•èµ„ç‰¹ç‚¹å’Œæ˜“é”™å€¾å‘ï¼Œæä¾›ä¸ªæ€§åŒ–æ“ä½œå»ºè®®
- è¯†åˆ«å½“å‰æœ€éœ€è­¦æƒ•çš„é£é™©ç‚¹å’Œæœ€å€¼å¾—å…³æ³¨çš„æœºä¼šç‚¹

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“„ ç»¼åˆåˆ†ææŠ¥å‘Š
### ğŸ“Š ä¸ªè‚¡å½“å‰çŠ¶å†µ
### ğŸŒ å¤§ç›˜ä¸è¡Œä¸šç¯å¢ƒ  
### ğŸ‘¤ ç”¨æˆ·è§‚ç‚¹åˆ†æ
### ğŸ“ˆ æ¶¨è·Œé¢„æµ‹ä¸æ¦‚ç‡
### ğŸ¯ å…·ä½“æ“ä½œå»ºè®®
### âš ï¸ é£é™©æç¤º

**åˆ†æè¦æ±‚ï¼š**
- ç”¨ä¸­æ–‡æ’°å†™ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡800å­—
- é¿å…é‡å¤å„ä¸“é¡¹åˆ†æçš„å…·ä½“å†…å®¹ï¼Œé‡ç‚¹çªå‡ºç»¼åˆåˆ¤æ–­å’Œæ“ä½œæŒ‡å¯¼
- é¢„æµ‹å’Œå»ºè®®å¿…é¡»å…·ä½“é‡åŒ–ï¼Œé¿å…æ¨¡ç³Šè¡¨è¿°
- æ‰€æœ‰åˆ¤æ–­åŸºäºæ•°æ®åˆ†æï¼Œç»“è®ºè¦æœ‰æ˜ç¡®çš„å¯æ“ä½œæ€§
- **å¯¹äºä¸å€¼å¾—ä¹°çš„è‚¡ç¥¨è¦ç›´æ¥è¯´å‡ºæ¥ï¼Œä¸è¦ç»™æŠ•èµ„è€…è™šå‡å¸Œæœ›**
- é’ˆå¯¹ç”¨æˆ·ç‰¹ç‚¹ç»™å‡ºå·®å¼‚åŒ–çš„é£é™©æé†’å’Œæ“ä½œå»ºè®®"""
        
        user_message = f"""è¯·å¯¹{stock_name}ï¼ˆ{stock_code}ï¼‰è¿›è¡Œç»¼åˆåˆ†æï¼š

# è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼š

- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

# å½“å‰è¡Œæƒ…æ•°æ®ï¼š

{basic_info_section}

# å·²æœ‰åˆ†ææ•°æ®ï¼š

{historical_summary}

# å¸‚åœºç¯å¢ƒæ•°æ®ï¼š

{market_summary}

# ç”¨æˆ·é…ç½®ä¿¡æ¯ï¼š

{user_profile_section}
{user_mistakes_section}
{user_opinion_section}"""
        
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        print(f'req length {len(user_message)}')
        
        # ä½¿ç”¨ç»Ÿä¸€çš„åˆ†æç”Ÿæˆå™¨
        generator = BaseAnalysisGenerator()
        result = generator.generate_analysis("comprehensive", messages, stock_code)
        result.data_sources = all_data_sources
        
        return result
        
    except Exception as e:
        # ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
        error_report = f"""# âŒ ç»¼åˆåˆ†æç”Ÿæˆå¤±è´¥

**é”™è¯¯ä¿¡æ¯:** {str(e)}

**æ—¶é—´:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ç¡®è®¤AIæœåŠ¡é…ç½®æ­£ç¡®
3. ç¨åé‡è¯•

## æ•°æ®æ¥æºï¼š
{len(all_data_sources)}ä¸ªæ•°æ®æºå·²æ”¶é›†ï¼Œä½†AIåˆ†æå¤±è´¥ã€‚"""
        
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
        print(f"ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        traceback.print_exc()
        
        return AnalysisResult(
            success=False,
            report=error_report,
            timestamp=datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            error_message=str(e),
            analysis_type="comprehensive",
            stock_code=stock_code,
            data_sources=all_data_sources
        )
