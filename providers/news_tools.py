"""
æ–°é—»å·¥å…·æ¨¡å—

æä¾›è‚¡ç¥¨æ–°é—»ã€å…¬å‘Šã€ç ”ç©¶æŠ¥å‘Šç­‰ä¿¡æ¯çš„è·å–å’Œåˆ†æåŠŸèƒ½ã€‚

è®¾è®¡æ¶æ„ï¼š
1. FinGenius WebSearch æ•°æ®æº - æ¥è‡ªæœç´¢å¼•æ“ï¼ˆç™¾åº¦/Google/Bing/DuckDuckGoï¼‰
   â””â”€â”€ search_stock_news_by_fg_smart() - æ™ºèƒ½æœç´¢è‚¡ç¥¨æ–°é—»
2. akshare ä¸œè´¢æ•°æ®æº - æ¥è‡ªä¸œæ–¹è´¢å¯Œï¼ˆæ–°é—»/å…¬å‘Š/ç ”æŠ¥ï¼‰
   â””â”€â”€ get_stock_news_by_akshare() - è·å–è‚¡ç¥¨å®Œæ•´ä¿¡æ¯

ä¸»è¦åŠŸèƒ½ï¼š
- è‚¡ç¥¨æ–°é—»ã€å…¬å‘Šã€ç ”ç©¶æŠ¥å‘Šè·å–
- å¤šæœç´¢å¼•æ“æ–°é—»æœç´¢
- æ•°æ®åˆ†æå’Œå±•ç¤ºåŠŸèƒ½
"""

import akshare as ak
from datetime import datetime
import re
from collections import Counter
import asyncio
import sys


def run_async_in_notebook(coro):
    """
    åœ¨Jupyter notebookç¯å¢ƒä¸­å®‰å…¨è¿è¡Œå¼‚æ­¥å‡½æ•°çš„è¾…åŠ©å‡½æ•°
    
    Args:
        coro: åç¨‹å¯¹è±¡
    
    Returns:
        å¼‚æ­¥å‡½æ•°çš„ç»“æœ
    """
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨Jupyterç¯å¢ƒä¸­
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœå·²æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå°è¯•ä½¿ç”¨nest_asyncio
            try:
                import nest_asyncio
                nest_asyncio.apply()
                return asyncio.run(coro)
            except ImportError:
                # å¦‚æœæ²¡æœ‰nest_asyncioï¼Œæä¾›æ›¿ä»£æ–¹æ¡ˆ
                print("âš ï¸ å»ºè®®å®‰è£… nest_asyncio: pip install nest_asyncio")
                print("   å½“å‰ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
                # åˆ›å»ºä»»åŠ¡å¹¶åœ¨å½“å‰å¾ªç¯ä¸­è¿è¡Œ
                task = asyncio.create_task(coro)
                return loop.run_until_complete(task)
        else:
            # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œæ­£å¸¸ä½¿ç”¨asyncio.run
            return asyncio.run(coro)
    except RuntimeError:
        # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
        return asyncio.run(coro)


class FinGeniusWebSearch:
    """
    FinGenius Webæœç´¢å·¥å…·å°è£…ç±»
    """
    def __init__(self):
        self.web_search = None
        self._setup_fingenius_path()
        self._initialize_web_search()
    
    def _setup_fingenius_path(self):
        """è®¾ç½®FinGeniusé¡¹ç›®è·¯å¾„"""
        fingenius_dir = "/exports/stock/git/FinGenius"
        if fingenius_dir not in sys.path:
            sys.path.insert(0, fingenius_dir)
    
    def _initialize_web_search(self):
        """åˆå§‹åŒ–WebSearchå·¥å…·"""
        try:
            FINGENIUS_DIR = "/exports/stock/git/FinGenius"
            if FINGENIUS_DIR not in sys.path:
                sys.path.insert(0, FINGENIUS_DIR)            
            from src.tool.web_search import WebSearch
            self.web_search = WebSearch()
            print("âœ“ FinGenius WebSearchå·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            print(f"âŒ å¯¼å…¥FinGenius WebSearchå¤±è´¥: {e}")
            self.web_search = None
        except Exception as e:
            print(f"âŒ åˆ›å»ºWebSearchå®ä¾‹å¤±è´¥: {e}")
            self.web_search = None
    
    async def search_news(self, query, num_results=5, lang="zh", country="cn", fetch_content=False):
        """
        æœç´¢æ–°é—»
        
        Args:
            query: æœç´¢å…³é”®è¯
            num_results: è¿”å›ç»“æœæ•°é‡
            lang: è¯­è¨€ ("zh" æˆ– "en")
            country: å›½å®¶ä»£ç  ("cn", "us" ç­‰)
            fetch_content: æ˜¯å¦è·å–è¯¦ç»†å†…å®¹
        
        Returns:
            æœç´¢ç»“æœå¯¹è±¡
        """
        if not self.web_search:
            print("âŒ WebSearchå·¥å…·æœªåˆå§‹åŒ–")
            return None
        
        try:
            result = await self.web_search.execute(
                query=query,
                num_results=num_results,
                lang=lang,
                country=country,
                fetch_content=fetch_content
            )
            return result
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return None
    
    def is_available(self):
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        return self.web_search is not None


def search_stock_news_web(stock_name, stock_code=None, num_results=5, search_type="chinese"):
    """
    ä½¿ç”¨FinGenius web_searchæœç´¢è‚¡ç¥¨ç›¸å…³æ–°é—»
    
    Args:
        stock_name: è‚¡ç¥¨åç§°ï¼Œå¦‚ "æ‹›å•†é“¶è¡Œ", "Apple"
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "600036", "AAPL"ï¼ˆå¯é€‰ï¼‰
        num_results: è¿”å›ç»“æœæ•°é‡
        search_type: æœç´¢ç±»å‹ ("chinese" æˆ– "english")
    
    Returns:
        dict: åŒ…å«æœç´¢ç»“æœçš„å­—å…¸
    """
    print(f"ğŸ” ä½¿ç”¨FinGenius web_searchæœç´¢è‚¡ç¥¨æ–°é—»: {stock_name}")
    
    # åˆå§‹åŒ–æœç´¢å·¥å…·
    search_tool = FinGeniusWebSearch()
    
    if not search_tool.is_available():
        print("âŒ FinGenius WebSearchå·¥å…·ä¸å¯ç”¨")
        return {
            'success': False,
            'error': 'WebSearchå·¥å…·ä¸å¯ç”¨',
            'results': []
        }
    
    # æ„å»ºæœç´¢æŸ¥è¯¢
    if search_type == "chinese":
        if stock_code:
            query = f"{stock_name} {stock_code} æœ€æ–°æ–°é—» è‚¡ç¥¨"
        else:
            query = f"{stock_name} æœ€æ–°æ–°é—» è‚¡ç¥¨"
        lang = "zh"
        country = "cn"
    else:
        if stock_code:
            query = f"{stock_name} {stock_code} latest news stock"
        else:
            query = f"{stock_name} latest news stock"
        lang = "en"
        country = "us"
    
    try:
        # è¿è¡Œå¼‚æ­¥æœç´¢ - ä½¿ç”¨è¾…åŠ©å‡½æ•°å¤„ç†Jupyterç¯å¢ƒå…¼å®¹æ€§
        result = run_async_in_notebook(search_tool.search_news(
            query=query,
            num_results=num_results,
            lang=lang,
            country=country,
            fetch_content=False
        ))
        
        if result and hasattr(result, 'results'):
            processed_results = []
            for item in result.results:
                processed_item = {
                    'title': item.title,
                    'url': item.url,
                    'description': getattr(item, 'description', ''),
                    'source': getattr(item, 'source', ''),
                    'position': getattr(item, 'position', 0),
                    'relevance_score': 0.8  # é»˜è®¤ç›¸å…³æ€§è¯„åˆ†
                }
                processed_results.append(processed_item)
            
            return {
                'success': True,
                'query': query,
                'total_results': len(processed_results),
                'results': processed_results,
                'metadata': {
                    'language': lang,
                    'country': country,
                    'search_engine': 'FinGenius WebSearch'
                }
            }
        else:
            return {
                'success': False,
                'error': 'æœªæ‰¾åˆ°æœç´¢ç»“æœ',
                'results': []
            }
            
    except Exception as e:
        print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'success': False,
            'error': str(e),
            'results': []
        }


def search_stock_news_web_sync(stock_name, stock_code=None, num_results=5, search_type="chinese"):
    """
    ä½¿ç”¨FinGenius web_searchæœç´¢è‚¡ç¥¨ç›¸å…³æ–°é—»ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œé¿å…å¼‚æ­¥é—®é¢˜ï¼‰
    
    Args:
        stock_name: è‚¡ç¥¨åç§°ï¼Œå¦‚ "æ‹›å•†é“¶è¡Œ", "Apple"
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "600036", "AAPL"ï¼ˆå¯é€‰ï¼‰
        num_results: è¿”å›ç»“æœæ•°é‡
        search_type: æœç´¢ç±»å‹ ("chinese" æˆ– "english")
    
    Returns:
        dict: åŒ…å«æœç´¢ç»“æœçš„å­—å…¸
    """
    print(f"ğŸ” ä½¿ç”¨FinGenius web_searchæœç´¢è‚¡ç¥¨æ–°é—»ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰: {stock_name}")
    
    # åˆå§‹åŒ–æœç´¢å·¥å…·
    search_tool = FinGeniusWebSearch()
    
    if not search_tool.is_available():
        print("âŒ FinGenius WebSearchå·¥å…·ä¸å¯ç”¨")
        return {
            'success': False,
            'error': 'WebSearchå·¥å…·ä¸å¯ç”¨',
            'results': []
        }
    
    # æ„å»ºæœç´¢æŸ¥è¯¢
    if search_type == "chinese":
        if stock_code:
            query = f"{stock_name} {stock_code} æœ€æ–°æ–°é—» è‚¡ç¥¨"
        else:
            query = f"{stock_name} æœ€æ–°æ–°é—» è‚¡ç¥¨"
        lang = "zh"
        country = "cn"
    else:
        if stock_code:
            query = f"{stock_name} {stock_code} latest news stock"
        else:
            query = f"{stock_name} latest news stock"
        lang = "en"
        country = "us"
    
    try:
        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°
        import threading
        import queue
        
        result_queue = queue.Queue()
        exception_queue = queue.Queue()
        
        def run_search():
            try:
                # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                result = loop.run_until_complete(search_tool.search_news(
                    query=query,
                    num_results=num_results,
                    lang=lang,
                    country=country,
                    fetch_content=False
                ))
                
                result_queue.put(result)
                loop.close()
            except Exception as e:
                exception_queue.put(e)
        
        search_thread = threading.Thread(target=run_search)
        search_thread.start()
        search_thread.join(timeout=30)  # 30ç§’è¶…æ—¶
        
        if not exception_queue.empty():
            raise exception_queue.get()
        
        if result_queue.empty():
            raise TimeoutError("æœç´¢è¶…æ—¶")
        
        result = result_queue.get()
        
        if result and hasattr(result, 'results'):
            processed_results = []
            for item in result.results:
                processed_item = {
                    'title': item.title,
                    'url': item.url,
                    'description': getattr(item, 'description', ''),
                    'source': getattr(item, 'source', ''),
                    'position': getattr(item, 'position', 0),
                    'relevance_score': 0.8  # é»˜è®¤ç›¸å…³æ€§è¯„åˆ†
                }
                processed_results.append(processed_item)
            
            return {
                'success': True,
                'query': query,
                'total_results': len(processed_results),
                'results': processed_results,
                'metadata': {
                    'language': lang,
                    'country': country,
                    'search_engine': 'FinGenius WebSearch (åŒæ­¥ç‰ˆæœ¬)'
                }
            }
        else:
            return {
                'success': False,
                'error': 'æœªæ‰¾åˆ°æœç´¢ç»“æœ',
                'results': []
            }
            
    except Exception as e:
        print(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'success': False,
            'error': str(e),
            'results': []
        }


def search_stock_news_by_fg_smart(stock_name, stock_code=None, num_results=5, search_type="chinese"):
    """
    æ™ºèƒ½æœç´¢è‚¡ç¥¨æ–°é—» - è‡ªåŠ¨å¤„ç†å¼‚æ­¥é—®é¢˜
    
    å…ˆå°è¯•å¼‚æ­¥ç‰ˆæœ¬ï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨åˆ‡æ¢åˆ°åŒæ­¥ç‰ˆæœ¬
    
    Args:
        stock_name: è‚¡ç¥¨åç§°ï¼Œå¦‚ "æ‹›å•†é“¶è¡Œ", "Apple"
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "600036", "AAPL"ï¼ˆå¯é€‰ï¼‰
        num_results: è¿”å›ç»“æœæ•°é‡
        search_type: æœç´¢ç±»å‹ ("chinese" æˆ– "english")
    
    Returns:
        dict: åŒ…å«æœç´¢ç»“æœçš„å­—å…¸ï¼ŒåŒ…å«ä½¿ç”¨çš„ç‰ˆæœ¬ä¿¡æ¯
    """
    print(f"ğŸ§  æ™ºèƒ½æœç´¢è‚¡ç¥¨æ–°é—»: {stock_name}")
    
    try:
        # é¦–å…ˆå°è¯•å¼‚æ­¥ç‰ˆæœ¬
        print("   å°è¯•å¼‚æ­¥ç‰ˆæœ¬...")
        result = search_stock_news_web(stock_name, stock_code, num_results, search_type)
        
        if result['success']:
            result['used_version'] = 'async'
            print("   âœ… å¼‚æ­¥ç‰ˆæœ¬æˆåŠŸ")
            return result
        else:
            print(f"   âš ï¸ å¼‚æ­¥ç‰ˆæœ¬å¤±è´¥: {result['error']}")
            raise Exception("å¼‚æ­¥ç‰ˆæœ¬å¤±è´¥")
            
    except Exception as e:
        print(f"   ğŸ”§ åˆ‡æ¢åˆ°åŒæ­¥ç‰ˆæœ¬...")
        
        try:
            # ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ä½œä¸ºå¤‡é€‰
            result = search_stock_news_web_sync(stock_name, stock_code, num_results, search_type)
            
            if result['success']:
                result['used_version'] = 'sync'
                print("   âœ… åŒæ­¥ç‰ˆæœ¬æˆåŠŸ")
                return result
            else:
                result['used_version'] = 'sync_failed'
                print(f"   âŒ åŒæ­¥ç‰ˆæœ¬ä¹Ÿå¤±è´¥: {result['error']}")
                return result
                
        except Exception as sync_e:
            print(f"   âŒ åŒæ­¥ç‰ˆæœ¬å¼‚å¸¸: {sync_e}")
            return {
                'success': False,
                'error': f'æ‰€æœ‰ç‰ˆæœ¬éƒ½å¤±è´¥ - å¼‚æ­¥: {str(e)[:100]}, åŒæ­¥: {str(sync_e)[:100]}',
                'results': [],
                'used_version': 'all_failed'
            }


def get_stock_news_by_akshare(stock_code, debug=False):
    """
    ä½¿ç”¨akshareè·å–è‚¡ç¥¨æ–°é—»ã€å…¬å‘Šã€ç ”ç©¶æŠ¥å‘Šï¼ˆä¸œè´¢æ•°æ®æºï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001", "600036"
    
    Returns:
        dict: åŒ…å«æ‰€æœ‰ä¿¡æ¯çš„å­—å…¸
    """
    print(f"ğŸ“Š è·å–è‚¡ç¥¨ {stock_code} çš„è¯¦ç»†ä¿¡æ¯...")
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    result = {
        'company_news': [],
        'announcements': [],
        'research_reports': [],
        'news_summary': {}
    }
    
    # è·å–å…¬å¸æ–°é—»
    try:
        print("   è·å–å…¬å¸æ–°é—»...")
        company_news = ak.stock_news_em(stock_code)
        if not company_news.empty:
            company_news = company_news.to_dict('records')
            company_news = sorted(company_news, 
                           key=lambda x: datetime.strptime(x.get('å‘å¸ƒæ—¶é—´', '1900-01-01 00:00:00'), '%Y-%m-%d %H:%M:%S'), 
                           reverse=True)
            result['company_news'] = company_news
        print(f"   âœ“ æˆåŠŸè·å– {len(result['company_news'])} æ¡å…¬å¸æ–°é—»")

        if debug:
            print(f"âœ“ æ–°é—»å·²æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼Œå…± {len(result)} æ¡")

    except Exception as e:
        print(f"   âš ï¸ è·å–å…¬å¸æ–°é—»å¤±è´¥: {e}")
    
    """
    # è·å–å…¬å¸å…¬å‘Š
    try:
        print("   è·å–å…¬å¸å…¬å‘Š...")
        announcements = ak.stock_notice_report(stock_code) # è¿™ä¸ªå‚æ•°åº”è¯¥æ˜¯ä»£ç ï¼Œä¸”åªèƒ½å–æŸä¸€å¤©çš„ï¼Œè¿”å›çš„æ˜¯å½“å¤©æ‰€æœ‰å…¬å¸çš„å…¬å‘Š
        if not announcements.empty:
            result['announcements'] = announcements.to_dict('records')
        print(f"   âœ“ æˆåŠŸè·å– {len(result['announcements'])} æ¡å…¬å‘Š")
    except Exception as e:
        print(f"   âš ï¸ è·å–å…¬å¸å…¬å‘Šå¤±è´¥: {e}")
    
    
    # è·å–ç ”ç©¶æŠ¥å‘Š
    try:
        print("   è·å–ç ”ç©¶æŠ¥å‘Š...")
        # ä½¿ç”¨ä¸åŒçš„akshareå‡½æ•°å°è¯•è·å–ç ”ç©¶æŠ¥å‘Š
        try:
            research_reports = ak.stock_research_report_em(stock_code)
            if not research_reports.empty:
                result['research_reports'] = research_reports.to_dict('records')
        except:
            # å¦‚æœç¬¬ä¸€ä¸ªå‡½æ•°å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨å‡½æ•°
            research_reports = ak.stock_analyst_rank_em(stock_code)
            if not research_reports.empty:
                result['research_reports'] = research_reports.to_dict('records')
        
        print(f"   âœ“ æˆåŠŸè·å– {len(result['research_reports'])} æ¡ç ”ç©¶æŠ¥å‘Š")
    except Exception as e:
        print(f"   âš ï¸ è·å–ç ”ç©¶æŠ¥å‘Šå¤±è´¥: {e}")
    """
    # ç”Ÿæˆæ‘˜è¦ä¿¡æ¯
    result['news_summary'] = {
        'total_news_count': len(result['company_news']) + len(result['announcements']) + len(result['research_reports']),
        'company_news_count': len(result['company_news']),
        'announcements_count': len(result['announcements']),
        'research_reports_count': len(result['research_reports']),
        'data_freshness': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'stock_code': stock_code
    }
    
    print(f"   âœ… è‚¡ç¥¨ä¿¡æ¯è·å–å®Œæˆï¼Œå…± {result['news_summary']['total_news_count']} æ¡ä¿¡æ¯")
    return result


def show_stock_by_ak_summary(stock_info):
    """
    ç¾åŒ–æ˜¾ç¤ºè‚¡ç¥¨ä¿¡æ¯æ‘˜è¦
    
    Args:
        stock_info: get_stock_news_by_akshareè¿”å›çš„è‚¡ç¥¨ä¿¡æ¯å­—å…¸
    """
    print(f"ğŸ“ˆ è‚¡ç¥¨ä¿¡æ¯æ‘˜è¦æŠ¥å‘Š")
    print("=" * 60)
    
    summary = stock_info['news_summary']
    stock_code = summary['stock_code']
    
    print(f"ğŸ¯ è‚¡ç¥¨ä»£ç : {stock_code}")
    print(f"ğŸ“… æ•°æ®æ›´æ–°æ—¶é—´: {summary['data_freshness']}")
    
    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"   ğŸ“° å…¬å¸æ–°é—»: {summary['company_news_count']} æ¡")
    print(f"   ğŸ“‹ å…¬å¸å…¬å‘Š: {summary['announcements_count']} æ¡")
    print(f"   ğŸ“„ ç ”ç©¶æŠ¥å‘Š: {summary['research_reports_count']} æ¡")
    print(f"   ğŸ“ˆ æ€»è®¡: {summary['total_news_count']} æ¡")
    
    # æ˜¾ç¤ºæœ€æ–°æ–°é—»æ ‡é¢˜
    if stock_info['company_news']:
        print(f"\nğŸ“° æœ€æ–°å…¬å¸æ–°é—»ï¼ˆå‰5æ¡ï¼‰:")
        for i, news in enumerate(stock_info['company_news'][:5], 1):
            title = news.get('æ–°é—»æ ‡é¢˜', news.get('title', 'æ— æ ‡é¢˜'))
            time = news.get('å‘å¸ƒæ—¶é—´', news.get('publish_time', 'æ— æ—¶é—´'))
            print(f"   {i}. {title}")
            print(f"      æ—¶é—´: {time}")
    
    # æ˜¾ç¤ºæœ€æ–°å…¬å‘Šæ ‡é¢˜
    if stock_info['announcements']:
        print(f"\nğŸ“‹ æœ€æ–°å…¬å¸å…¬å‘Šï¼ˆå‰3æ¡ï¼‰:")
        for i, announcement in enumerate(stock_info['announcements'][:3], 1):
            # å…¬å‘Šçš„åˆ—åå¯èƒ½ä¸åŒï¼Œå°è¯•å¤šç§å¯èƒ½çš„åˆ—å
            title = (announcement.get('å…¬å‘Šæ ‡é¢˜') or 
                    announcement.get('æ ‡é¢˜') or 
                    announcement.get('title') or 
                    'æ— æ ‡é¢˜')
            time = (announcement.get('å…¬å‘Šæ—¥æœŸ') or 
                   announcement.get('å‘å¸ƒæ—¶é—´') or 
                   announcement.get('æ—¥æœŸ') or 
                   'æ— æ—¶é—´')
            print(f"   {i}. {title}")
            print(f"      æ—¶é—´: {time}")
    
    # æ˜¾ç¤ºç ”ç©¶æŠ¥å‘Šè¯„çº§åˆ†å¸ƒ
    if stock_info['research_reports']:
        print(f"\nâ­ ç ”ç©¶æŠ¥å‘Šè¯„çº§åˆ†å¸ƒ:")
        # å°è¯•æå–è¯„çº§ä¿¡æ¯
        ratings = []
        for report in stock_info['research_reports']:
            rating = (report.get('æŠ•èµ„è¯„çº§') or 
                     report.get('è¯„çº§') or 
                     report.get('rating') or 
                     report.get('æœ€æ–°è¯„çº§'))
            if rating and rating != 'nan':
                ratings.append(rating)
        
        if ratings:
            rating_count = Counter(ratings)
            for rating, count in rating_count.most_common():
                print(f"   â€¢ {rating}: {count} ä¸ªæœºæ„")
        else:
            print("   æš‚æ— è¯„çº§ä¿¡æ¯")

import json
from llm import openai_client

# æƒ…ç»ªåˆ†ææç¤ºè¯æ¨¡æ¿
SENTIMENT_ANALYSIS_PROMPT_TEMPLATE = """è¯·åˆ†æä»¥ä¸‹æ–°é—»å¯¹è‚¡ç¥¨"{stock_name}"çš„æŠ•èµ„æƒ…ç»ªå½±å“ï¼š

æ–°é—»æ ‡é¢˜: {news_title}
æ–°é—»å†…å®¹: {news_content}

è¯·ä»è¯¥è‚¡ç¥¨æŠ•èµ„è€…çš„è§’åº¦åˆ†æè¿™æ¡æ–°é—»çš„ä¸‰é¡¹æŒ‡æ ‡ï¼š
- æƒ…ç»ªç±»åˆ«ï¼šä¹è§‚ã€ä¸­æ€§ã€æ‚²è§‚
- æƒ…ç»ªå¼ºåº¦ï¼š1-5ï¼ˆ1=è½»å¾®å½±å“ï¼Œ5=é‡å¤§å½±å“ï¼‰
- é¢„æœŸåç¦»åº¦ï¼š1-5ï¼ˆ1=ç¬¦åˆé¢„æœŸï¼Œ5=éå¸¸å‡ºä¹æ„æ–™ï¼‰

è¿”å›JSONæ ¼å¼ï¼š{return_format}"""

def filter_time(news, start_date, end_date):
    # æ—¶é—´è¿‡æ»¤
    filtered_news = []
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    for news in news:
        publish_time_str = news.get('å‘å¸ƒæ—¶é—´', '')
        if publish_time_str:
            news_date_str = publish_time_str.split(' ')[0]
            news_dt = datetime.strptime(news_date_str, '%Y-%m-%d')
            if start_dt <= news_dt <= end_dt:
                filtered_news.append(news)
    return filtered_news

def analyze_news_sentiment(news_base, stock_name, start_date=None, end_date=None, limit=-1, debug=False):
    client = openai_client.OpenAIClient()
    ret_array = []

    if start_date is not None and end_date is not None:
        news = filter_time(news_base, start_date, end_date)
        if debug:
            print(f"âœ“ æ–°é—»å·²æŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤ï¼Œ{len(news_base)} -> {len(news)} æ¡")
    
    for idx, item in enumerate(news):
        if 'æ–°é—»æ ‡é¢˜' not in item or 'æ–°é—»å†…å®¹' not in item:
            print("æ–°é—»æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡è¯¥æ¡æ–°é—»")
            continue
        
        return_format = "{'sentiment':'xx', 'intensity': 5, 'deviation': 3}"
        
        # ä½¿ç”¨æç¤ºè¯æ¨¡æ¿
        query = SENTIMENT_ANALYSIS_PROMPT_TEMPLATE.format(
            stock_name=stock_name,
            news_title=item['æ–°é—»æ ‡é¢˜'],
            news_content=item['æ–°é—»å†…å®¹'],
            return_format=return_format
        )
        
        try:
            # ä½¿ç”¨JSONæ¨¡å¼
            ai_result = client.ask(query, json_mode=True, debug=debug)
            if debug:
                print(f"æ–°é—»æ ‡é¢˜: {item['æ–°é—»æ ‡é¢˜']}")
                print(f"æ–°é—»å†…å®¹: {item['æ–°é—»å†…å®¹']}")
                print(f"\nJSONæ¨¡å¼è¿”å›: {ai_result}")
            
            # ç›´æ¥è§£æJSONï¼Œä¸éœ€è¦é¢å¤–çš„å­—ç¬¦ä¸²å¤„ç†
            sentiment_data = json.loads(ai_result)
            item['æƒ…ç»ªç±»å‹'] = sentiment_data.get('sentiment', 'ä¸­æ€§')
            item['æƒ…ç»ªçº§åˆ«'] = sentiment_data.get('intensity', 3)
            item['é¢„æœŸåç¦»åº¦'] = sentiment_data.get('deviation', 3)
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            print(f"è¿”å›å†…å®¹: {ai_result}")
        except Exception as e:
            print(f"å…¶ä»–é”™è¯¯: {e}")
        if limit != -1 and idx >= limit:
            break
        ret_array.append(item)

    return ret_array

