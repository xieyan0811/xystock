"""
è‚¡ç¥¨æ•°æ®å·¥å…·æ¨¡å— - ç»Ÿä¸€çš„è‚¡ç¥¨æ•°æ®è·å–å’Œç¼“å­˜ç®¡ç†

æœ¬æ¨¡å—æä¾›è‚¡ç¥¨æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼ŒåŒ…æ‹¬ï¼š
1. è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å’Œå®æ—¶è¡Œæƒ…
2. Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡
3. æ–°é—»èµ„è®¯æ•°æ®
4. ç­¹ç åˆ†ææ•°æ®
5. é£é™©æŒ‡æ ‡è®¡ç®—
6. AIåˆ†ææŠ¥å‘Š

æ‰€æœ‰æ•°æ®éƒ½æ”¯æŒæ™ºèƒ½ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
"""

import sys
import os
import json
import warnings
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Optional, Any, List

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

warnings.filterwarnings('ignore')

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from providers.stock_utils import (
    get_stock_name, get_market_info, get_indicators, 
    normalize_stock_input, get_chip_analysis_data
)
from providers.stock_data_fetcher import data_manager, KLineType
from providers.news_tools import get_stock_news_by_akshare
from providers.risk_metrics import calculate_portfolio_risk


# =========================
# ç‹¬ç«‹çš„æ•°æ®è·å–å‡½æ•°ï¼ˆçº¯å¤–éƒ¨APIè°ƒç”¨ï¼‰
# =========================

def fetch_stock_basic_info(stock_code: str) -> Dict:
    """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯çš„å…·ä½“å®ç°"""
    basic_info = {}
    
    try:
        if not data_manager.is_available():
            if not data_manager.initialize():
                raise Exception("æ•°æ®æä¾›è€…åˆå§‹åŒ–å¤±è´¥")
                
        # è·å–å®æ—¶è¡Œæƒ…
        realtime_data = data_manager.get_realtime_quote(stock_code)
        stock_info = data_manager.get_stock_info(stock_code)
        
        if realtime_data:
            basic_info.update({
                'current_price': float(realtime_data.current_price),
                'change': float(realtime_data.change),
                'change_percent': float(realtime_data.change_percent),
                'volume': int(realtime_data.volume),
                'amount': float(realtime_data.amount),
                'high': float(realtime_data.high),
                'low': float(realtime_data.low),
                'open': float(realtime_data.open),
                'prev_close': float(realtime_data.prev_close),
                'timestamp': str(realtime_data.timestamp),
            })
        
        if stock_info:
            basic_info.update({
                'name': str(stock_info.name) if stock_info.name else '',
                'industry': str(stock_info.industry) if stock_info.industry else '',
                'total_market_value': float(stock_info.total_market_value) if stock_info.total_market_value else 0,
                'circulating_market_value': float(stock_info.circulating_market_value) if stock_info.circulating_market_value else 0,
                'pe_ratio': str(stock_info.pe_ratio) if stock_info.pe_ratio else '',
                'pb_ratio': str(stock_info.pb_ratio) if stock_info.pb_ratio else '',
                'roe': str(stock_info.roe) if stock_info.roe else '',
                'gross_profit_margin': str(stock_info.gross_profit_margin) if stock_info.gross_profit_margin else '',
                'net_profit_margin': str(stock_info.net_profit_margin) if stock_info.net_profit_margin else '',
                'net_profit': str(stock_info.net_profit) if stock_info.net_profit else '',
            })
        
    except Exception as e:
        basic_info['error'] = str(e)
    
    basic_info['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    return basic_info


def fetch_stock_kline_data(stock_code: str, period: int = 160) -> Dict:
    """è·å–è‚¡ç¥¨Kçº¿æ•°æ®çš„å…·ä½“å®ç°"""
    kline_info = {}
    
    try:
        # å›ºå®šä½¿ç”¨æ—¥Kæ•°æ®
        kline_data = data_manager.get_kline_data(
            stock_code, 
            KLineType.DAY, 
            period
        )
        
        if kline_data and len(kline_data) > 0:
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame([k.__dict__ for k in kline_data])
            df = df.sort_values('datetime')
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            df['MA5'] = df['close'].rolling(window=5).mean()
            df['MA10'] = df['close'].rolling(window=10).mean()
            df['MA20'] = df['close'].rolling(window=20).mean()
            
            # è·å–æŠ€æœ¯æŒ‡æ ‡
            indicators = get_indicators(df)
            
            # é£é™©æŒ‡æ ‡è®¡ç®—
            risk_metrics = {}
            if len(df) >= 5:
                try:
                    risk_metrics = calculate_portfolio_risk(df, price_col='close')
                    # ç¡®ä¿summary_tableæ˜¯å¯åºåˆ—åŒ–çš„
                    if 'summary_table' in risk_metrics and hasattr(risk_metrics['summary_table'], 'to_dict'):
                        risk_metrics['summary_table'] = risk_metrics['summary_table'].to_dict()
                except Exception as e:
                    risk_metrics['error'] = str(e)
            
            # è½¬æ¢DataFrameä¸ºå­—å…¸åˆ—è¡¨ï¼ˆç¡®ä¿JSONå®‰å…¨ï¼‰
            kline_data_list = []
            for _, row in df.iterrows():
                row_dict = {}
                for col, value in row.items():
                    if pd.isna(value):
                        row_dict[col] = None
                    elif hasattr(value, 'isoformat'):  # datetime
                        row_dict[col] = value.isoformat()
                    else:
                        row_dict[col] = value
                kline_data_list.append(row_dict)
            
            # è·å–æœ€æ–°æ•°æ®
            latest_data = {}
            if len(df) > 0:
                latest_row = df.iloc[-1]
                for col, value in latest_row.items():
                    if pd.isna(value):
                        latest_data[col] = None
                    elif hasattr(value, 'isoformat'):
                        latest_data[col] = value.isoformat()
                    else:
                        latest_data[col] = value
            
            kline_info.update({
                'kline_data': kline_data_list,
                'indicators': indicators,
                'risk_metrics': risk_metrics,
                'data_length': len(df),
                'latest_data': latest_data
            })
        else:
            kline_info['error'] = f"æœªè·å–åˆ°è‚¡ç¥¨ {stock_code} çš„Kçº¿æ•°æ®"
            
    except Exception as e:
        kline_info['error'] = str(e)
    
    kline_info['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    return kline_info


def fetch_stock_news_data(stock_code: str) -> Dict:
    """è·å–è‚¡ç¥¨æ–°é—»æ•°æ®çš„å…·ä½“å®ç°"""
    news_info = {}
    
    try:
        # ä½¿ç”¨news_toolsæ¨¡å—è·å–æ–°é—»
        stock_data = get_stock_news_by_akshare(stock_code)
        
        if stock_data and 'company_news' in stock_data:
            news_data = stock_data['company_news']
            
            news_info.update({
                'news_data': news_data,
                'news_count': len(news_data),
                'latest_news': news_data[:5] if len(news_data) >= 5 else news_data  # å‰5æ¡æœ€æ–°æ–°é—»
            })
        else:
            news_info['error'] = "æœªèƒ½è·å–åˆ°ç›¸å…³æ–°é—»"
            
    except Exception as e:
        news_info['error'] = str(e)
    
    news_info['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    return news_info


def fetch_stock_chip_data(stock_code: str) -> Dict:
    """è·å–è‚¡ç¥¨ç­¹ç æ•°æ®çš„å…·ä½“å®ç°"""
    chip_info = {}
    
    try:
        # è·å–ç­¹ç åˆ†ææ•°æ®
        chip_data = get_chip_analysis_data(stock_code)
        
        if "error" not in chip_data:
            chip_info.update(chip_data)
        else:
            chip_info['error'] = chip_data["error"]
            
    except Exception as e:
        chip_info['error'] = str(e)
    
    chip_info['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    return chip_info


class StockTools:
    """ç»Ÿä¸€çš„è‚¡ç¥¨æ•°æ®å·¥å…·ç±»"""
    
    def __init__(self, cache_dir: str = "data/cache"):
        """åˆå§‹åŒ–è‚¡ç¥¨å·¥å…·"""
        self.cache_dir = cache_dir
        project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.cache_file = os.path.join(project_dir, cache_dir, "stock_data.json")
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
        
        # ç¼“å­˜é…ç½®
        self.cache_configs = {
            'basic_info': {'expire_minutes': 5, 'description': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯'},
            'kline_data': {'expire_minutes': 30, 'description': 'Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡'},
            'news_data': {'expire_minutes': 60, 'description': 'æ–°é—»èµ„è®¯æ•°æ®'},
            'chip_data': {'expire_minutes': 1440, 'description': 'ç­¹ç åˆ†ææ•°æ®'},  # 1å¤©
            'ai_analysis': {'expire_minutes': 180, 'description': 'AIåˆ†ææŠ¥å‘Š'},
        }
    
    # =========================
    # ç¼“å­˜ç®¡ç†ç›¸å…³æ–¹æ³•
    # =========================
    
    def _load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {}
        except Exception:
            return {}
    
    def _make_json_safe(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå®‰å…¨çš„æ ¼å¼"""
        import numpy as np
        import pandas as pd
        
        if isinstance(obj, dict):
            return {key: self._make_json_safe(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_safe(item) for item in obj]
        elif isinstance(obj, pd.Series):
            return obj.tolist()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif isinstance(obj, (np.integer, np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        elif hasattr(obj, 'isoformat'):  # datetime, date objects
            return obj.isoformat()
        else:
            return obj
    
    def _save_cache(self, cache_data: Dict):
        """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
        try:
            # ç¡®ä¿æ•°æ®æ˜¯JSONå®‰å…¨çš„
            safe_cache_data = self._make_json_safe(cache_data)
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(safe_cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ ä¿å­˜è‚¡ç¥¨æ•°æ®ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_cache_key(self, data_type: str, stock_code: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{data_type}_{stock_code}"
    
    def _is_cache_valid(self, data_type: str, stock_code: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        try:
            cache_data = self._load_cache()
            cache_key = self._get_cache_key(data_type, stock_code)
            
            if cache_key not in cache_data:
                return False
            
            cache_meta = cache_data[cache_key].get('cache_meta', {})
            cache_time = datetime.fromisoformat(cache_meta['timestamp'])
            expire_minutes = self.cache_configs[data_type]['expire_minutes']
            expire_time = cache_time + timedelta(minutes=expire_minutes)
            
            return datetime.now() < expire_time
        except Exception:
            return False
    
    def _get_cached_data(self, data_type: str, stock_code: str) -> Dict:
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            cache_data = self._load_cache()
            cache_key = self._get_cache_key(data_type, stock_code)
            return cache_data.get(cache_key, {}).get('data', {})
        except Exception:
            return {}
    
    def _save_cached_data(self, data_type: str, stock_code: str, data: Dict):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        try:
            cache_data = self._load_cache()
            cache_key = self._get_cache_key(data_type, stock_code)
            
            cache_data[cache_key] = {
                'cache_meta': {
                    'timestamp': datetime.now().isoformat(),
                    'data_type': data_type,
                    'stock_code': stock_code,
                    'expire_minutes': self.cache_configs[data_type]['expire_minutes']
                },
                'data': data
            }
            self._save_cache(cache_data)
            print(f"ğŸ’¾ {stock_code} {self.cache_configs[data_type]['description']}å·²ç¼“å­˜")
        except Exception as e:
            print(f"âŒ ç¼“å­˜è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
    
    # =========================
    # æ•°æ®è·å–æ–¹æ³•ï¼ˆå¸¦ç¼“å­˜ï¼‰
    # =========================
    
    def get_stock_basic_info(self, stock_code: str, use_cache: bool = True, force_refresh: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        data_type = 'basic_info'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            return self._get_cached_data(data_type, stock_code)
        
        # è·å–æ–°æ•°æ®
        print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
        try:
            data = fetch_stock_basic_info(stock_code)
            if use_cache and 'error' not in data:
                self._save_cached_data(data_type, stock_code, data)
            return data
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            # è¿”å›ç¼“å­˜æ•°æ®ä½œä¸ºå¤‡ä»½
            return self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
    
    def get_stock_kline_data(self, stock_code: str, period: int = 160, use_cache: bool = True, force_refresh: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡"""
        data_type = 'kline_data'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            return self._get_cached_data(data_type, stock_code)
        
        # è·å–æ–°æ•°æ®
        print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
        try:
            data = fetch_stock_kline_data(stock_code, period)
            if use_cache and 'error' not in data:
                self._save_cached_data(data_type, stock_code, data)
            return data
        except Exception as e:
            print(f"âŒ è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
    
    def get_stock_news_data(self, stock_code: str, use_cache: bool = True, force_refresh: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨æ–°é—»æ•°æ®"""
        data_type = 'news_data'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            return self._get_cached_data(data_type, stock_code)
        
        # è·å–æ–°æ•°æ®
        print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
        try:
            data = fetch_stock_news_data(stock_code)
            if use_cache and 'error' not in data:
                self._save_cached_data(data_type, stock_code, data)
            return data
        except Exception as e:
            print(f"âŒ è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
            return self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
    
    def get_stock_chip_data(self, stock_code: str, use_cache: bool = True, force_refresh: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨ç­¹ç æ•°æ®"""
        data_type = 'chip_data'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            return self._get_cached_data(data_type, stock_code)
        
        # è·å–æ–°æ•°æ®
        print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
        try:
            data = fetch_stock_chip_data(stock_code)
            if use_cache and 'error' not in data:
                self._save_cached_data(data_type, stock_code, data)
            return data
        except Exception as e:
            print(f"âŒ è·å–ç­¹ç æ•°æ®å¤±è´¥: {e}")
            return self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
    
    def get_ai_analysis(self, stock_code: str, analysis_type: str = 'comprehensive', use_cache: bool = True) -> Dict:
        """è·å–AIåˆ†ææ•°æ®"""
        data_type = 'ai_analysis'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # ä½¿ç”¨åˆ†æç±»å‹åŒºåˆ†ä¸åŒçš„AIåˆ†æ
        cache_key = f"{data_type}_{analysis_type}_{stock_code}"
        
        if use_cache:
            try:
                cache_data = self._load_cache()
                if cache_key in cache_data:
                    cache_meta = cache_data[cache_key].get('cache_meta', {})
                    cache_time = datetime.fromisoformat(cache_meta['timestamp'])
                    expire_time = cache_time + timedelta(minutes=self.cache_configs[data_type]['expire_minutes'])
                    
                    if datetime.now() < expire_time:
                        print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {analysis_type} AIåˆ†æ")
                        return cache_data[cache_key].get('data', {})
            except Exception:
                pass
        
        # AIåˆ†ææ•°æ®éœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼Œè¿™é‡Œè¿”å›ç°æœ‰ç¼“å­˜
        print(f"ğŸ“‹ ä½¿ç”¨ç°æœ‰çš„ {stock_code} {analysis_type} AIåˆ†æ")
        try:
            cache_data = self._load_cache()
            return cache_data.get(cache_key, {}).get('data', {})
        except Exception:
            return {}
    
    def set_ai_analysis(self, stock_code: str, analysis_type: str, analysis_data: Dict):
        """è®¾ç½®AIåˆ†ææ•°æ®"""
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
            
        cache_key = f"ai_analysis_{analysis_type}_{stock_code}"
        analysis_data['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        try:
            cache_data = self._load_cache()
            cache_data[cache_key] = {
                'cache_meta': {
                    'timestamp': datetime.now().isoformat(),
                    'data_type': 'ai_analysis',
                    'stock_code': stock_code,
                    'analysis_type': analysis_type,
                    'expire_minutes': self.cache_configs['ai_analysis']['expire_minutes']
                },
                'data': analysis_data
            }
            self._save_cache(cache_data)
            print(f"ğŸ’¾ {stock_code} {analysis_type} AIåˆ†æå·²ç¼“å­˜")
        except Exception as e:
            print(f"âŒ ç¼“å­˜AIåˆ†æå¤±è´¥: {e}")
    
    # =========================
    # ç»¼åˆæŠ¥å‘Šæ–¹æ³•
    # =========================
    
    def get_comprehensive_stock_report(self, stock_code: str, use_cache: bool = True) -> Dict:
        """è·å–è‚¡ç¥¨ç»¼åˆæŠ¥å‘Š"""
        print(f"ğŸ“‹ ç”Ÿæˆ {stock_code} ç»¼åˆè‚¡ç¥¨æŠ¥å‘Š...")
        print("=" * 60)
        
        report = {
            'report_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'stock_code': stock_code,
            'basic_info': {},
            'kline_data': {},
            'news_data': {},
            'chip_data': {},
            'ai_analysis': {},
            'stock_summary': {}
        }
        
        # è·å–å„ç±»æ•°æ®
        report['basic_info'] = self.get_stock_basic_info(stock_code, use_cache)
        report['kline_data'] = self.get_stock_kline_data(stock_code, 160, use_cache)
        report['news_data'] = self.get_stock_news_data(stock_code, use_cache)
        report['chip_data'] = self.get_stock_chip_data(stock_code, use_cache)
        
        # è·å–å„ç§AIåˆ†æ
        report['ai_analysis'] = {
            'fundamental': self.get_ai_analysis(stock_code, 'fundamental', use_cache),
            'market': self.get_ai_analysis(stock_code, 'market', use_cache),
            'news': self.get_ai_analysis(stock_code, 'news', use_cache),
            'chip': self.get_ai_analysis(stock_code, 'chip', use_cache),
        }
        
        # ç”Ÿæˆè‚¡ç¥¨æ‘˜è¦
        report['stock_summary'] = self._generate_stock_summary(report)
        
        print("=" * 60)
        print("âœ… ç»¼åˆè‚¡ç¥¨æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        
        return report
    
    def _generate_stock_summary(self, report: Dict) -> Dict:
        """ç”Ÿæˆè‚¡ç¥¨æ‘˜è¦"""
        summary = {}
        
        # åŸºæœ¬ä¿¡æ¯æ‘˜è¦
        basic = report['basic_info']
        if basic and 'error' not in basic:
            summary['current_price'] = basic.get('current_price', 0)
            summary['change_percent'] = basic.get('change_percent', 0)
            summary['stock_name'] = basic.get('name', '')
            summary['industry'] = basic.get('industry', '')
        
        # æŠ€æœ¯é¢æ‘˜è¦
        kline = report['kline_data']
        if kline and 'error' not in kline:
            indicators = kline.get('indicators', {})
            summary['technical_trend'] = f"{indicators.get('ma_trend', 'æœªçŸ¥')} | MACD {indicators.get('macd_trend', 'æœªçŸ¥')}"
            summary['rsi_level'] = self._judge_rsi_level(indicators.get('rsi_14', 50))
        
        # æ–°é—»æ‘˜è¦
        news = report['news_data']
        if news and 'error' not in news:
            summary['news_count'] = news.get('news_count', 0)
        
        # ç­¹ç æ‘˜è¦
        chip = report['chip_data']
        if chip and 'error' not in chip:
            summary['profit_ratio'] = chip.get('profit_ratio', 0)
            summary['avg_cost'] = chip.get('avg_cost', 0)
        
        return summary
    
    def _judge_rsi_level(self, rsi: float) -> str:
        """åˆ¤æ–­RSIæ°´å¹³"""
        if rsi >= 80:
            return "è¶…ä¹°"
        elif rsi >= 70:
            return "å¼ºåŠ¿"
        elif rsi >= 30:
            return "æ­£å¸¸"
        elif rsi >= 20:
            return "å¼±åŠ¿"
        else:
            return "è¶…å–"
    
    # =========================
    # ç¼“å­˜ç®¡ç†æ–¹æ³•
    # =========================
    
    def clear_cache(self, stock_code: str = None, data_type: str = None):
        """æ¸…ç†ç¼“å­˜"""
        try:
            cache_data = self._load_cache()
            
            if stock_code and data_type:
                # æ¸…ç†ç‰¹å®šè‚¡ç¥¨çš„ç‰¹å®šæ•°æ®ç±»å‹
                cache_key = self._get_cache_key(data_type, stock_code)
                if cache_key in cache_data:
                    del cache_data[cache_key]
                    self._save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç† {stock_code} {self.cache_configs.get(data_type, {}).get('description', data_type)} ç¼“å­˜")
                else:
                    print(f"â„¹ï¸  {stock_code} {data_type} ç¼“å­˜ä¸å­˜åœ¨")
                    
            elif stock_code:
                # æ¸…ç†ç‰¹å®šè‚¡ç¥¨çš„æ‰€æœ‰ç¼“å­˜
                keys_to_remove = [key for key in cache_data.keys() if key.endswith(f"_{stock_code}")]
                for key in keys_to_remove:
                    del cache_data[key]
                if keys_to_remove:
                    self._save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç† {stock_code} æ‰€æœ‰ç¼“å­˜ ({len(keys_to_remove)}é¡¹)")
                else:
                    print(f"â„¹ï¸  {stock_code} æ— ç¼“å­˜æ•°æ®")
                    
            elif data_type:
                # æ¸…ç†ç‰¹å®šæ•°æ®ç±»å‹çš„æ‰€æœ‰ç¼“å­˜
                keys_to_remove = [key for key in cache_data.keys() if key.startswith(f"{data_type}_")]
                for key in keys_to_remove:
                    del cache_data[key]
                if keys_to_remove:
                    self._save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç†æ‰€æœ‰ {self.cache_configs.get(data_type, {}).get('description', data_type)} ç¼“å­˜ ({len(keys_to_remove)}é¡¹)")
                else:
                    print(f"â„¹ï¸  æ—  {data_type} ç¼“å­˜æ•°æ®")
                    
            else:
                # æ¸…ç†æ‰€æœ‰ç¼“å­˜
                if os.path.exists(self.cache_file):
                    os.remove(self.cache_file)
                    print("âœ… å·²æ¸…ç†æ‰€æœ‰è‚¡ç¥¨æ•°æ®ç¼“å­˜")
                else:
                    print("â„¹ï¸  ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")
                    
        except Exception as e:
            print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cache_status(self, stock_code: str = None) -> Dict:
        """è·å–ç¼“å­˜çŠ¶æ€"""
        status = {}
        current_time = datetime.now()
        cache_data = self._load_cache()
        
        for cache_key, cache_info in cache_data.items():
            try:
                cache_meta = cache_info.get('cache_meta', {})
                cached_stock_code = cache_meta.get('stock_code', '')
                data_type = cache_meta.get('data_type', '')
                analysis_type = cache_meta.get('analysis_type', '')
                
                # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œåªæ˜¾ç¤ºè¯¥è‚¡ç¥¨çš„ç¼“å­˜
                if stock_code and cached_stock_code != stock_code:
                    continue
                
                cache_time = datetime.fromisoformat(cache_meta['timestamp'])
                expire_minutes = cache_meta.get('expire_minutes', 60)
                expire_time = cache_time + timedelta(minutes=expire_minutes)
                is_valid = current_time < expire_time
                
                remaining_minutes = (expire_time - current_time).total_seconds() / 60
                if remaining_minutes > 0:
                    remaining_text = f"å‰©ä½™ {int(remaining_minutes)} åˆ†é’Ÿ"
                else:
                    remaining_text = "å·²è¿‡æœŸ"
                
                display_key = cache_key
                if analysis_type:
                    display_key = f"{cached_stock_code}_{analysis_type}_AIåˆ†æ"
                
                status[display_key] = {
                    'stock_code': cached_stock_code,
                    'data_type': data_type,
                    'analysis_type': analysis_type,
                    'description': self.cache_configs.get(data_type, {}).get('description', data_type),
                    'valid': is_valid,
                    'cache_time': cache_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'expire_minutes': expire_minutes,
                    'remaining': remaining_text
                }
            except Exception:
                continue
        
        return status
    
    def print_cache_status(self, stock_code: str = None):
        """æ‰“å°ç¼“å­˜çŠ¶æ€"""
        status = self.get_cache_status(stock_code)
        
        print("=" * 70)
        if stock_code:
            print(f"ğŸ“Š è‚¡ç¥¨ {stock_code} æ•°æ®ç¼“å­˜çŠ¶æ€")
        else:
            print("ğŸ“Š è‚¡ç¥¨æ•°æ®ç¼“å­˜çŠ¶æ€")
        print(f"ğŸ“ ç¼“å­˜æ–‡ä»¶: {self.cache_file}")
        print("=" * 70)
        
        if not status:
            if stock_code:
                print(f"â„¹ï¸  è‚¡ç¥¨ {stock_code} æ— ç¼“å­˜æ•°æ®")
            else:
                print("â„¹ï¸  æ— ç¼“å­˜æ•°æ®")
        else:
            for key, info in status.items():
                status_icon = "âœ…" if info['valid'] else "âŒ"
                print(f"{status_icon} {info['stock_code']:<8} | {info['description']:<12} | {info['remaining']:<15} | è¿‡æœŸ: {info['expire_minutes']}åˆ†é’Ÿ")
        
        # æ˜¾ç¤ºç¼“å­˜æ–‡ä»¶å¤§å°
        try:
            if os.path.exists(self.cache_file):
                file_size = os.path.getsize(self.cache_file) / 1024  # KB
                print(f"ğŸ’¾ ç¼“å­˜æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
            else:
                print("ğŸ’¾ ç¼“å­˜æ–‡ä»¶: ä¸å­˜åœ¨")
        except Exception:
            pass
        
        print("=" * 70)


# =========================
# å…¨å±€å®ä¾‹å’Œä¾¿æ·å‡½æ•°
# =========================

# å…¨å±€è‚¡ç¥¨å·¥å…·å®ä¾‹
_stock_tools = None

def get_stock_tools() -> StockTools:
    """è·å–å…¨å±€è‚¡ç¥¨å·¥å…·å®ä¾‹"""
    global _stock_tools
    if _stock_tools is None:
        _stock_tools = StockTools()
    return _stock_tools

def show_stock_cache_status(stock_code: str = None):
    """æ˜¾ç¤ºè‚¡ç¥¨ç¼“å­˜çŠ¶æ€"""
    tools = get_stock_tools()
    tools.print_cache_status(stock_code)

def clear_stock_cache(stock_code: str = None, data_type: str = None):
    """æ¸…ç†è‚¡ç¥¨æ•°æ®ç¼“å­˜"""
    tools = get_stock_tools()
    tools.clear_cache(stock_code, data_type)

def set_stock_ai_analysis(stock_code: str, analysis_type: str, analysis_data: Dict):
    """è®¾ç½®è‚¡ç¥¨AIåˆ†ææ•°æ®"""
    tools = get_stock_tools()
    tools.set_ai_analysis(stock_code, analysis_type, analysis_data)

def get_stock_ai_analysis(stock_code: str, analysis_type: str = 'comprehensive') -> Dict:
    """è·å–è‚¡ç¥¨AIåˆ†ææ•°æ®"""
    tools = get_stock_tools()
    return tools.get_ai_analysis(stock_code, analysis_type)


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€è‚¡ç¥¨å·¥å…·æ¨¡å—...")
    
    tools = get_stock_tools()
    test_stock = "000001"  # å¹³å®‰é“¶è¡Œ
    
    print(f"\n1. æ˜¾ç¤º {test_stock} ç¼“å­˜çŠ¶æ€:")
    tools.print_cache_status(test_stock)
    
    print(f"\n2. è·å– {test_stock} åŸºæœ¬ä¿¡æ¯:")
    basic_info = tools.get_stock_basic_info(test_stock)
    if 'error' not in basic_info:
        print(f"   å½“å‰ä»·æ ¼: {basic_info.get('current_price', 'N/A')}")
        print(f"   è‚¡ç¥¨åç§°: {basic_info.get('name', 'N/A')}")
    else:
        print(f"   é”™è¯¯: {basic_info['error']}")
    
    print(f"\n3. æ˜¾ç¤ºæ›´æ–°åçš„ç¼“å­˜çŠ¶æ€:")
    tools.print_cache_status(test_stock)
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
