"""
è‚¡ç¥¨æ•°æ®å·¥å…·æ¨¡å— - ç»Ÿä¸€çš„è‚¡ç¥¨æ•°æ®è·å–å’Œç¼“å­˜ç®¡ç†

æœ¬æ¨¡å—æä¾›è‚¡ç¥¨æ•°æ®çš„ç»Ÿä¸€æ¥å£ï¼ŒåŒ…æ‹¬ï¼š
1. è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å’Œå®æ—¶è¡Œæƒ…
2. Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡
3. æ–°é—»èµ„è®¯æ•°æ®
4. ç­¹ç åˆ†ææ•°æ®
5. é£é™©æŒ‡æ ‡è®¡ç®—
6. AIåˆ†ææŠ¥å‘Š

æ‰€æœ‰æ•°æ®éƒ½æ”¯æŒæ™ºèƒ½ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
"""

import sys
import os
import json
import warnings
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.append(project_root)

warnings.filterwarnings('ignore')

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from providers.stock_utils import (
    get_stock_name, get_market_info, get_indicators, 
    normalize_stock_input, get_chip_analysis_data,
    fetch_stock_basic_info, fetch_stock_technical_indicators,
    fetch_stock_news_data, fetch_stock_chip_data
)
from providers.stock_data_fetcher import data_manager, KLineType
from providers.risk_metrics import calculate_portfolio_risk

# å¯¼å…¥AIåˆ†ææ¨¡å—
try:
    from analysis.stock_ai_analysis import (
        generate_fundamental_analysis_report, generate_stock_analysis_report, 
        generate_news_analysis_report, generate_chip_analysis_report
    )
    AI_ANALYSIS_AVAILABLE = True
except ImportError:
    AI_ANALYSIS_AVAILABLE = False
    print("âš ï¸ AIåˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")


class StockTools:
    """ç»Ÿä¸€çš„è‚¡ç¥¨æ•°æ®å·¥å…·ç±»"""
    
    def __init__(self, cache_dir: str = "data/cache"):
        """åˆå§‹åŒ–è‚¡ç¥¨å·¥å…·"""
        self.cache_dir = cache_dir
        project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.cache_file = os.path.join(project_dir, cache_dir, "stock_data.json")
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
        
        # ç¼“å­˜é…ç½®
        self.cache_configs = {
            'basic_info': {'expire_minutes': 5, 'description': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯'},
            'technical_indicators': {'expire_minutes': 30, 'description': 'æŠ€æœ¯æŒ‡æ ‡å’Œé£é™©æŒ‡æ ‡'},
            'news_data': {'expire_minutes': 60, 'description': 'æ–°é—»èµ„è®¯æ•°æ®'},
            'chip_data': {'expire_minutes': 1440, 'description': 'ç­¹ç åˆ†ææ•°æ®'},  # 1å¤©
            'ai_analysis': {'expire_minutes': 180, 'description': 'AIåˆ†ææŠ¥å‘Š'},
        }
    
    # =========================
    # ç¼“å­˜ç®¡ç†ç›¸å…³æ–¹æ³•
    # =========================
    
    def _load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {}
        except Exception:
            return {}
    
    def _make_json_safe(self, obj):
        """å°†å¯¹è±¡è½¬æ¢ä¸ºJSONå®‰å…¨çš„æ ¼å¼"""
        import numpy as np
        import pandas as pd
        
        if isinstance(obj, dict):
            return {key: self._make_json_safe(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_safe(item) for item in obj]
        elif isinstance(obj, pd.Series):
            return obj.tolist()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif isinstance(obj, (np.integer, np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        elif hasattr(obj, 'isoformat'):  # datetime, date objects
            return obj.isoformat()
        else:
            return obj
    
    def _save_cache(self, cache_data: Dict):
        """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
        try:
            # ç¡®ä¿æ•°æ®æ˜¯JSONå®‰å…¨çš„
            safe_cache_data = self._make_json_safe(cache_data)
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(safe_cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ ä¿å­˜è‚¡ç¥¨æ•°æ®ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_cache_key(self, data_type: str, stock_code: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{data_type}_{stock_code}"
    
    def _is_cache_valid(self, data_type: str, stock_code: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        try:
            cache_data = self._load_cache()
            cache_key = self._get_cache_key(data_type, stock_code)
            
            if cache_key not in cache_data:
                return False
            
            cache_meta = cache_data[cache_key].get('cache_meta', {})
            cache_time = datetime.fromisoformat(cache_meta['timestamp'])
            expire_minutes = self.cache_configs[data_type]['expire_minutes']
            expire_time = cache_time + timedelta(minutes=expire_minutes)
            
            return datetime.now() < expire_time
        except Exception:
            return False
    
    def _get_cached_data(self, data_type: str, stock_code: str) -> Dict:
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            cache_data = self._load_cache()
            cache_key = self._get_cache_key(data_type, stock_code)
            return cache_data.get(cache_key, {}).get('data', {})
        except Exception:
            return {}
    
    def _save_cached_data(self, data_type: str, stock_code: str, data: Dict):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        try:
            cache_data = self._load_cache()
            cache_key = self._get_cache_key(data_type, stock_code)
            
            cache_data[cache_key] = {
                'cache_meta': {
                    'timestamp': datetime.now().isoformat(),
                    'data_type': data_type,
                    'stock_code': stock_code,
                    'expire_minutes': self.cache_configs[data_type]['expire_minutes']
                },
                'data': data
            }
            self._save_cache(cache_data)
            print(f"ğŸ’¾ {stock_code} {self.cache_configs[data_type]['description']}å·²ç¼“å­˜")
        except Exception as e:
            print(f"âŒ ç¼“å­˜è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
    
    # =========================
    # æ•°æ®è·å–æ–¹æ³•ï¼ˆå¸¦ç¼“å­˜ï¼‰
    # =========================
    
    def get_stock_basic_info(self, stock_code: str, use_cache: bool = True, force_refresh: bool = False, include_ai_analysis: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            include_ai_analysis: æ˜¯å¦åŒ…å«AIåŸºæœ¬é¢åˆ†ææŠ¥å‘Š
            
        Returns:
            Dict: åŸºæœ¬ä¿¡æ¯æ•°æ®ï¼Œå¦‚æœinclude_ai_analysis=Trueï¼Œåˆ™åŒ…å«ai_analysiså­—æ®µ
        """
        data_type = 'basic_info'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            basic_data = self._get_cached_data(data_type, stock_code)
        else:
            # è·å–æ–°æ•°æ®
            print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
            try:
                basic_data = fetch_stock_basic_info(stock_code)
                if use_cache and 'error' not in basic_data:
                    self._save_cached_data(data_type, stock_code, basic_data)
            except Exception as e:
                print(f"âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
                # è¿”å›ç¼“å­˜æ•°æ®ä½œä¸ºå¤‡ä»½
                basic_data = self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
        
        # å¦‚æœéœ€è¦AIåˆ†æä¸”åŸºæœ¬æ•°æ®è·å–æˆåŠŸ
        if include_ai_analysis and 'error' not in basic_data:
            try:
                # è·å–è‚¡ç¥¨åç§°å’Œå¸‚åœºä¿¡æ¯
                stock_name = get_stock_name(stock_code, 'stock')
                market_info = get_market_info(stock_code)
                
                # ç”ŸæˆAIåŸºæœ¬é¢åˆ†ææŠ¥å‘Š
                ai_report, ai_timestamp = self.generate_fundamental_analysis_with_cache(
                    stock_code=stock_code,
                    stock_name=stock_name,
                    market_info=market_info,
                    fundamental_data=basic_data,
                    use_cache=use_cache,
                    force_refresh=force_refresh
                )
                
                # å°†AIåˆ†ææ·»åŠ åˆ°è¿”å›æ•°æ®ä¸­
                basic_data['ai_analysis'] = {
                    'report': ai_report,
                    'timestamp': ai_timestamp
                }
                
            except Exception as e:
                print(f"âŒ ç”ŸæˆAIåŸºæœ¬é¢åˆ†æå¤±è´¥: {e}")
                basic_data['ai_analysis'] = {
                    'error': str(e),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
        
        return basic_data
    
    def get_stock_technical_indicators(self, stock_code: str, period: int = 160, use_cache: bool = True, force_refresh: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡å’Œé£é™©æŒ‡æ ‡ï¼ˆä¸ç¼“å­˜Kçº¿æ•°æ®æœ¬èº«ï¼‰"""
        data_type = 'technical_indicators'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            return self._get_cached_data(data_type, stock_code)
        
        # è·å–æ–°æ•°æ®
        print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
        try:
            data = fetch_stock_technical_indicators(stock_code, period)
            if use_cache and 'error' not in data:
                self._save_cached_data(data_type, stock_code, data)
            return data
        except Exception as e:
            print(f"âŒ è·å–æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            return self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
    
    def get_stock_kline_data(self, stock_code: str, period: int = 160, use_cache: bool = True, force_refresh: bool = False, include_ai_analysis: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨Kçº¿æ•°æ®ï¼ˆå®æ—¶è·å–ï¼Œä¸ç¼“å­˜Kçº¿æ•°æ®æœ¬èº«ï¼Œä½†è¿”å›åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„å®Œæ•´ä¿¡æ¯ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            period: è·å–çš„Kçº¿å‘¨æœŸæ•°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            include_ai_analysis: æ˜¯å¦åŒ…å«AIæŠ€æœ¯åˆ†ææŠ¥å‘Š
            
        Returns:
            Dict: Kçº¿æ•°æ®ï¼Œå¦‚æœinclude_ai_analysis=Trueï¼Œåˆ™åŒ…å«ai_analysiså­—æ®µ
        """
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        try:
            # ç›´æ¥è·å–Kçº¿æ•°æ®ï¼ˆåˆ©ç”¨ç°æœ‰CSVç¼“å­˜ï¼‰
            kline_data = data_manager.get_kline_data(
                stock_code, 
                KLineType.DAY, 
                period
            )
            
            if kline_data and len(kline_data) > 0:
                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame([k.__dict__ for k in kline_data])
                df = df.sort_values('datetime')
                
                # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
                df['MA5'] = df['close'].rolling(window=5).mean()
                df['MA10'] = df['close'].rolling(window=10).mean()
                df['MA20'] = df['close'].rolling(window=20).mean()
                
                # è·å–ç¼“å­˜çš„æŠ€æœ¯æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                indicators_data = self.get_stock_technical_indicators(stock_code, period, use_cache, force_refresh)
                
                # è®¡ç®—å®Œæ•´çš„é£é™©æŒ‡æ ‡ï¼ˆç”¨äºæ˜¾ç¤ºï¼ŒåŒ…å«å›¾è¡¨æ•°æ®ï¼‰
                full_risk_metrics = {}
                try:
                    if len(df) >= 5:
                        full_risk_metrics = calculate_portfolio_risk(df, price_col='close')
                        # ç¡®ä¿summary_tableæ˜¯å¯åºåˆ—åŒ–çš„
                        if 'summary_table' in full_risk_metrics and hasattr(full_risk_metrics['summary_table'], 'to_dict'):
                            full_risk_metrics['summary_table'] = full_risk_metrics['summary_table'].to_dict()
                except Exception as e:
                    full_risk_metrics['error'] = str(e)
                
                # ç»„åˆè¿”å›å®Œæ•´ä¿¡æ¯
                result = {
                    'kline_data': df.to_dict('records'),  # Kçº¿æ•°æ®å®æ—¶è¿”å›
                    'indicators': indicators_data.get('indicators', {}),
                    'risk_metrics': full_risk_metrics,  # å®Œæ•´é£é™©æŒ‡æ ‡ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                    'risk_summary': indicators_data.get('risk_metrics', {}),  # ç²¾ç®€é£é™©æ‘˜è¦ï¼ˆæ¥è‡ªç¼“å­˜ï¼‰
                    'data_length': len(df),
                    'latest_data': df.iloc[-1].to_dict() if len(df) > 0 else {},
                    'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                # å¦‚æœéœ€è¦AIåˆ†æä¸”Kçº¿æ•°æ®è·å–æˆåŠŸ
                if include_ai_analysis:
                    try:
                        # è·å–è‚¡ç¥¨åç§°å’Œå¸‚åœºä¿¡æ¯
                        stock_name = get_stock_name(stock_code, 'stock')
                        market_info = get_market_info(stock_code)
                        indicators = get_indicators(df)
                        
                        # ç”ŸæˆAIæŠ€æœ¯åˆ†ææŠ¥å‘Š
                        ai_report, ai_timestamp = self.generate_stock_analysis_with_cache(
                            stock_code=stock_code,
                            stock_name=stock_name,
                            market_info=market_info,
                            df=df,
                            indicators=indicators,
                            use_cache=use_cache,
                            force_refresh=force_refresh
                        )
                        
                        # å°†AIåˆ†ææ·»åŠ åˆ°è¿”å›æ•°æ®ä¸­
                        result['ai_analysis'] = {
                            'report': ai_report,
                            'timestamp': ai_timestamp
                        }
                        
                    except Exception as e:
                        print(f"âŒ ç”ŸæˆAIæŠ€æœ¯åˆ†æå¤±è´¥: {e}")
                        result['ai_analysis'] = {
                            'error': str(e),
                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        }
                
                return result
            else:
                return {'error': f"æœªè·å–åˆ°è‚¡ç¥¨ {stock_code} çš„Kçº¿æ•°æ®"}
                
        except Exception as e:
            return {'error': str(e)}
    
    def get_stock_news_data(self, stock_code: str, use_cache: bool = True, force_refresh: bool = False, include_ai_analysis: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨æ–°é—»æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            include_ai_analysis: æ˜¯å¦åŒ…å«AIæ–°é—»åˆ†ææŠ¥å‘Š
            
        Returns:
            Dict: æ–°é—»æ•°æ®ï¼Œå¦‚æœinclude_ai_analysis=Trueï¼Œåˆ™åŒ…å«ai_analysiså­—æ®µ
        """
        data_type = 'news_data'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            news_data = self._get_cached_data(data_type, stock_code)
        else:
            # è·å–æ–°æ•°æ®
            print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
            try:
                news_data = fetch_stock_news_data(stock_code)
                if use_cache and 'error' not in news_data:
                    self._save_cached_data(data_type, stock_code, news_data)
            except Exception as e:
                print(f"âŒ è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
                news_data = self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
        
        # å¦‚æœéœ€è¦AIåˆ†æä¸”æ–°é—»æ•°æ®è·å–æˆåŠŸ
        if include_ai_analysis and 'error' not in news_data:
            try:
                # è·å–è‚¡ç¥¨åç§°å’Œå¸‚åœºä¿¡æ¯
                stock_name = get_stock_name(stock_code, 'stock')
                market_info = get_market_info(stock_code)
                
                # ç”ŸæˆAIæ–°é—»åˆ†ææŠ¥å‘Š
                ai_report, ai_timestamp = self.generate_news_analysis_with_cache(
                    stock_code=stock_code,
                    stock_name=stock_name,
                    market_info=market_info,
                    news_data=news_data.get('data', []),
                    use_cache=use_cache,
                    force_refresh=force_refresh
                )
                
                # å°†AIåˆ†ææ·»åŠ åˆ°è¿”å›æ•°æ®ä¸­
                news_data['ai_analysis'] = {
                    'report': ai_report,
                    'timestamp': ai_timestamp
                }
                
            except Exception as e:
                print(f"âŒ ç”ŸæˆAIæ–°é—»åˆ†æå¤±è´¥: {e}")
                news_data['ai_analysis'] = {
                    'error': str(e),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
        
        return news_data
    
    def get_stock_chip_data(self, stock_code: str, use_cache: bool = True, force_refresh: bool = False, include_ai_analysis: bool = False) -> Dict:
        """è·å–è‚¡ç¥¨ç­¹ç æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            include_ai_analysis: æ˜¯å¦åŒ…å«AIåˆ†ææŠ¥å‘Š
            
        Returns:
            Dict: ç­¹ç æ•°æ®ï¼Œå¦‚æœinclude_ai_analysis=Trueï¼Œåˆ™åŒ…å«ai_analysiså­—æ®µ
        """
        data_type = 'chip_data'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh and self._is_cache_valid(data_type, stock_code):
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {self.cache_configs[data_type]['description']}")
            chip_data = self._get_cached_data(data_type, stock_code)
        else:
            # è·å–æ–°æ•°æ®
            print(f"ğŸ“¡ è·å– {stock_code} {self.cache_configs[data_type]['description']}...")
            try:
                chip_data = fetch_stock_chip_data(stock_code)
                if use_cache and 'error' not in chip_data:
                    self._save_cached_data(data_type, stock_code, chip_data)
            except Exception as e:
                print(f"âŒ è·å–ç­¹ç æ•°æ®å¤±è´¥: {e}")
                chip_data = self._get_cached_data(data_type, stock_code) if use_cache else {'error': str(e)}
        
        # å¦‚æœéœ€è¦AIåˆ†æä¸”ç­¹ç æ•°æ®è·å–æˆåŠŸ
        if include_ai_analysis and 'error' not in chip_data:
            try:
                # è·å–è‚¡ç¥¨åç§°
                stock_name = get_stock_name(stock_code, 'stock')
                
                # ç”ŸæˆAIåˆ†ææŠ¥å‘Š
                ai_report, ai_timestamp = self.generate_chip_analysis_with_cache(
                    stock_code=stock_code,
                    stock_name=stock_name, 
                    chip_data=chip_data,
                    use_cache=use_cache,
                    force_refresh=force_refresh
                )
                
                # å°†AIåˆ†ææ·»åŠ åˆ°è¿”å›æ•°æ®ä¸­
                chip_data['ai_analysis'] = {
                    'report': ai_report,
                    'timestamp': ai_timestamp
                }
                
            except Exception as e:
                print(f"âŒ ç”ŸæˆAIåˆ†æå¤±è´¥: {e}")
                chip_data['ai_analysis'] = {
                    'error': str(e),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
        
        return chip_data
    
    def get_ai_analysis(self, stock_code: str, analysis_type: str = 'comprehensive', use_cache: bool = True) -> Dict:
        """è·å–AIåˆ†ææ•°æ®"""
        data_type = 'ai_analysis'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
        
        # ä½¿ç”¨åˆ†æç±»å‹åŒºåˆ†ä¸åŒçš„AIåˆ†æ
        cache_key = f"{data_type}_{analysis_type}_{stock_code}"
        
        if use_cache:
            try:
                cache_data = self._load_cache()
                if cache_key in cache_data:
                    cache_meta = cache_data[cache_key].get('cache_meta', {})
                    cache_time = datetime.fromisoformat(cache_meta['timestamp'])
                    expire_time = cache_time + timedelta(minutes=self.cache_configs[data_type]['expire_minutes'])
                    
                    if datetime.now() < expire_time:
                        print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} {analysis_type} AIåˆ†æ")
                        return cache_data[cache_key].get('data', {})
            except Exception:
                pass
        
        # AIåˆ†ææ•°æ®éœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼Œè¿™é‡Œè¿”å›ç°æœ‰ç¼“å­˜
        print(f"ğŸ“‹ ä½¿ç”¨ç°æœ‰çš„ {stock_code} {analysis_type} AIåˆ†æ")
        try:
            cache_data = self._load_cache()
            return cache_data.get(cache_key, {}).get('data', {})
        except Exception:
            return {}
    
    def set_ai_analysis(self, stock_code: str, analysis_type: str, analysis_data: Dict):
        """è®¾ç½®AIåˆ†ææ•°æ®"""
        try:
            stock_code, _ = normalize_stock_input(stock_code, 'stock')
        except:
            pass
            
        cache_key = f"ai_analysis_{analysis_type}_{stock_code}"
        analysis_data['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        try:
            cache_data = self._load_cache()
            cache_data[cache_key] = {
                'cache_meta': {
                    'timestamp': datetime.now().isoformat(),
                    'data_type': 'ai_analysis',
                    'stock_code': stock_code,
                    'analysis_type': analysis_type,
                    'expire_minutes': self.cache_configs['ai_analysis']['expire_minutes']
                },
                'data': analysis_data
            }
            self._save_cache(cache_data)
            print(f"ğŸ’¾ {stock_code} {analysis_type} AIåˆ†æå·²ç¼“å­˜")
        except Exception as e:
            print(f"âŒ ç¼“å­˜AIåˆ†æå¤±è´¥: {e}")
    
    # =========================
    # AIåˆ†ææŠ¥å‘Šæ–¹æ³•
    # =========================
    
    def generate_fundamental_analysis_with_cache(self, stock_code: str, stock_name: str = None, 
                                                market_info: Dict = None, fundamental_data: Dict = None,
                                                use_cache: bool = True, force_refresh: bool = False) -> Tuple[str, str]:
        """
        ç”ŸæˆåŸºæœ¬é¢åˆ†ææŠ¥å‘Šï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            market_info: å¸‚åœºä¿¡æ¯
            fundamental_data: åŸºæœ¬é¢æ•°æ®
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            Tuple[str, str]: (åˆ†ææŠ¥å‘Š, æ—¶é—´æˆ³)
        """
        analysis_type = "fundamental"
        cache_key = f"ai_analysis_{analysis_type}_{stock_code}"
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh:
            cached_data = self.get_ai_analysis(stock_code, analysis_type, use_cache=True)
            if cached_data and 'report' in cached_data:
                return cached_data['report'], cached_data.get('timestamp', '')
        
        # æ£€æŸ¥AIåˆ†ææ¨¡å—æ˜¯å¦å¯ç”¨
        if not AI_ANALYSIS_AVAILABLE:
            error_msg = "AIåˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…"
            return error_msg, datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        try:
            # è·å–å¿…è¦æ•°æ®
            if stock_name is None:
                stock_name = get_stock_name(stock_code, 'stock')
            if market_info is None:
                market_info = get_market_info(stock_code)
            
            # ç”ŸæˆåŸºæœ¬é¢åˆ†ææŠ¥å‘Š
            report, timestamp = generate_fundamental_analysis_report(
                stock_code=stock_code,
                stock_name=stock_name,
                market_info=market_info,
                fundamental_data=fundamental_data or {}
            )
            
            # ç¼“å­˜ç»“æœ
            self.set_ai_analysis(stock_code, analysis_type, {
                'report': report,
                'timestamp': timestamp,
                'stock_name': stock_name
            })
            
            return report, timestamp
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            error_msg = f"åŸºæœ¬é¢åˆ†æå¤±è´¥: {str(e)}"
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return error_msg, timestamp
    
    def generate_stock_analysis_with_cache(self, stock_code: str, stock_name: str = None,
                                         market_info: Dict = None, df=None, indicators: Dict = None,
                                         use_cache: bool = True, force_refresh: bool = False) -> Tuple[str, str]:
        """
        ç”Ÿæˆè‚¡ç¥¨æŠ€æœ¯åˆ†ææŠ¥å‘Šï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            market_info: å¸‚åœºä¿¡æ¯
            df: Kçº¿æ•°æ®DataFrame
            indicators: æŠ€æœ¯æŒ‡æ ‡
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            Tuple[str, str]: (åˆ†ææŠ¥å‘Š, æ—¶é—´æˆ³)
        """
        analysis_type = "technical"
        cache_key = f"ai_analysis_{analysis_type}_{stock_code}"
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh:
            cached_data = self.get_ai_analysis(stock_code, analysis_type, use_cache=True)
            if cached_data and 'report' in cached_data:
                return cached_data['report'], cached_data.get('timestamp', '')
        
        # æ£€æŸ¥AIåˆ†ææ¨¡å—æ˜¯å¦å¯ç”¨
        if not AI_ANALYSIS_AVAILABLE:
            error_msg = "AIåˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…"
            return error_msg, datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        try:
            # è·å–å¿…è¦æ•°æ®
            if stock_name is None:
                stock_name = get_stock_name(stock_code, 'stock')
            if market_info is None:
                market_info = get_market_info(stock_code)
            if df is None:
                kline_data = self.get_stock_kline_data(stock_code)
                if 'data' in kline_data and 'df' in kline_data['data']:
                    df = kline_data['data']['df']
                else:
                    raise ValueError("æ— æ³•è·å–Kçº¿æ•°æ®")
            if indicators is None:
                indicators = get_indicators(df)
            
            # ç”ŸæˆæŠ€æœ¯åˆ†ææŠ¥å‘Š
            report = generate_stock_analysis_report(
                stock_code=stock_code,
                stock_name=stock_name,
                market_info=market_info,
                df=df,
                indicators=indicators
            )
            
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # ç¼“å­˜ç»“æœ
            self.set_ai_analysis(stock_code, analysis_type, {
                'report': report,
                'timestamp': timestamp,
                'stock_name': stock_name
            })
            
            return report, timestamp
            
        except Exception as e:
            error_msg = f"æŠ€æœ¯åˆ†æå¤±è´¥: {str(e)}"
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return error_msg, timestamp
    
    def generate_news_analysis_with_cache(self, stock_code: str, stock_name: str = None,
                                        market_info: Dict = None, news_data: List = None,
                                        use_cache: bool = True, force_refresh: bool = False) -> Tuple[str, str]:
        """
        ç”Ÿæˆæ–°é—»åˆ†ææŠ¥å‘Šï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            market_info: å¸‚åœºä¿¡æ¯
            news_data: æ–°é—»æ•°æ®
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            Tuple[str, str]: (åˆ†ææŠ¥å‘Š, æ—¶é—´æˆ³)
        """
        analysis_type = "news"
        cache_key = f"ai_analysis_{analysis_type}_{stock_code}"
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh:
            cached_data = self.get_ai_analysis(stock_code, analysis_type, use_cache=True)
            if cached_data and 'report' in cached_data:
                return cached_data['report'], cached_data.get('timestamp', '')
        
        # æ£€æŸ¥AIåˆ†ææ¨¡å—æ˜¯å¦å¯ç”¨
        if not AI_ANALYSIS_AVAILABLE:
            error_msg = "AIåˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…"
            return error_msg, datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        try:
            # è·å–å¿…è¦æ•°æ®
            if stock_name is None:
                stock_name = get_stock_name(stock_code, 'stock')
            if market_info is None:
                market_info = get_market_info(stock_code)
            if news_data is None:
                news_result = self.get_stock_news_data(stock_code)
                if 'data' in news_result and 'news' in news_result['data']:
                    news_data = news_result['data']['news']
                else:
                    news_data = []
            
            # ç”Ÿæˆæ–°é—»åˆ†ææŠ¥å‘Š
            report, timestamp = generate_news_analysis_report(
                stock_code=stock_code,
                stock_name=stock_name,
                market_info=market_info,
                news_data=news_data
            )
            
            # ç¼“å­˜ç»“æœ
            self.set_ai_analysis(stock_code, analysis_type, {
                'report': report,
                'timestamp': timestamp,
                'stock_name': stock_name
            })
            
            return report, timestamp
            
        except Exception as e:
            error_msg = f"æ–°é—»åˆ†æå¤±è´¥: {str(e)}"
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return error_msg, timestamp
    
    def generate_chip_analysis_with_cache(self, stock_code: str, stock_name: str = None,
                                        chip_data: Dict = None,
                                        use_cache: bool = True, force_refresh: bool = False) -> Tuple[str, str]:
        """
        ç”Ÿæˆç­¹ç åˆ†ææŠ¥å‘Šï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            chip_data: ç­¹ç æ•°æ®
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            Tuple[str, str]: (åˆ†ææŠ¥å‘Š, æ—¶é—´æˆ³)
        """
        analysis_type = "chip"
        cache_key = f"ai_analysis_{analysis_type}_{stock_code}"
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache and not force_refresh:
            cached_data = self.get_ai_analysis(stock_code, analysis_type, use_cache=True)
            if cached_data and 'report' in cached_data:
                return cached_data['report'], cached_data.get('timestamp', '')
        
        # æ£€æŸ¥AIåˆ†ææ¨¡å—æ˜¯å¦å¯ç”¨
        if not AI_ANALYSIS_AVAILABLE:
            error_msg = "AIåˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…"
            return error_msg, datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        try:
            # è·å–å¿…è¦æ•°æ®
            if stock_name is None:
                stock_name = get_stock_name(stock_code, 'stock')
            if chip_data is None:
                raise ValueError("æ— æ³•è·å–ç­¹ç æ•°æ®")
            
            # ç”Ÿæˆç­¹ç åˆ†ææŠ¥å‘Š
            report, timestamp = generate_chip_analysis_report(
                stock_code=stock_code,
                stock_name=stock_name,
                chip_data=chip_data
            )
            
            # ç¼“å­˜ç»“æœ
            self.set_ai_analysis(stock_code, analysis_type, {
                'report': report,
                'timestamp': timestamp,
                'stock_name': stock_name
            })
            
            return report, timestamp
            
        except Exception as e:
            error_msg = f"ç­¹ç åˆ†æå¤±è´¥: {str(e)}"
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            return error_msg, timestamp
    
    def get_comprehensive_ai_analysis(self, stock_code: str, user_opinion: str = "", 
                                     use_cache: bool = True, force_refresh: bool = False) -> Dict:
        """è·å–ç»¼åˆAIåˆ†ææ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            user_opinion: ç”¨æˆ·è§‚ç‚¹
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            Dict: ç»¼åˆåˆ†æç»“æœ
        """
        data_type = 'ai_analysis'
        analysis_type = 'comprehensive'
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            stock_code, stock_name = normalize_stock_input(stock_code, 'stock')
        except Exception as e:
            return {
                'error': f'è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯: {str(e)}',
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        
        cache_key = f"{data_type}_{analysis_type}_{stock_code}"
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆå¦‚æœç”¨æˆ·è§‚ç‚¹ä¸ºç©ºä¸”ä¸å¼ºåˆ¶åˆ·æ–°ï¼‰
        if use_cache and not force_refresh and not user_opinion.strip():
            try:
                cache_data = self._load_cache()
                if cache_key in cache_data:
                    cache_meta = cache_data[cache_key].get('cache_meta', {})
                    cache_time = datetime.fromisoformat(cache_meta['timestamp'])
                    expire_time = cache_time + timedelta(minutes=self.cache_configs[data_type]['expire_minutes'])
                    
                    if datetime.now() < expire_time:
                        print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ {stock_code} ç»¼åˆåˆ†æ")
                        return cache_data[cache_key].get('data', {})
            except Exception:
                pass
        
        # ç”Ÿæˆæ–°çš„ç»¼åˆåˆ†æ
        try:
            # æ£€æŸ¥AIåˆ†ææ¨¡å—æ˜¯å¦å¯ç”¨
            if not AI_ANALYSIS_AVAILABLE:
                return {
                    'error': 'AIåˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…',
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
            
            print(f"ğŸ¤– ç”Ÿæˆ {stock_code} ç»¼åˆAIåˆ†æ...")
            
            # å¯¼å…¥åˆ†æå‡½æ•°
            from analysis.stock_ai_analysis import generate_comprehensive_analysis_report
            
            # ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
            report, data_sources = generate_comprehensive_analysis_report(
                stock_code=stock_code,
                stock_name=stock_name,
                user_opinion=user_opinion,
                stock_tools=self
            )
            
            # æ„å»ºåˆ†ææ•°æ®
            analysis_data = {
                'report': report,
                'data_sources': data_sources,
                'analysis_info': {
                    'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'data_sources_count': len(data_sources),
                    'user_opinion_included': bool(user_opinion.strip()),
                    'user_opinion': user_opinion.strip() if user_opinion.strip() else None
                },
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'cache_time': datetime.now().isoformat()
            }
            
            # ç¼“å­˜ç»“æœ
            try:
                cache_data = self._load_cache()
                cache_data[cache_key] = {
                    'cache_meta': {
                        'timestamp': datetime.now().isoformat(),
                        'data_type': data_type,
                        'stock_code': stock_code,
                        'analysis_type': analysis_type,
                        'expire_minutes': self.cache_configs[data_type]['expire_minutes']
                    },
                    'data': analysis_data
                }
                self._save_cache(cache_data)
                print(f"ğŸ’¾ {stock_code} ç»¼åˆåˆ†æå·²ç¼“å­˜")
            except Exception as e:
                print(f"âŒ ç¼“å­˜ç»¼åˆåˆ†æå¤±è´¥: {e}")
            
            return analysis_data
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç»¼åˆåˆ†æå¤±è´¥: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    # =========================
    # ç»¼åˆæŠ¥å‘Šæ–¹æ³•
    # =========================
    
    def get_comprehensive_stock_report(self, stock_code: str, use_cache: bool = True) -> Dict:
        """è·å–è‚¡ç¥¨ç»¼åˆæŠ¥å‘Š"""
        print(f"ğŸ“‹ ç”Ÿæˆ {stock_code} ç»¼åˆè‚¡ç¥¨æŠ¥å‘Š...")
        print("=" * 60)
        
        report = {
            'report_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'stock_code': stock_code,
            'basic_info': {},
            'kline_data': {},
            'news_data': {},
            'chip_data': {},
            'ai_analysis': {},
            'stock_summary': {}
        }
        
        # è·å–å„ç±»æ•°æ®
        report['basic_info'] = self.get_stock_basic_info(stock_code, use_cache)
        report['kline_data'] = self.get_stock_kline_data(stock_code, 160, use_cache)
        report['news_data'] = self.get_stock_news_data(stock_code, use_cache)
        report['chip_data'] = self.get_stock_chip_data(stock_code, use_cache)
        
        # è·å–å„ç§AIåˆ†æ
        report['ai_analysis'] = {
            'fundamental': self.get_ai_analysis(stock_code, 'fundamental', use_cache),
            'market': self.get_ai_analysis(stock_code, 'market', use_cache),
            'news': self.get_ai_analysis(stock_code, 'news', use_cache),
            'chip': self.get_ai_analysis(stock_code, 'chip', use_cache),
        }
        
        # ç”Ÿæˆè‚¡ç¥¨æ‘˜è¦
        report['stock_summary'] = self._generate_stock_summary(report)
        
        print("=" * 60)
        print("âœ… ç»¼åˆè‚¡ç¥¨æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        
        return report
    
    def _generate_stock_summary(self, report: Dict) -> Dict:
        """ç”Ÿæˆè‚¡ç¥¨æ‘˜è¦"""
        summary = {}
        
        # åŸºæœ¬ä¿¡æ¯æ‘˜è¦
        basic = report['basic_info']
        if basic and 'error' not in basic:
            summary['current_price'] = basic.get('current_price', 0)
            summary['change_percent'] = basic.get('change_percent', 0)
            summary['stock_name'] = basic.get('name', '')
            summary['industry'] = basic.get('industry', '')
        
        # æŠ€æœ¯é¢æ‘˜è¦
        kline = report['kline_data']
        if kline and 'error' not in kline:
            indicators = kline.get('indicators', {})
            summary['technical_trend'] = f"{indicators.get('ma_trend', 'æœªçŸ¥')} | MACD {indicators.get('macd_trend', 'æœªçŸ¥')}"
            summary['rsi_level'] = self._judge_rsi_level(indicators.get('rsi_14', 50))
        
        # æ–°é—»æ‘˜è¦
        news = report['news_data']
        if news and 'error' not in news:
            summary['news_count'] = news.get('news_count', 0)
        
        # ç­¹ç æ‘˜è¦
        chip = report['chip_data']
        if chip and 'error' not in chip:
            summary['profit_ratio'] = chip.get('profit_ratio', 0)
            summary['avg_cost'] = chip.get('avg_cost', 0)
        
        return summary
    
    def _judge_rsi_level(self, rsi: float) -> str:
        """åˆ¤æ–­RSIæ°´å¹³"""
        if rsi >= 80:
            return "è¶…ä¹°"
        elif rsi >= 70:
            return "å¼ºåŠ¿"
        elif rsi >= 30:
            return "æ­£å¸¸"
        elif rsi >= 20:
            return "å¼±åŠ¿"
        else:
            return "è¶…å–"
    
    # =========================
    # ç¼“å­˜ç®¡ç†æ–¹æ³•
    # =========================
    
    def clear_cache(self, stock_code: str = None, data_type: str = None):
        """æ¸…ç†ç¼“å­˜"""
        try:
            cache_data = self._load_cache()
            
            if stock_code and data_type:
                # æ¸…ç†ç‰¹å®šè‚¡ç¥¨çš„ç‰¹å®šæ•°æ®ç±»å‹
                cache_key = self._get_cache_key(data_type, stock_code)
                if cache_key in cache_data:
                    del cache_data[cache_key]
                    self._save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç† {stock_code} {self.cache_configs.get(data_type, {}).get('description', data_type)} ç¼“å­˜")
                else:
                    print(f"â„¹ï¸  {stock_code} {data_type} ç¼“å­˜ä¸å­˜åœ¨")
                    
            elif stock_code:
                # æ¸…ç†ç‰¹å®šè‚¡ç¥¨çš„æ‰€æœ‰ç¼“å­˜
                keys_to_remove = [key for key in cache_data.keys() if key.endswith(f"_{stock_code}")]
                for key in keys_to_remove:
                    del cache_data[key]
                if keys_to_remove:
                    self._save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç† {stock_code} æ‰€æœ‰ç¼“å­˜ ({len(keys_to_remove)}é¡¹)")
                else:
                    print(f"â„¹ï¸  {stock_code} æ— ç¼“å­˜æ•°æ®")
                    
            elif data_type:
                # æ¸…ç†ç‰¹å®šæ•°æ®ç±»å‹çš„æ‰€æœ‰ç¼“å­˜
                keys_to_remove = [key for key in cache_data.keys() if key.startswith(f"{data_type}_")]
                for key in keys_to_remove:
                    del cache_data[key]
                if keys_to_remove:
                    self._save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç†æ‰€æœ‰ {self.cache_configs.get(data_type, {}).get('description', data_type)} ç¼“å­˜ ({len(keys_to_remove)}é¡¹)")
                else:
                    print(f"â„¹ï¸  æ—  {data_type} ç¼“å­˜æ•°æ®")
                    
            else:
                # æ¸…ç†æ‰€æœ‰ç¼“å­˜
                if os.path.exists(self.cache_file):
                    os.remove(self.cache_file)
                    print("âœ… å·²æ¸…ç†æ‰€æœ‰è‚¡ç¥¨æ•°æ®ç¼“å­˜")
                else:
                    print("â„¹ï¸  ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")
                    
        except Exception as e:
            print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cache_status(self, stock_code: str = None) -> Dict:
        """è·å–ç¼“å­˜çŠ¶æ€"""
        status = {}
        current_time = datetime.now()
        cache_data = self._load_cache()
        
        for cache_key, cache_info in cache_data.items():
            try:
                cache_meta = cache_info.get('cache_meta', {})
                cached_stock_code = cache_meta.get('stock_code', '')
                data_type = cache_meta.get('data_type', '')
                analysis_type = cache_meta.get('analysis_type', '')
                
                # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œåªæ˜¾ç¤ºè¯¥è‚¡ç¥¨çš„ç¼“å­˜
                if stock_code and cached_stock_code != stock_code:
                    continue
                
                cache_time = datetime.fromisoformat(cache_meta['timestamp'])
                expire_minutes = cache_meta.get('expire_minutes', 60)
                expire_time = cache_time + timedelta(minutes=expire_minutes)
                is_valid = current_time < expire_time
                
                remaining_minutes = (expire_time - current_time).total_seconds() / 60
                if remaining_minutes > 0:
                    remaining_text = f"å‰©ä½™ {int(remaining_minutes)} åˆ†é’Ÿ"
                else:
                    remaining_text = "å·²è¿‡æœŸ"
                
                display_key = cache_key
                if analysis_type:
                    display_key = f"{cached_stock_code}_{analysis_type}_AIåˆ†æ"
                
                status[display_key] = {
                    'stock_code': cached_stock_code,
                    'data_type': data_type,
                    'analysis_type': analysis_type,
                    'description': self.cache_configs.get(data_type, {}).get('description', data_type),
                    'valid': is_valid,
                    'cache_time': cache_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'expire_minutes': expire_minutes,
                    'remaining': remaining_text
                }
            except Exception:
                continue
        
        return status
    
    def print_cache_status(self, stock_code: str = None):
        """æ‰“å°ç¼“å­˜çŠ¶æ€"""
        status = self.get_cache_status(stock_code)
        
        print("=" * 70)
        if stock_code:
            print(f"ğŸ“Š è‚¡ç¥¨ {stock_code} æ•°æ®ç¼“å­˜çŠ¶æ€")
        else:
            print("ğŸ“Š è‚¡ç¥¨æ•°æ®ç¼“å­˜çŠ¶æ€")
        print(f"ğŸ“ ç¼“å­˜æ–‡ä»¶: {self.cache_file}")
        print("=" * 70)
        
        if not status:
            if stock_code:
                print(f"â„¹ï¸  è‚¡ç¥¨ {stock_code} æ— ç¼“å­˜æ•°æ®")
            else:
                print("â„¹ï¸  æ— ç¼“å­˜æ•°æ®")
        else:
            for key, info in status.items():
                status_icon = "âœ…" if info['valid'] else "âŒ"
                print(f"{status_icon} {info['stock_code']:<8} | {info['description']:<12} | {info['remaining']:<15} | è¿‡æœŸ: {info['expire_minutes']}åˆ†é’Ÿ")
        
        # æ˜¾ç¤ºç¼“å­˜æ–‡ä»¶å¤§å°
        try:
            if os.path.exists(self.cache_file):
                file_size = os.path.getsize(self.cache_file) / 1024  # KB
                print(f"ğŸ’¾ ç¼“å­˜æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
            else:
                print("ğŸ’¾ ç¼“å­˜æ–‡ä»¶: ä¸å­˜åœ¨")
        except Exception:
            pass
        
        print("=" * 70)


# =========================
# å…¨å±€å®ä¾‹å’Œä¾¿æ·å‡½æ•°
# =========================

# å…¨å±€è‚¡ç¥¨å·¥å…·å®ä¾‹
_stock_tools = None

def get_stock_tools() -> StockTools:
    """è·å–å…¨å±€è‚¡ç¥¨å·¥å…·å®ä¾‹"""
    global _stock_tools
    if _stock_tools is None:
        _stock_tools = StockTools()
    return _stock_tools

def show_stock_cache_status(stock_code: str = None):
    """æ˜¾ç¤ºè‚¡ç¥¨ç¼“å­˜çŠ¶æ€"""
    tools = get_stock_tools()
    tools.print_cache_status(stock_code)

def clear_stock_cache(stock_code: str = None, data_type: str = None):
    """æ¸…ç†è‚¡ç¥¨æ•°æ®ç¼“å­˜"""
    tools = get_stock_tools()
    tools.clear_cache(stock_code, data_type)

def set_stock_ai_analysis(stock_code: str, analysis_type: str, analysis_data: Dict):
    """è®¾ç½®è‚¡ç¥¨AIåˆ†ææ•°æ®"""
    tools = get_stock_tools()
    tools.set_ai_analysis(stock_code, analysis_type, analysis_data)

def get_stock_ai_analysis(stock_code: str, analysis_type: str = 'comprehensive') -> Dict:
    """è·å–è‚¡ç¥¨AIåˆ†ææ•°æ®"""
    tools = get_stock_tools()
    return tools.get_ai_analysis(stock_code, analysis_type)

if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€è‚¡ç¥¨å·¥å…·æ¨¡å—...")
    
    tools = get_stock_tools()
    test_stock = "000001"  # å¹³å®‰é“¶è¡Œ
    
    print(f"\n1. æ˜¾ç¤º {test_stock} ç¼“å­˜çŠ¶æ€:")
    tools.print_cache_status(test_stock)
    
    print(f"\n2. è·å– {test_stock} åŸºæœ¬ä¿¡æ¯:")
    basic_info = tools.get_stock_basic_info(test_stock)
    if 'error' not in basic_info:
        print(f"   å½“å‰ä»·æ ¼: {basic_info.get('current_price', 'N/A')}")
        print(f"   è‚¡ç¥¨åç§°: {basic_info.get('name', 'N/A')}")
    else:
        print(f"   é”™è¯¯: {basic_info['error']}")
    
    print(f"\n3. æ˜¾ç¤ºæ›´æ–°åçš„ç¼“å­˜çŠ¶æ€:")
    tools.print_cache_status(test_stock)
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
