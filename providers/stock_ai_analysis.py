"""
è‚¡ç¥¨AIåˆ†æå·¥å…·
æä¾›åŸºäºLLMçš„è‚¡ç¥¨å¸‚åœºåˆ†æåŠŸèƒ½ã€ç­¹ç åˆ†æåŠŸèƒ½ã€æ–°é—»åˆ†æåŠŸèƒ½å’ŒåŸºæœ¬é¢åˆ†æåŠŸèƒ½
"""

from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass
from llm.openai_client import OpenAIClient
import datetime
import sys
import os
import traceback

project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_dir not in sys.path:
    sys.path.append(project_dir)

from utils.string_utils import remove_markdown_format
from providers.data_formatters import get_stock_formatter


@dataclass
class AnalysisResult:
    """AIåˆ†æç»“æœçš„ç»Ÿä¸€æ ¼å¼"""
    success: bool
    report: str
    timestamp: str
    error_message: Optional[str] = None
    analysis_type: str = ""
    stock_code: str = ""
    data_sources: Optional[List[Dict]] = None


class AnalysisConfig:
    """AIåˆ†æé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        try:
            from config_manager import config
            self.config = config
        except Exception as e:
            print(f"åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            self.config = None
    
    def get_analysis_config(self, analysis_type: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šåˆ†æç±»å‹çš„é…ç½®"""
        if not self.config:
            return self._get_default_config(analysis_type)
        
        try:
            config_key = f"AI_ANALYSIS.{analysis_type.upper()}"
            return {
                'temperature': self.config.get(f'{config_key}.TEMPERATURE', 0.5),
                'model_type': self.config.get(f'{config_key}.MODEL_TYPE', 'default'),
                'max_length': self.config.get(f'{config_key}.MAX_LENGTH', 500),
                'cache_filename': self.config.get(f'{config_key}.CACHE_FILENAME', f'req_{analysis_type}.txt')
            }
        except Exception as e:
            print(f"è·å–{analysis_type}é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return self._get_default_config(analysis_type)
    
    def _get_default_config(self, analysis_type: str) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        defaults = {
            'technical': {'temperature': 0.5, 'model_type': 'inference', 'max_length': 500, 'cache_filename': 'req_tech.txt'},
            'news': {'temperature': 0.7, 'model_type': 'default', 'max_length': 800, 'cache_filename': 'req_news.txt'},
            'chip': {'temperature': 0.5, 'model_type': 'default', 'max_length': 500, 'cache_filename': 'req_chip.txt'},
            'fundamental': {'temperature': 0.6, 'model_type': 'default', 'max_length': 500, 'cache_filename': 'req_basic_info.txt'},
            'comprehensive': {'temperature': 0.4, 'model_type': 'default', 'max_length': 800, 'cache_filename': 'req.txt'}
        }
        return defaults.get(analysis_type, defaults['comprehensive'])


class DataCollector:
    """æ•°æ®æ”¶é›†å™¨ - è´Ÿè´£æ”¶é›†å„ç§åˆ†ææ‰€éœ€çš„æ•°æ®"""
    
    def __init__(self):
        self.formatter = get_stock_formatter()
    
    def collect_stock_basic_info(self, stock_identity: Dict[str, Any]) -> Tuple[str, Optional[Dict]]:
        """æ”¶é›†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            from providers.stock_data_tools import get_stock_tools
            stock_tools = get_stock_tools()
            basic_info = stock_tools.get_basic_info(stock_identity, use_cache=True)
            
            if basic_info and 'error' not in basic_info:
                formatted_info = self.formatter.format_basic_info(basic_info, stock_identity)
                data_source = {
                    'type': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯',
                    'description': 'åŒ…å«å½“å‰ä»·æ ¼ã€æ¶¨è·Œé¢ã€æ¶¨è·Œå¹…ç­‰å®æ—¶æ•°æ®',
                    'timestamp': basic_info.get('update_time', 'æœªçŸ¥æ—¶é—´')
                }
                return formatted_info, data_source
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        
        return "", None
    
    def collect_historical_analyses(self, stock_code: str, stock_tools=None) -> Tuple[Dict[str, str], List[Dict]]:
        """æ”¶é›†å†å²åˆ†ææ•°æ®"""
        historical_analyses = {}
        data_sources = []
        
        if not stock_tools:
            return historical_analyses, data_sources
        
        analysis_types = {
            'technical': 'æŠ€æœ¯åˆ†æ',
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'news': 'æ–°é—»åˆ†æ',
            'chip': 'ç­¹ç åˆ†æ'
        }
        
        for analysis_type, description in analysis_types.items():
            try:
                cached_analysis = stock_tools.get_cached_ai_analysis(stock_code, analysis_type, use_cache=True)
                if cached_analysis and 'report' in cached_analysis:
                    historical_analyses[analysis_type] = cached_analysis['report']
                    data_sources.append({
                        'type': description,
                        'description': f'ç¼“å­˜çš„{description}æŠ¥å‘Š',
                        'timestamp': cached_analysis.get('timestamp', 'æœªçŸ¥æ—¶é—´')
                    })
            except Exception as e:
                print(f"è·å–{description}å¤±è´¥: {e}")
        
        return historical_analyses, data_sources
    
    def collect_market_data(self, market_tools=None) -> Tuple[str, str, List[Dict]]:
        """æ”¶é›†å¸‚åœºæ•°æ®"""
        market_report_text = ""
        market_ai_analysis = ""
        data_sources = []
        
        if not market_tools:
            try:
                from providers.market_data_tools import get_market_tools
                market_tools = get_market_tools()
            except Exception as e:
                print(f"å¯¼å…¥market_toolså¤±è´¥: {e}")
                return market_report_text, market_ai_analysis, data_sources
        
        # æ”¶é›†å¸‚åœºç»¼åˆæŠ¥å‘Š
        try:
            market_report = market_tools.get_comprehensive_market_report(use_cache=True)
            if market_report:
                data_sources.append({
                    'type': 'å¸‚åœºç»¼åˆæŠ¥å‘Š',
                    'description': 'åŒ…å«æŠ€æœ¯æŒ‡æ ‡ã€æƒ…ç»ªã€ä¼°å€¼ã€èµ„é‡‘æµå‘ç­‰å¸‚åœºæ•°æ®',
                    'timestamp': market_report.get('report_time', 'æœªçŸ¥æ—¶é—´')
                })
                market_report_text = market_tools.generate_market_report(market_report, format_type='summary')
        except Exception as e:
            print(f"è·å–å¸‚åœºç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")
        
        # æ”¶é›†AIå¤§ç›˜åˆ†æ
        try:
            market_ai_data = market_tools.get_ai_analysis(use_cache=True)
            if market_ai_data:
                if isinstance(market_ai_data, dict) and 'report' in market_ai_data:
                    market_ai_analysis = market_ai_data['report']
                data_sources.append({
                    'type': 'AIå¤§ç›˜åˆ†æ',
                    'description': 'åŸºäºAIæ¨¡å‹çš„å¸‚åœºåˆ†ææŠ¥å‘Š',
                    'timestamp': market_ai_data.get('analysis_time', 'æœªçŸ¥æ—¶é—´')
                })
        except Exception as e:
            print(f"è·å–å¤§ç›˜åˆ†æå¤±è´¥: {e}")
        
        return market_report_text, market_ai_analysis, data_sources
    
    def collect_user_profile(self) -> Tuple[str, str, List[Dict]]:
        """æ”¶é›†ç”¨æˆ·ç”»åƒæ•°æ®"""
        user_profile_section = ""
        user_mistakes_section = ""
        data_sources = []
        
        try:
            from config_manager import config
            
            # ç”¨æˆ·ç”»åƒ
            user_profile_raw = config.get('USER_PROFILE.RAW', '').strip()
            if user_profile_raw:
                user_profile_section = f"\n# ç”¨æˆ·ç”»åƒ\n{user_profile_raw}\n"
                data_sources.append({
                    'type': 'ç”¨æˆ·ç”»åƒ',
                    'description': 'ç”¨æˆ·çš„æŠ•èµ„åå¥½ã€é£é™©æ‰¿å—èƒ½åŠ›ç­‰ä¿¡æ¯',
                    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
            
            # ç”¨æˆ·å¸¸çŠ¯é”™è¯¯
            user_mistakes = config.get('USER_PROFILE.MISTAKES', '')
            if user_mistakes:
                user_mistakes_section = f"\n# ç”¨æˆ·å¸¸çŠ¯é”™è¯¯\n{user_mistakes}\n"
                data_sources.append({
                    'type': 'ç”¨æˆ·å¸¸çŠ¯é”™è¯¯',
                    'description': 'ç”¨æˆ·åœ¨æŠ•èµ„è¿‡ç¨‹ä¸­å¸¸çŠ¯çš„é”™è¯¯å’Œè¯¯åŒº',
                    'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })
        except Exception as e:
            print(f"è·å–ç”¨æˆ·é…ç½®å¤±è´¥: {e}")
        
        return user_profile_section, user_mistakes_section, data_sources


class ReportFormatter:
    """æŠ¥å‘Šæ ¼å¼åŒ–å™¨ - è´Ÿè´£æ ¼å¼åŒ–å„ç§æ•°æ®ä¸ºæŠ¥å‘Šæ ¼å¼"""
    
    @staticmethod
    def format_historical_summary(historical_analyses: Dict[str, str], truncate_data: bool = False) -> str:
        """æ ¼å¼åŒ–å†å²åˆ†ææ‘˜è¦"""
        if not historical_analyses:
            return "\n\n## ğŸ“Š å†å²åˆ†ææ‘˜è¦\næœªæ‰¾åˆ°ç›¸å…³å†å²åˆ†ææ•°æ®ï¼Œå°†åŸºäºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¿›è¡Œåˆ†æã€‚\n"
        
        analysis_types = {
            'technical': 'æŠ€æœ¯åˆ†æ',
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'news': 'æ–°é—»åˆ†æ',
            'chip': 'ç­¹ç åˆ†æ'
        }
        
        historical_summary = "\n\n# ğŸ“Š å†å²åˆ†ææ‘˜è¦\n"
        for analysis_type, report in historical_analyses.items():
            if truncate_data:
                summary = report[:300] + "..." if len(report) > 300 else report
            else:
                summary = report
            summary = remove_markdown_format(summary)
            historical_summary += f"\n## {analysis_types.get(analysis_type, analysis_type)}:\n\n{summary}\n"
        
        return historical_summary
    
    @staticmethod
    def format_market_summary(market_report_text: str, market_ai_analysis: str, truncate_data: bool = False) -> str:
        """æ ¼å¼åŒ–å¸‚åœºç¯å¢ƒåˆ†æ"""
        if not market_report_text and not market_ai_analysis:
            return "\n\n## ğŸŒ å¸‚åœºç¯å¢ƒåˆ†æ\næš‚æ— å¸‚åœºç¯å¢ƒæ•°æ®ã€‚\n\n"
        
        market_summary = "\n\n# ğŸŒ å¸‚åœºç¯å¢ƒåˆ†æ\n"
        
        if market_report_text:
            market_text_summary = market_report_text[:500] + "..." if truncate_data and len(market_report_text) > 500 else market_report_text
            market_summary += f"\n## å¸‚åœºç»¼åˆæŠ¥å‘Š:\n\n{market_text_summary}\n\n"
        
        if market_ai_analysis:
            ai_summary = market_ai_analysis[:300] + "..." if truncate_data and len(market_ai_analysis) > 300 else market_ai_analysis
            market_summary += f"\n### AIå¤§ç›˜åˆ†æ:\n\n{ai_summary}\n\n"
        
        return market_summary
    
    @staticmethod
    def format_user_opinion_section(user_opinion: str, user_position: str) -> Tuple[str, List[Dict]]:
        """æ ¼å¼åŒ–ç”¨æˆ·è§‚ç‚¹éƒ¨åˆ†"""
        user_opinion_section = ""
        data_sources = []
        
        if user_opinion.strip():
            user_opinion_section = f"\n# ç”¨æˆ·è§‚ç‚¹\n{user_opinion.strip()}\n"
            data_sources.append({
                'type': 'ç”¨æˆ·è§‚ç‚¹',
                'description': 'ç”¨æˆ·æä¾›çš„æŠ•èµ„è§‚ç‚¹å’Œçœ‹æ³•',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        if user_position and user_position.strip() and user_position.strip() != "ä¸ç¡®å®š":
            user_opinion_section += f"\n# ç”¨æˆ·å½“å‰æŒä»“çŠ¶æ€\n{user_position.strip()}\n"
            data_sources.append({
                'type': 'ç”¨æˆ·æŒä»“',
                'description': f'ç”¨æˆ·å½“å‰æŒä»“çŠ¶æ€ï¼š{user_position.strip()}',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        return user_opinion_section, data_sources


def _save_request_to_cache(content: str, filename: str):
    """ä¿å­˜è¯·æ±‚å†…å®¹åˆ°ç¼“å­˜æ–‡ä»¶"""
    try:
        cache_path = os.path.join(project_dir, "data", "cache", filename)
        with open(cache_path, "w", encoding="utf-8") as f:
            f.write(content)
    except Exception as e:
        print(f"ä¿å­˜è¯·æ±‚æ–‡ä»¶{filename}å¤±è´¥: {e}")


def _handle_analysis_error(error: Exception, analysis_type: str = "åˆ†æ") -> Tuple[str, str]:
    """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†"""
    error_msg = f"ç”Ÿæˆ{analysis_type}æŠ¥å‘Šå¤±è´¥: {str(error)}"
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    return error_msg, timestamp


class BaseAnalysisGenerator:
    """åŸºç¡€åˆ†æç”Ÿæˆå™¨ - æä¾›é€šç”¨çš„åˆ†æç”ŸæˆåŠŸèƒ½"""
    
    def __init__(self):
        self.client = OpenAIClient()
        self.config_manager = AnalysisConfig()
    
    def generate_analysis(self, analysis_type: str, messages: List[Dict], stock_code: str = "") -> AnalysisResult:
        """é€šç”¨çš„åˆ†æç”Ÿæˆæ–¹æ³•"""
        config = self.config_manager.get_analysis_config(analysis_type)
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        if len(messages) > 1:
            _save_request_to_cache(messages[1]['content'], config['cache_filename'])
        
        try:
            response = self.client.chat(
                messages=messages,
                temperature=config['temperature'],
                model_type=config['model_type']
            )
            
            return AnalysisResult(
                success=True,
                report=response,
                timestamp=timestamp,
                analysis_type=analysis_type,
                stock_code=stock_code
            )
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆ{analysis_type}åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}"
            print(error_msg)
            traceback.print_exc()
            
            return AnalysisResult(
                success=False,
                report=error_msg,
                timestamp=timestamp,
                error_message=str(e),
                analysis_type=analysis_type,
                stock_code=stock_code
            )

def get_stock_info(stock_identity):
    from providers.stock_data_tools import get_stock_tools
    stock_tools = get_stock_tools()
    return stock_tools.get_basic_info(stock_identity, use_cache=True)

def generate_stock_analysis_report(
    stock_identity: Dict[str, Any],
    kline_info: Dict[str, Any] = None,
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨æŠ€æœ¯åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    kline_text = formatter.format_kline_data(kline_info)

    # æ„å»ºåˆ†ææç¤º
    system_message = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨æŠ€æœ¯åˆ†æå¸ˆã€‚ä½ å¿…é¡»å¯¹{stock_name}ï¼ˆè‚¡ç¥¨ä»£ç ï¼š{stock_code}ï¼‰è¿›è¡Œè¯¦ç»†çš„æŠ€æœ¯åˆ†æã€‚

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}
- è´§å¸ï¼š{stock_identity.get('currency_name', 'äººæ°‘å¸')}({stock_identity.get('currency_symbol', 'Â¥')})

**åˆ†æè¦æ±‚ï¼š**
1. åŸºäºæä¾›çš„çœŸå®æ•°æ®è¿›è¡ŒæŠ€æœ¯åˆ†æ
2. åˆ†æç§»åŠ¨å¹³å‡çº¿ã€MACDã€RSIã€å¸ƒæ—å¸¦ç­‰æŠ€æœ¯æŒ‡æ ‡
3. è€ƒè™‘å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æ
4. æä¾›å…·ä½“çš„æ•°å€¼å’Œä¸“ä¸šåˆ†æ
5. ç»™å‡ºæ˜ç¡®çš„æŠ•èµ„å»ºè®®
6. é‡ç‚¹å…³æ³¨å½“å‰è‚¡ä»·å˜åŠ¨å¯¹æŠ€æœ¯åˆ†æçš„å½±å“

**è¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ
## ğŸ“‰ ä»·æ ¼è¶‹åŠ¿åˆ†æ
## ğŸ’­ æŠ•èµ„å»ºè®®

è¯·ä½¿ç”¨ä¸­æ–‡ï¼ŒåŸºäºçœŸå®æ•°æ®è¿›è¡Œåˆ†æã€‚ç¡®ä¿åœ¨åˆ†æä¸­æ­£ç¡®ä½¿ç”¨å…¬å¸åç§°"{stock_name}"å’Œè‚¡ç¥¨ä»£ç "{stock_code}"ã€‚"""

    # æ„å»ºæ¶ˆæ¯
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": f"""è¯·åŸºäºä»¥ä¸‹æ•°æ®å¯¹{stock_name}({stock_code})è¿›è¡ŒæŠ€æœ¯åˆ†æï¼š

{basic_info_section}

{kline_text}

è¯·è¿›è¡Œè¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ä»·æ ¼è¶‹åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡ã€æ”¯æ’‘é˜»åŠ›ä½å’ŒæŠ•èµ„å»ºè®®ã€‚æŠ¥å‘Šåº”ä¸å¤šäº500å­—ï¼Œå¿…é¡»åŸºäºæ•°æ®åšå‡ºä¸“ä¸šçš„åˆ†æã€‚è¯·å…³æ³¨å½“å‰è‚¡ä»·è¡¨ç°çš„å½±å“ã€‚"""
        }
    ]

    return generator.generate_analysis("technical", messages, stock_code)


def generate_news_analysis_report(
    stock_identity: Dict[str, Any],
    news_data: List[Dict]
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨æ–°é—»åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    news_text = formatter.format_news_data(news_data, has_content=True)
    
    # æ„å»ºåˆ†ææç¤º
    system_message = f"""æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œè´Ÿè´£åˆ†ææœ€æ–°çš„å¸‚åœºæ–°é—»å’Œäº‹ä»¶å¯¹è‚¡ç¥¨ä»·æ ¼çš„æ½œåœ¨å½±å“ã€‚

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- æ‰€å±å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}

æ‚¨çš„ä¸»è¦èŒè´£åŒ…æ‹¬ï¼š
1. è¯„ä¼°æ–°é—»äº‹ä»¶çš„ç´§æ€¥ç¨‹åº¦å’Œå¸‚åœºå½±å“
2. è¯†åˆ«å¯èƒ½å½±å“è‚¡ä»·çš„å…³é”®ä¿¡æ¯
3. åˆ†ææ–°é—»çš„æ—¶æ•ˆæ€§å’Œå¯é æ€§
4. æä¾›åŸºäºæ–°é—»çš„äº¤æ˜“å»ºè®®å’Œä»·æ ¼å½±å“è¯„ä¼°
5. å‚è€ƒå½“å‰è‚¡ä»·è¡¨ç°åˆ†æåšå‡ºåˆ†æå’Œé¢„æµ‹

é‡ç‚¹å…³æ³¨çš„æ–°é—»ç±»å‹ï¼š
- è´¢æŠ¥å‘å¸ƒå’Œä¸šç»©æŒ‡å¯¼
- é‡å¤§åˆä½œå’Œå¹¶è´­æ¶ˆæ¯
- æ”¿ç­–å˜åŒ–å’Œç›‘ç®¡åŠ¨æ€
- çªå‘äº‹ä»¶å’Œå±æœºç®¡ç†
- è¡Œä¸šè¶‹åŠ¿å’ŒæŠ€æœ¯çªç ´
- ç®¡ç†å±‚å˜åŠ¨å’Œæˆ˜ç•¥è°ƒæ•´

åˆ†æè¦ç‚¹ï¼š
- æ–°é—»çš„æ—¶æ•ˆæ€§ï¼ˆå‘å¸ƒæ—¶é—´è·ç¦»ç°åœ¨å¤šä¹…ï¼‰
- æ–°é—»çš„å¯ä¿¡åº¦ï¼ˆæ¥æºæƒå¨æ€§ï¼‰
- å¸‚åœºå½±å“ç¨‹åº¦ï¼ˆå¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“ï¼‰
- æŠ•èµ„è€…æƒ…ç»ªå˜åŒ–ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰

ğŸ“Š ä»·æ ¼å½±å“åˆ†æè¦æ±‚ï¼š
- è¯„ä¼°æ–°é—»å¯¹è‚¡ä»·çš„çŸ­æœŸå½±å“ï¼ˆ1-3å¤©ï¼‰
- åˆ†æå¯èƒ½çš„ä»·æ ¼æ³¢åŠ¨å¹…åº¦ï¼ˆç™¾åˆ†æ¯”ï¼‰
- æä¾›åŸºäºæ–°é—»çš„ä»·æ ¼è°ƒæ•´å»ºè®®

è¯·ç”¨ä¸­æ–‡æ’°å†™åˆ†ææŠ¥å‘Šï¼Œç»“æ„åº”åŒ…å«ï¼š
## ğŸ“° æ–°é—»æ¦‚è¿°
## ğŸ“Š å…³é”®ä¿¡æ¯åˆ†æ
## ğŸ’¹ å¸‚åœºå½±å“è¯„ä¼°
## ğŸ’¡ æŠ•èµ„å»ºè®®"""

    # æ„å»ºæ¶ˆæ¯
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": f"""è¯·åˆ†æä»¥ä¸‹å…³äº{stock_name}({stock_code})çš„æœ€æ–°æ–°é—»ï¼Œè¯„ä¼°å…¶å¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“ï¼š

{basic_info_section}

=== æœ€æ–°æ–°é—»æ•°æ® ===

{news_text}

è¯·æä¾›è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. æ–°é—»äº‹ä»¶çš„å…³é”®ä¿¡æ¯æå–
2. å¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“åˆ†æ
3. æŠ•èµ„å»ºè®®å’Œé£é™©è¯„ä¼°

æŠ¥å‘Šåº”ä¸è¶…è¿‡800å­—ï¼Œå¿…é¡»åŸºäºçœŸå®æ–°é—»æ•°æ®åšå‡ºä¸“ä¸šçš„åˆ†æã€‚å¦‚æœæ–°é—»æ•°æ®ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºåˆ†æçš„å±€é™æ€§ã€‚"""
        }
    ]
    
    return generator.generate_analysis("news", messages, stock_code)
        
        
def generate_chip_analysis_report(
    stock_identity: Dict[str, Any],
    chip_data: Dict[str, Any]
) -> AnalysisResult:
    """ç”Ÿæˆç­¹ç åˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_stock_overview(stock_identity, get_stock_info(stock_identity))
    chip_text = formatter.format_chip_data(chip_data)
    
    # æ„å»ºåˆ†ææç¤º
    system_message = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç­¹ç åˆ†æå¸ˆï¼Œä¸“ç²¾äºAè‚¡å¸‚åœºçš„ç­¹ç åˆ†å¸ƒæŠ€æœ¯åˆ†æã€‚ä½ èƒ½å¤Ÿæ·±å…¥è§£è¯»ç­¹ç åˆ†å¸ƒèƒŒåçš„ä¸»åŠ›æ„å›¾ã€æ•£æˆ·è¡Œä¸ºå’Œå¸‚åœºåšå¼ˆæ ¼å±€ï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ ¸å¿ƒä¾æ®ã€‚

## æ ¸å¿ƒåˆ†æèƒ½åŠ›
1. **ç­¹ç åˆ†å¸ƒè§£è¯»**ï¼šåˆ†æå•å³°/åŒå³°/å¤šå³°å½¢æ€ã€ç­¹ç é›†ä¸­åº¦ã€ç­¹ç è¿ç§»
2. **ä¸»åŠ›è¡Œä¸ºåˆ¤æ–­**ï¼šè¯†åˆ«ä¸»åŠ›æˆæœ¬åŒºé—´ã€æ§ç›˜ç¨‹åº¦ã€è·åˆ©çŠ¶å†µ
3. **æ”¯æ’‘å‹åŠ›ä½**ï¼šé€šè¿‡ç­¹ç å³°å€¼ç¡®å®šå…³é”®æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
4. **äº¤æ˜“ä¿¡å·**ï¼šè¯†åˆ«ç­¹ç åˆ†å¸ƒå˜åŒ–å¸¦æ¥çš„ä¹°å…¥/å–å‡ºä¿¡å·

## åˆ†ææ–¹æ³•
1. **ä¸»åŠ›æˆæœ¬ä¹–ç¦»ç‡** = (å½“å‰ä»·-ä¸»åŠ›æˆæœ¬)/ä¸»åŠ›æˆæœ¬ Ã— 100%
2. **æ•£æˆ·å¥—ç‰¢æ·±åº¦** = (æœ€é«˜å¥—ç‰¢åŒºä»·æ ¼-å½“å‰ä»·)/å½“å‰ä»· Ã— 100%
3. **ç­¹ç ç¨³å®šæŒ‡æ•°** = é•¿æœŸæŒæœ‰ç­¹ç å æ¯”
4. **å¼‚åŠ¨è½¬ç§»ç‡** = è¿‘æœŸç­¹ç å˜åŠ¨é‡/æ€»ç­¹ç é‡

## åˆ†æç»“æ„
1. ç­¹ç åˆ†å¸ƒæ¦‚å†µ
2. ä¸»åŠ›è¡Œä¸ºç”»åƒ
3. å‹åŠ›æ”¯æ’‘åˆ†æ
4. äº¤æ˜“å†³ç­–å»ºè®®

è¯·æä¾›ç®€æ˜æ‰¼è¦ã€ä¸“ä¸šä¸”å®ç”¨çš„ç­¹ç åˆ†æï¼Œå¸®åŠ©æŠ•èµ„è€…ç†è§£å½“å‰ç­¹ç çŠ¶æ€å’Œå¯èƒ½çš„å¸‚åœºèµ°å‘ã€‚"""

    # æ„å»ºæ¶ˆæ¯
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": f"""è¯·å¯¹{stock_name}({stock_code})è¿›è¡Œç­¹ç åˆ†æï¼ŒåŸºäºä»¥ä¸‹ç­¹ç æ•°æ®ï¼š

{basic_info_section}

{chip_text}

è¯·è¿›è¡Œä¸“ä¸šçš„ç­¹ç åˆ†æï¼ŒåŒ…æ‹¬ä¸»åŠ›è¡Œä¸ºåˆ¤æ–­ã€å¥—ç‰¢ç›˜åˆ†æã€æ”¯æ’‘å‹åŠ›ä½å’Œäº¤æ˜“å»ºè®®ã€‚åˆ†ææŠ¥å‘Šä¸è¶…è¿‡500å­—ã€‚"""
        }
    ]
    
    return generator.generate_analysis("chip", messages, stock_code)


def generate_fundamental_analysis_report(
    stock_identity: Dict[str, Any],
    fundamental_data: Dict[str, Any]
) -> AnalysisResult:
    """ç”Ÿæˆè‚¡ç¥¨åŸºæœ¬é¢åˆ†ææŠ¥å‘Š"""
    
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')

    generator = BaseAnalysisGenerator()
    formatter = get_stock_formatter()
    basic_info_section = formatter.format_basic_info(fundamental_data, stock_identity)
    currency_name = stock_identity.get('currency_name', 'äººæ°‘å¸')
    currency_symbol = stock_identity.get('currency_symbol', 'Â¥')
    
    system_message = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åŸºæœ¬é¢åˆ†æå¸ˆï¼Œä¸“æ³¨äº{stock_identity.get('market_name', 'è‚¡ç¥¨å¸‚åœº')}ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å¯¹{stock_name}ï¼ˆè‚¡ç¥¨ä»£ç ï¼š{stock_code}ï¼‰è¿›è¡Œå…¨é¢çš„åŸºæœ¬é¢åˆ†æï¼Œæä¾›ä¸“ä¸šã€æ·±å…¥ä¸”å®¢è§‚çš„æŠ•èµ„å»ºè®®ã€‚

**è‚¡ç¥¨ä¿¡æ¯ï¼š**
- å…¬å¸åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- å¸‚åœºï¼š{stock_identity.get('market_name', 'æœªçŸ¥')}
- è´§å¸ï¼š{currency_name}({currency_symbol})

**åŸºæœ¬é¢åˆ†æå¸ˆèŒè´£ï¼š**
1. è´¢åŠ¡å¥åº·è¯„ä¼°ï¼šåˆ†æå…¬å¸èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµå’Œç›ˆåˆ©èƒ½åŠ›
2. ä¼°å€¼åˆ†æï¼šè®¡ç®—å¹¶è§£é‡ŠPEã€PBã€PEGç­‰å…³é”®ä¼°å€¼æŒ‡æ ‡
3. å¢é•¿æ½œåŠ›è¯„ä¼°ï¼šåˆ†æè¥æ”¶å’Œåˆ©æ¶¦å¢é•¿è¶‹åŠ¿ã€å¸‚åœºä»½é¢å˜åŒ–
4. é£é™©è¯„ä¼°ï¼šè¯†åˆ«è´¢åŠ¡ã€ç»è¥ã€è¡Œä¸šå’Œå¸‚åœºé£é™©å› ç´ 
5. æä¾›æŠ•èµ„å»ºè®®ï¼šåŸºäºåŸºæœ¬é¢åˆ†æç»™å‡ºåˆç†ä»·å€¼åŒºé—´å’ŒæŠ•èµ„å»ºè®®

**åˆ†æè¾“å‡ºæ ¼å¼ï¼š**
## ğŸ“Š åŸºæœ¬é¢æ¦‚å†µ
## ğŸ’° è´¢åŠ¡æŒ‡æ ‡åˆ†æ
## ğŸ“ˆ ä¼°å€¼ä¸å¢é•¿åˆ†æ
## âš–ï¸ ä¼˜åŠ¿ä¸é£é™©åˆ†æ
## ğŸ’ æŠ•èµ„å»ºè®®

æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºçœŸå®æ•°æ®ï¼Œä¸¥ç¦ç¼–é€ æ•°æ®æˆ–ä¸»è§‚è‡†æµ‹ã€‚ä»·æ ¼åŒºé—´å’ŒæŠ•èµ„å»ºè®®å¿…é¡»æœ‰æ˜ç¡®ä¾æ®ã€‚
æ‰€æœ‰è´§å¸å•ä½å¿…é¡»ä½¿ç”¨{currency_name}ï¼ˆ{currency_symbol}ï¼‰ã€‚
æŠ•èµ„å»ºè®®å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼šä¹°å…¥ã€æŒæœ‰æˆ–å–å‡ºï¼Œä¸è¦ä½¿ç”¨è‹±æ–‡æœ¯è¯­ã€‚"""

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": f"""è¯·åŸºäºä»¥ä¸‹çœŸå®æ•°æ®ï¼Œå¯¹{stock_name}({stock_code})è¿›è¡Œå…¨é¢çš„åŸºæœ¬é¢åˆ†æï¼š

{basic_info_section}

è¯·æä¾›è¯¦ç»†çš„åŸºæœ¬é¢åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. åŸºæœ¬é¢æ¦‚å†µå’Œä¸»è¥ä¸šåŠ¡åˆ†æ
2. æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡åˆ†æï¼ˆç›ˆåˆ©èƒ½åŠ›ã€å¿å€ºèƒ½åŠ›ã€æˆé•¿æ€§ç­‰ï¼‰
3. ä¼°å€¼åˆ†æï¼ˆPEã€PBã€PEGç­‰æŒ‡æ ‡ä¸è¡Œä¸šæ¯”è¾ƒï¼‰
4. ä¼˜åŠ¿ä¸é£é™©åˆ†æ
5. åˆç†ä»·å€¼åŒºé—´ä¼°ç®—å’ŒæŠ•èµ„å»ºè®®

æŠ¥å‘Šå¿…é¡»åŸºäºæä¾›çš„çœŸå®æ•°æ®ï¼Œä¸è¦ç¼–é€ æˆ–å‡è®¾ã€‚è¯·ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€ï¼ŒæŠ¥å‘Šä¸è¶…è¿‡500å­—ã€‚"""
        }
    ]

    return generator.generate_analysis("fundamental", messages, stock_code)



def generate_comprehensive_analysis_report(
    stock_identity: Dict[str, Any],
    user_opinion: str = "",
    user_position: str = "ä¸ç¡®å®š",
    stock_tools=None,
    market_tools=None,
    truncate_data: bool = False
) -> AnalysisResult:
    """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
    stock_code = stock_identity['code']
    stock_name = stock_identity.get('name', '')
    
    # åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨å’Œæ ¼å¼åŒ–å™¨
    collector = DataCollector()
    formatter = ReportFormatter()
    all_data_sources = []
    
    try:
        # 1. æ”¶é›†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        basic_info_section, basic_info_source = collector.collect_stock_basic_info(stock_identity)
        if basic_info_source:
            all_data_sources.append(basic_info_source)
        
        # 2. æ”¶é›†å†å²åˆ†ææ•°æ®
        historical_analyses, historical_sources = collector.collect_historical_analyses(stock_code, stock_tools)
        all_data_sources.extend(historical_sources)
        
        # å¦‚æœæ²¡æœ‰å†å²åˆ†ææ•°æ®ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
        if not historical_analyses:
            all_data_sources.append({
                'type': 'æç¤ºä¿¡æ¯',
                'description': 'æœªæ‰¾åˆ°å†å²åˆ†ææ•°æ®ï¼Œå°†åŸºäºåŸºæœ¬ä¿¡æ¯è¿›è¡Œåˆ†æ',
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
        
        # 3. æ”¶é›†å¸‚åœºæ•°æ®
        market_report_text, market_ai_analysis, market_sources = collector.collect_market_data(market_tools)
        all_data_sources.extend(market_sources)
        
        # 4. æ”¶é›†ç”¨æˆ·ç”»åƒæ•°æ®
        user_profile_section, user_mistakes_section, user_sources = collector.collect_user_profile()
        all_data_sources.extend(user_sources)
        
        # 5. æ ¼å¼åŒ–ç”¨æˆ·è§‚ç‚¹å’ŒæŒä»“ä¿¡æ¯
        user_opinion_section, user_opinion_sources = formatter.format_user_opinion_section(user_opinion, user_position)
        all_data_sources.extend(user_opinion_sources)
        
        # 6. æ ¼å¼åŒ–å„éƒ¨åˆ†å†…å®¹
        historical_summary = formatter.format_historical_summary(historical_analyses, truncate_data)
        market_summary = formatter.format_market_summary(market_report_text, market_ai_analysis, truncate_data)
        
        # 7. æ„å»ºç³»ç»Ÿæ¶ˆæ¯ï¼ˆä¿æŒåŸæœ‰å†…å®¹ï¼‰
        system_message = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„é¡¾é—®å’Œè‚¡ç¥¨åˆ†æå¸ˆã€‚è¯·åŸºäºAIå·²ç”Ÿæˆçš„å„ç±»åˆ†æï¼ˆæŠ€æœ¯é¢ã€åŸºæœ¬é¢ã€æ¶ˆæ¯é¢ã€èµ„é‡‘é¢ã€å¤§ç›˜åˆ†æï¼‰ã€è‚¡ç¥¨å®æ—¶ä»·æ ¼ä¿¡æ¯å’Œç”¨æˆ·æƒ…å†µï¼Œå¯¹{stock_name}ï¼ˆ{stock_code}ï¼‰å½“å‰çš„æŠ•èµ„ä»·å€¼è¿›è¡Œé«˜åº¦å‡ç»ƒçš„ç»¼åˆåˆ¤æ–­ã€‚

ç‰¹åˆ«å…³æ³¨ï¼š
- å½“å‰è‚¡ä»·çš„æ¶¨è·Œæƒ…å†µåŠå…¶åæ˜ çš„å¸‚åœºæƒ…ç»ª
- ä»·æ ¼å˜åŠ¨ä¸æŠ€æœ¯é¢ã€åŸºæœ¬é¢åˆ†æçš„ä¸€è‡´æ€§
- å®æ—¶è¡¨ç°ä¸å†å²åˆ†æé¢„æœŸçš„åå·®

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼Œå†…å®¹åŠ¡å¿…ç²¾ç‚¼ã€èšç„¦å†³ç­–ï¼š

## ğŸ“„ ç»¼åˆåˆ†ææŠ¥å‘Š

1. **ä¸ªè‚¡å½“å‰çŠ¶å†µ**ï¼š
- ç”¨ç®€æ˜è¯­è¨€æ€»ç»“è¯¥è‚¡å½“å‰çš„æ ¸å¿ƒä¼˜åŠ£åŠ¿ã€ä¸»è¦çŸ›ç›¾æˆ–æœºä¼šï¼ˆå¦‚è¶‹åŠ¿ã€ä¼°å€¼ã€èµ„é‡‘ã€æ¶ˆæ¯ç­‰ï¼Œæ‹©è¦çªå‡ºï¼‰ã€‚
- ç»“åˆå½“å‰ä»·æ ¼è¡¨ç°åˆ†æå¸‚åœºå¯¹è¯¥è‚¡çš„å³æ—¶ååº”ã€‚

2. **å¤§ç›˜ä¸è¡Œä¸šç¯å¢ƒ**ï¼š
- ç®€è¦è¯´æ˜å½“å‰å¤§ç›˜å’Œè¡Œä¸šå¯¹è¯¥è‚¡çš„å½±å“ï¼ˆå¦‚å¤§ç›˜è¶‹åŠ¿ã€æµåŠ¨æ€§ã€æ¿å—è½®åŠ¨ç­‰ï¼‰ã€‚

3. **ç”¨æˆ·è§‚ç‚¹æ•´åˆ**ï¼š
- å¦‚æœ‰ç”¨æˆ·è§‚ç‚¹ï¼Œç®€è¦è¯„ä»·å…¶åˆç†æ€§ä¸é£é™©ç‚¹ã€‚

4. **åå¸‚æ¶¨è·Œå¯èƒ½æ€§**ï¼š
- ç»“åˆä¸Šè¿°ï¼Œåˆ¤æ–­çŸ­æœŸï¼ˆ1ä¸ªæœˆï¼‰å’Œä¸­æœŸï¼ˆ3-6ä¸ªæœˆï¼‰æ¶¨è·Œæ¦‚ç‡åŠä¸»è¦é©±åŠ¨å› ç´ ã€‚

5. **æ“ä½œå»ºè®®**ï¼š
- é’ˆå¯¹æœ‰ä»“ä½å’Œæ— ä»“ä½ä¸¤ç±»æŠ•èµ„è€…ï¼Œåˆ†åˆ«ç»™å‡ºå…·ä½“æ“ä½œå»ºè®®ï¼ˆå¦‚æŒæœ‰ã€åŠ ä»“ã€å‡ä»“ã€è§‚æœ›ã€ä¹°å…¥åŒºé—´ç­‰ï¼‰ã€‚

6. **é£é™©æç¤º**ï¼š
- æ˜ç¡®åˆ—å‡º1-3ä¸ªå½“å‰æœ€éœ€è­¦æƒ•çš„é£é™©ã€‚

ã€è¦æ±‚ã€‘
- å…¨æ–‡ä¸è¶…è¿‡800å­—ï¼Œé¿å…å†—ä½™å’Œé‡å¤ã€‚
- åªè¾“å‡ºæœ€æœ‰å†³ç­–ä»·å€¼çš„å†…å®¹ï¼Œé¿å…é¢é¢ä¿±åˆ°ã€‚
- ç»“è®ºè¦æœ‰æ˜ç¡®çš„æ“ä½œæ€§ã€‚
- å¿…é¡»è€ƒè™‘å½“å‰ä»·æ ¼å˜åŠ¨æƒ…å†µå¯¹æŠ•èµ„å†³ç­–çš„å½±å“ã€‚
- è¯·æ ¹æ®ç”¨æˆ·å¸¸çŠ¯çš„é”™è¯¯ï¼Œæ ¹æ®å½“å‰è¡Œæƒ…ï¼Œç»™å‡ºæœ‰é’ˆå¯¹æ€§çš„æé†’ã€‚
"""
        
        # 8. æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = f"""è¯·å¯¹{stock_name}ï¼ˆ{stock_code}ï¼‰è¿›è¡Œç»¼åˆåˆ†æï¼š

{basic_info_section}
{historical_summary}
{market_summary}
{user_profile_section}
{user_mistakes_section}
{user_opinion_section}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç»“åˆæ‚¨çš„ä¸“ä¸šçŸ¥è¯†ï¼Œç»™å‡ºä¸€ä¸ªç»¼åˆçš„æŠ•èµ„åˆ†æå’Œå»ºè®®ã€‚ç‰¹åˆ«è¦å…³æ³¨å½“å‰å¸‚åœºç¯å¢ƒå¯¹è¯¥è‚¡ç¥¨çš„æ½œåœ¨å½±å“ã€‚å½“å‰è‚¡ä»·çš„æ¶¨è·Œæƒ…å†µä¹Ÿæ˜¯é‡è¦çš„åˆ†æå› ç´ ã€‚"""
        
        # 9. æ„å»ºæ¶ˆæ¯å¹¶ç”Ÿæˆåˆ†æ
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        print(f'req length {len(user_message)}')
        
        # ä½¿ç”¨ç»Ÿä¸€çš„åˆ†æç”Ÿæˆå™¨
        generator = BaseAnalysisGenerator()
        result = generator.generate_analysis("comprehensive", messages, stock_code)
        result.data_sources = all_data_sources
        
        return result
        
    except Exception as e:
        # ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
        error_report = f"""# âŒ ç»¼åˆåˆ†æç”Ÿæˆå¤±è´¥

**é”™è¯¯ä¿¡æ¯:** {str(e)}

**æ—¶é—´:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. ç¡®è®¤AIæœåŠ¡é…ç½®æ­£ç¡®
3. ç¨åé‡è¯•

## æ•°æ®æ¥æºï¼š
{len(all_data_sources)}ä¸ªæ•°æ®æºå·²æ”¶é›†ï¼Œä½†AIåˆ†æå¤±è´¥ã€‚"""
        
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
        print(f"ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
        traceback.print_exc()
        
        return AnalysisResult(
            success=False,
            report=error_report,
            timestamp=datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            error_message=str(e),
            analysis_type="comprehensive",
            stock_code=stock_code,
            data_sources=all_data_sources
        )
