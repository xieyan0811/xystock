"""
å¸‚åœºæ•°æ®ç¼“å­˜ç®¡ç†å™¨

æœ¬æ¨¡å—æä¾›å¸‚åœºåŸºç¡€æ•°æ®çš„ç¼“å­˜ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. å¸‚åœºæƒ…ç»ªæŒ‡æ ‡ç¼“å­˜
2. ä¼°å€¼æŒ‡æ ‡ç¼“å­˜
3. èµ„é‡‘æµå‘æŒ‡æ ‡ç¼“å­˜
4. èèµ„èåˆ¸è¯¦ç»†æ•°æ®ç¼“å­˜

æ”¯æŒä¸åŒæ•°æ®ç±»å‹çš„å·®å¼‚åŒ–è¿‡æœŸç­–ç•¥
"""

import json
import os
import numpy as np
import pandas as pd
from datetime import datetime, timedelta, date, time
from typing import Dict, Optional, Any


class NumpyJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†numpyã€pandaså’Œdatetimeæ•°æ®ç±»å‹"""
    
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            if np.isnan(obj) or np.isinf(obj):
                return None
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif hasattr(obj, 'item'):  # numpy scalar types
            return obj.item()
        
        # å¤„ç†pandasæ•°æ®ç±»å‹
        elif isinstance(obj, (pd.Timestamp, pd.DatetimeIndex)):
            return obj.isoformat() if hasattr(obj, 'isoformat') else str(obj)
        elif pd.isna(obj):
            return None
        
        # å¤„ç†PythonåŸç”Ÿdatetimeç±»å‹
        elif isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, time):
            return obj.isoformat()
        
        # å¤„ç†pandasæ—¥æœŸç›¸å…³ç±»å‹
        elif hasattr(obj, 'to_pydatetime'):  # pandas datetime-like objects
            try:
                return obj.to_pydatetime().isoformat()
            except:
                return str(obj)
        elif hasattr(obj, 'date'):  # objects with date method
            try:
                return obj.date().isoformat()
            except:
                return str(obj)
        
        return super().default(obj)


class MarketDataCache:
    """å¸‚åœºæ•°æ®ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = "data/cache"):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.cache_dir = cache_dir
        project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.cache_file = os.path.join(project_dir, cache_dir, "market_data.json")
        
        os.makedirs(cache_dir, exist_ok=True)
        
        # ç¼“å­˜é…ç½®
        self.cache_configs = {
            'market_sentiment': {'expire_minutes': 15, 'description': 'å¸‚åœºæƒ…ç»ªæŒ‡æ ‡'},
            'valuation_data': {'expire_minutes': 1440, 'description': 'ä¼°å€¼æŒ‡æ ‡'},
            'money_flow_data': {'expire_minutes': 43200, 'description': 'èµ„é‡‘æµå‘æŒ‡æ ‡'},
            'margin_data': {'expire_minutes': 60, 'description': 'èèµ„èåˆ¸æ•°æ®'},
            'current_indices': {'expire_minutes': 5, 'description': 'å½“å‰æŒ‡æ•°å®æ—¶æ•°æ®'},
            'ai_analysis': {'expire_minutes': 180, 'description': 'AIå¤§ç›˜åˆ†æ'},
            'technical_indicators': {'expire_minutes': 60, 'description': 'æŠ€æœ¯æŒ‡æ ‡æ•°æ®'}
        }
    
    def load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return self._clean_loaded_data(data)
            return {}
        except Exception:
            return {}
    
    def _clean_loaded_data(self, data):
        """æ¸…ç†ä»JSONåŠ è½½çš„æ•°æ®ï¼Œå¤„ç†ç‰¹æ®Šå€¼"""
        if isinstance(data, dict):
            return {k: self._clean_loaded_data(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_loaded_data(item) for item in data]
        elif isinstance(data, float):
            if np.isnan(data) or np.isinf(data):
                return None
            return data
        else:
            return data
    
    def save_cache(self, cache_data: Dict):
        """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2, cls=NumpyJSONEncoder)
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def is_cache_valid(self, data_type: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        try:
            cache_data = self.load_cache()
            if data_type not in cache_data:
                return False
            
            cache_meta = cache_data[data_type].get('cache_meta', {})
            cache_time = datetime.fromisoformat(cache_meta['timestamp'])
            expire_minutes = self.cache_configs[data_type]['expire_minutes']
            expire_time = cache_time + timedelta(minutes=expire_minutes)
            
            return datetime.now() < expire_time
        except Exception:
            return False
    
    def get_cached_data(self, data_type: str) -> Dict:
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            cache_data = self.load_cache()
            return cache_data.get(data_type, {}).get('data', {})
        except Exception:
            return {}
    
    def save_cached_data(self, data_type: str, data: Dict):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        try:
            cache_data = self.load_cache()
            cache_data[data_type] = {
                'cache_meta': {
                    'timestamp': datetime.now().isoformat(),
                    'data_type': data_type,
                    'expire_minutes': self.cache_configs[data_type]['expire_minutes']
                },
                'data': data
            }
            self.save_cache(cache_data)
            print(f"ğŸ’¾ {self.cache_configs[data_type]['description']}å·²ç¼“å­˜")
        except Exception as e:
            print(f"âŒ ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
    
    def clear_cache(self, data_type: Optional[str] = None):
        """æ¸…ç†ç¼“å­˜"""
        if data_type:
            if data_type not in self.cache_configs:
                print(f"âŒ æœªçŸ¥çš„æ•°æ®ç±»å‹: {data_type}")
                return
            
            try:
                cache_data = self.load_cache()
                if data_type in cache_data:
                    del cache_data[data_type]
                    self.save_cache(cache_data)
                    print(f"âœ… å·²æ¸…ç†{self.cache_configs[data_type]['description']}ç¼“å­˜")
                else:
                    print(f"â„¹ï¸ {self.cache_configs[data_type]['description']}ç¼“å­˜ä¸å­˜åœ¨")
            except Exception as e:
                print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        else:
            try:
                if os.path.exists(self.cache_file):
                    os.remove(self.cache_file)
                    print("âœ… å·²æ¸…ç†æ‰€æœ‰ç¼“å­˜æ•°æ®")
                else:
                    print("â„¹ï¸ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")
            except Exception as e:
                print(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cache_status(self) -> Dict:
        """è·å–ç¼“å­˜çŠ¶æ€"""
        status = {}
        current_time = datetime.now()
        cache_data = self.load_cache()
        
        for data_type, config in self.cache_configs.items():
            if data_type in cache_data:
                is_valid = self.is_cache_valid(data_type)
                
                try:
                    cache_meta = cache_data[data_type].get('cache_meta', {})
                    cache_time_str = cache_meta.get('timestamp', '')
                    cache_time = datetime.fromisoformat(cache_time_str)
                    expire_time = cache_time + timedelta(minutes=config['expire_minutes'])
                    
                    if is_valid:
                        remaining_minutes = int((expire_time - current_time).total_seconds() / 60)
                        remaining_text = f"{remaining_minutes}åˆ†é’Ÿåè¿‡æœŸ"
                    else:
                        overdue_minutes = int((current_time - expire_time).total_seconds() / 60)
                        remaining_text = f"å·²è¿‡æœŸ{overdue_minutes}åˆ†é’Ÿ"
                        
                except Exception:
                    cache_time_str = "è§£æå¤±è´¥"
                    remaining_text = "æœªçŸ¥"
                
                status[data_type] = {
                    'description': config['description'],
                    'exists': True,
                    'valid': is_valid,
                    'cache_time': cache_time_str,
                    'expire_minutes': config['expire_minutes'],
                    'remaining': remaining_text
                }
            else:
                status[data_type] = {
                    'description': config['description'],
                    'exists': False,
                    'valid': False,
                    'cache_time': None,
                    'expire_minutes': config['expire_minutes'],
                    'remaining': "æ— ç¼“å­˜"
                }
        
        return status
    
    def print_cache_status(self):
        """æ‰“å°ç¼“å­˜çŠ¶æ€"""
        status = self.get_cache_status()
        
        print("=" * 70)
        print("ğŸ“Š å¸‚åœºæ•°æ®ç¼“å­˜çŠ¶æ€")
        print(f"ğŸ“ ç¼“å­˜æ–‡ä»¶: {self.cache_file}")
        print("=" * 70)
        
        for data_type, info in status.items():
            status_icon = "âœ…" if info['valid'] else ("ğŸ“‹" if info['exists'] else "âŒ")
            print(f"{status_icon} {info['description']:<12} | {info['remaining']:<15} | è¿‡æœŸæ—¶é—´: {info['expire_minutes']}åˆ†é’Ÿ")
        
        try:
            if os.path.exists(self.cache_file):
                file_size = os.path.getsize(self.cache_file)
                size_text = f"{file_size/1024:.1f}KB" if file_size > 1024 else f"{file_size}B"
                print(f"\nğŸ“¦ ç¼“å­˜æ–‡ä»¶å¤§å°: {size_text}")
            else:
                print(f"\nğŸ“¦ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception:
            pass
        
        print("=" * 70)


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_cache_manager = None

def get_cache_manager() -> MarketDataCache:
    """è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = MarketDataCache()
    return _cache_manager
