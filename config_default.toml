[LLM_OPENAI]
# OpenAI API 配置
API_KEY = "sk-"
BASE_URL = ""
TIMEOUT = 60  # 请求超时时间（秒）
MAX_RETRIES = 3  # 最大重试次数

# 默认模型配置
DEFAULT_MODEL = "deepseek-chat"
INFERENCE_MODEL = "deepseek-chat"
DEFAULT_TEMPERATURE = 0.7

[LLM_LOGGING]
# Token使用记录配置
USAGE_LOG_FILE = "logs/openai_usage.csv"
ENABLE_LOGGING = true
LOG_LEVEL = "INFO"

[LLM_CACHE]
# 缓存配置（可选）
ENABLE_CACHE = false
CACHE_TTL = 3600  # 缓存时间（秒）

[AI_ANALYSIS]
# AI分析配置
[AI_ANALYSIS.TECHNICAL]
TEMPERATURE = 0.5
MODEL_TYPE = "inference"
CACHE_FILENAME = "req_tech.txt"

[AI_ANALYSIS.NEWS]
TEMPERATURE = 0.7
MODEL_TYPE = "default"
CACHE_FILENAME = "req_news.txt"

[AI_ANALYSIS.CHIP]
TEMPERATURE = 0.5
MODEL_TYPE = "default"
CACHE_FILENAME = "req_chip.txt"

[AI_ANALYSIS.FUNDAMENTAL]
TEMPERATURE = 0.6
MODEL_TYPE = "default"
CACHE_FILENAME = "req_basic_info.txt"

[AI_ANALYSIS.COMPREHENSIVE]
TEMPERATURE = 0.4
MODEL_TYPE = "default"
CACHE_FILENAME = "req.txt"
